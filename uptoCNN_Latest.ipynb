{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27wxTozULWFU",
        "outputId": "03b9d3fc-8ec0-4eb4-e2a5-8a8f0ef76672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import pandas\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HADqygUtPsvp"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler  # to standardize the features\n",
        "from sklearn.decomposition import PCA  # to apply PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xS37utYIMqme",
        "outputId": "d2fda284-6ac1-482b-fe1d-c1a06b2f168a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import scipy.spatial\n",
        "\n",
        "\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\" \n",
        "model = hub.load(module_url)\n",
        "print (\"module %s loaded\" % module_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "lF_n6HoNLWuG",
        "outputId": "9c74d3d4-ec50-44bb-f4ea-de56bc1e63b7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-dec3159e-de89-4fca-9813-9301d9c73775\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-dec3159e-de89-4fca-9813-9301d9c73775\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving AAPL_combine_updated.csv to AAPL_combine_updated.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "T-xO4nxpLWwg"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def processText(column,n):#to remove stop words,to convert into lowercase and root word\n",
        "    import re\n",
        "\n",
        "    corpus = []\n",
        "    for i in range(n):\n",
        "        review = re.sub('[^a-zA-Z]', ' ', column[i])\n",
        "        review = review.lower()\n",
        "        review = review.split()\n",
        "        ps = PorterStemmer()\n",
        "        all_stopwords = stopwords.words('english')\n",
        "        all_stopwords.remove('not')\n",
        "        review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
        "        review = ' '.join(review)\n",
        "        corpus.append(review)\n",
        "    return corpus\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xMmAdQbLMwUi"
      },
      "outputs": [],
      "source": [
        "def embed(input):\n",
        "  return model(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQ0sEsHTLWzU",
        "outputId": "73735cab-0ec0-468a-bef5-886c843f019b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['datetime', 'close', 'open', 'low', 'high', 'volume', 'y_actual', 'evm',\n",
            "       'force_index', 'rsi', 'cci', 'macd-signal', 'atr', 'vwap', 'stx_7_3',\n",
            "       'Total Revenue', 'Cost of Revenue', 'Gross Profit', 'Normalized EBITDA',\n",
            "       'Operating Cash Flow', 'Investing Cash Flow', 'Financing Cash Flow',\n",
            "       'Free Cash Flow', 'Total Assets',\n",
            "       'Total Liabilities Net Minority Interest',\n",
            "       'Total Equity Gross Minority Interest', 'Total Capitalization',\n",
            "       'summary', 'title'],\n",
            "      dtype='object')\n",
            "       datetime       close        open         low        high      volume  \\\n",
            "969  2022-12-22  132.028412  134.350006  130.300003  134.559998  77852100.0   \n",
            "970  2022-12-23  131.658981  130.919998  129.639999  132.419998  63814900.0   \n",
            "971  2022-12-27  129.831772  131.380005  128.720001  131.410004  69007800.0   \n",
            "972  2022-12-28  125.847855  129.669998  125.870003  131.029999  85438400.0   \n",
            "973  2022-12-29  129.412415  127.989998  127.730003  130.479996  75703700.0   \n",
            "\n",
            "     y_actual       evm   force_index        rsi  ...  Operating Cash Flow  \\\n",
            "969       0.0 -5.483888 -1.211086e+09  36.101057  ...          122151000.0   \n",
            "970       0.0 -6.731920 -9.411091e+08  35.694640  ...          122151000.0   \n",
            "971       0.0 -4.783137 -8.874656e+08  33.675324  ...          122151000.0   \n",
            "972       1.0 -4.469965 -1.271092e+09  29.726630  ...          122151000.0   \n",
            "973       1.0 -4.473906 -9.856706e+08  36.860470  ...          122151000.0   \n",
            "\n",
            "     Investing Cash Flow  Financing Cash Flow  Free Cash Flow  Total Assets  \\\n",
            "969          -22354000.0         -110749000.0     111443000.0   352755000.0   \n",
            "970          -22354000.0         -110749000.0     111443000.0   352755000.0   \n",
            "971          -22354000.0         -110749000.0     111443000.0   352755000.0   \n",
            "972          -22354000.0         -110749000.0     111443000.0   352755000.0   \n",
            "973          -22354000.0         -110749000.0     111443000.0   352755000.0   \n",
            "\n",
            "     Total Liabilities Net Minority Interest  \\\n",
            "969                              302083000.0   \n",
            "970                              302083000.0   \n",
            "971                              302083000.0   \n",
            "972                              302083000.0   \n",
            "973                              302083000.0   \n",
            "\n",
            "     Total Equity Gross Minority Interest  Total Capitalization  \\\n",
            "969                            50672000.0           149631000.0   \n",
            "970                            50672000.0           149631000.0   \n",
            "971                            50672000.0           149631000.0   \n",
            "972                            50672000.0           149631000.0   \n",
            "973                            50672000.0           149631000.0   \n",
            "\n",
            "                                               summary  \\\n",
            "969  crypto winter damn bitcoin ethereum investor s...   \n",
            "970  dec reuter appl inc aapl appl watch electrocar...   \n",
            "971  last month insid transact gn store nordin fact...   \n",
            "972  appl expect launch buy pay later servic call a...   \n",
            "973  led tech investor much cautiou opt make switch...   \n",
            "\n",
            "                                                 title  \n",
            "969  bitcoin interest surg crypto winter arriv morn...  \n",
            "970  appl watch violat alivecor patent import ban h...  \n",
            "971  merri christma us appleinsid appleinsid best a...  \n",
            "972  catalyst appl stock first major new product be...  \n",
            "973  netflix lead faang higher could fail thestreet...  \n",
            "\n",
            "[5 rows x 29 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "df = pandas.read_csv('AAPL_combine_updated.csv')\n",
        "\n",
        "\n",
        "df=df.dropna()\n",
        "df = df[~(df['datetime'] >= '2023-01-01')]#dropping rows of year=2023\n",
        "\n",
        "df=df.reset_index(drop=True)\n",
        "\n",
        "\n",
        "print(df.columns)\n",
        "\n",
        "titleColumn=df['title']\n",
        "summaryColumn=df['summary']\n",
        "dateColumn=df['datetime']\n",
        "titleColumn=list(titleColumn)\n",
        "summaryColumn=list(summaryColumn)\n",
        "\n",
        "corpus=processText(titleColumn,len(titleColumn))#preprocessing title column\n",
        "df['title']=corpus\n",
        "\n",
        "summaryCorpus=processText(summaryColumn,len(summaryColumn))#preprocessing summary column\n",
        "df['summary']=summaryCorpus\n",
        "\n",
        "\n",
        "df = df.astype({'title':'string'})\n",
        "df = df.astype({'summary':'string'})\n",
        "\n",
        "print(df.tail(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeGz9GKzEsXI",
        "outputId": "ce540442-8e33-464c-f503-4f0526b7487e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(974, 29)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "QqlmHiL8hJ7P",
        "outputId": "7258cc15-f5bc-4cea-e3a6-0d6de9b63af0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'avan motor line six electr scooter launch one everi month moneycontrol mac pro imac qualcomm expect appl start appleinsid crorepati portfolio could turn rs monthli sip rs crore moneycontrol china didi launch credit crowdfund servic diversif reuter pro con buy appl aapl stock wtop perform dow compon nysearca dia seek alpha set vip mail contact iphon ipad io appleinsid ipad iphon xr lead christma activ help xr catch xs market share appleinsid holiday adventur maco mojav mac observ fool first icloud phish scam year idrop news beat dj ebro darden appoint appl music global editori head cover hip hop r b appleinsid juici year histori new york fame cartier mansion bloomberg usb type c protocol similar mfi final could block low qualiti charger appleinsid syndic bank sbi life insur sign bancassur pact moneycontrol stock watch china talk tough taiwan realmoney japanes yen soar flash crash sweep currenc market reuter meet year old ghanaian tech geniu code uber instagram snapchat puls ghana review zen dual watch wireless qi charger great still airpow appleinsid australian dollar left bloodi comput driven crash reuter appl plung hour slash revenu forecast thestreet stock market news jan nasdaq appl aapl biggest challeng thestreet pain hold stock case kotak mahindra bank moneycontrol micron technolog lone tech stock top piotroski f score seek alpha swap ratio fix vijaya bank bob dena bank merger moneycontrol tata motor ashok leyland fall dismal decemb sale perform moneycontrol great etf begin investor u news world report money much appl stand lose netflix stop app subscript forb buy netflix chill go back part nasdaq nflx seek alpha identifi multibagg pick stock doubl wealth moneycontrol ranveer singh heart rule box offic moneycontrol trend redefin retail industri moneycontrol amazon vs googl one clear stock buy right seek alpha control ohmibod vibrat appl watch mac observ nanci pelosi retak hous speaker gavel new congress conven marketwatch maev appl music web player customiz theme mac observ druckenmil indic use seek alpha new year gold price surg astonish gld expand bullionvault eight depress illumin month flip phone mac observ baidu sohu get caught latest chines internet clampdown bloomberg dow recov point plung resili start channel com wisc tv mumbai base builder sanjay agarw commit suicid project delay blame moneycontrol presid own trump bump trump slump bloomberg starbuck slide smaller competitor plan major expans thestreet ebro darden talk new appl music job futur ui improv appleinsid appl aapl outlook cut worst tech troubl bloomberg dow plung point appl flash warn sign yahoo financ dow fall point appl bombshel us factori slowdown cnn closer look appl troubl china grow wechat mac appl launch chines new year gift guid includ new year mac appl warn spark currenc flash crash highlight strong thestreet goldman sach call appl disappoint holiday quarter busi insid cyber research pull public talk hack appl face id reuter appl shock downgrad rattl global stock market guardian stock market log worst start year decad marketwatch appl cloud servic execut patrick gate depart stealth startup human appleinsid ascenda singbridg acquir acr land parcel chennai moneycontrol best perform fidel fund retir yahoo financ see work appl new b austin campu austin busi journal extend batteri life appl watch appleinsid iphon xs batteri health degrad fast know idrop news gm breweri q review rise input cost hurt margin moneycontrol much appl stock safe marketwatch top tech trend seek alpha use safari save password mac app appleinsid new phish scam masquerad appl support call appleinsid tech stock without china exposur investorplac exclus camp experi luxuri side kumbh mela season moneycontrol samsung huawei suppli major modem chip qualcomm reuter credit suiss expect strong q quarter aurobindo torrent pharma cadila moneycontrol alloc portfolio small midcap wealth gener moneycontrol spectrum offer appl tv k subscrib per month appleinsid huawei punish staff pay cut market tweet sent via iphon appleinsid citi levkovich cut p target sentiment enter panic mode marketwatch china warn signal trump trade war final hit home euronew close stock market oil price track marketwatch pandora releas redesign appl watch app offlin playback support appleinsid appl biggest stock price drop iphon era recent drop rank marketwatch trump like meet china wang qishan davo report say bloomberg appl stock drop decemb motley fool extend batteri life iphon xr iphon xs day beyond appleinsid appl plaster privaci ad billboard near la vega convent center ahead ce appleinsid stock rise even sensex fall day moneycontrol decod thing know husqvarna vitpilen swartpilen moneycontrol appl elabor ipad pro precis manufactur process reiter micron toler bend appleinsid netflix idiot hurt bird box challeng marketwatch appl rais dividend motley fool technic classroom predict market trend triangl chart pattern moneycontrol connect four display macbook pro targu univers quad video hd dock station appleinsid akamai commod busi hidden gem nasdaq akam seek alpha learn profit oscil market strategi moneycontrol warren buffett could lose billion appl stock marketwatch appl darkest day iphon era trigger flood price target cut analyst marketwatch appl stock price recov bold predict marketwatch ongc first get forc buy hpcl buy share back moneycontrol transcript icici bank q fy earn confer call moneycontrol ipad ipad pro get new case zagg rug book go slim book go messeng folio appleinsid appl burn googl amazon massiv ad overlook ce idrop news ad itun samsung tv great move appl long game play year appleinsid use appl siri homekit control numi intellig toilet appleinsid ring lineup grow new peephol camera seri smart light still homekit appleinsid stock market investor time hear ugli truth marketwatch favorit invest strategi seek alpha third parti usb c lightn cabl made offici ce griffin appleinsid honeywel debut pro smart thermostat lack homekit support appleinsid samsung show robot health care retail store bloomberg blue chip offer great buy write opportun seek alpha psa bewar popular packag track app iphon idrop news american chines buyer drive growth supercar maker mclaren marketwatch garmin ad hot smartwatch featur match appl samsung fortun packag tracker parcel add devic botnet mac observ homekit come brilliant wall mount smarthom control appleinsid tech giant gorg ai professor bad bloomberg samsung reaction putrid print may mean take stock bloomberg possibl ipad mini lte antenna shown pictur social media appleinsid plex may take roku amazon appl other ad support movi third parti subscript appleinsid googl leas convert mall race l offic space bloomberg merced claim luxuri car crown analyst eye challeng tesla euronew new version homepass introduc appl watch support mac observ lametr sky new wall mount smart light give data glanc appleinsid ge debut homekit enabl c ge smart light wall switch wall plug appleinsid amazon valuabl compani planet cnn kwikset launch aura halo smartlock homekit readi premi contemporari appleinsid prospect u profit drop rise investor reuter ignor appl watch ecg featur mac otterbox popsocket collabor iphon case lifeproof ship power pack appleinsid appl hold annual sharehold meet march st steve mac ce netgear nighthawk ax bring wi fi enhanc mac observ smartphon shipment china fell not appl mac wsj call iphon xr failur sell ludicr mistaken appleinsid appl music expand song lyric support seven countri includ franc germani appleinsid ce hyper new wireless airpod charg case mac observ worri appl watch ekg fals posit inflammatori nonsens appleinsid giant screen walk car best ce bloomberg happen stock market today motley fool squar sq add featur payment process app bloomberg appl hire former facebook privaci employe sandi parakila mac observ hand philip hue lineup outdoor light homekit outdoor motion sensor appleinsid omron heartguid pack blood pressur monitor smartwatch complet bp monitor featur ekg tech alivecor appleinsid mani push up plane bloomberg lie custom show g e devic fire carrier appleinsid new indoor mall map flyover locat appl map mac observ worst news stock market price cnn blockchain stock offer stablecoin enhanc crypto bloomberg virtual assist futur smart home investorplac appl impact p investopedia tyson galleria eye appl tiffani washington busi journal chart day china still fear factor appl investor realmoney tim cook say appl ecosystem never stronger marketwatch appl tell us anyth new china seek alpha appl supplier face china iphon sale exposur bloomberg honda dream drive earn amazon gift card ride car yahoo financ g smartphon could revit sale row erupt today mac hand netatmo homekit smart doorbel cam appleinsid appl consid use led base light tube glow appl watch band appleinsid satya nadella hit refresh bold vision microsoft futur investor busi daili jeff bezo wife mackenzi divorc year amazon ceo tweet wl tv hand laci new usb c mobil drive design mac mind appleinsid volkswagen poach alexand hitzing appl project titan team self drive vehicl role appleinsid stop mac app store say previou purchas appleinsid happi th birthday macbook pro deeper look appl icon notebook idrop news tencent mini program could open wechat busi use bloomberg trump trade war threaten divid world smartphon bloomberg scosch introduc trio wireless charg mount car home appleinsid hand nanoleaf hexagon homekit smart light panel appleinsid india get long await turn turn direct appl map appleinsid microsoft bing show suggest child porn mac observ bezo divorc unfurl investor wonder mean cbc ca appl secur chip affect disk storag mac observ nike dutch tax statu investig eu regul reuter appl supplier face china iphon sale exposur yahoo financ china retail slash iphon price appl sale warn reuter hand brilliant smart home control homekit integr appleinsid bullet journal not organ bloomberg appl next blackberri nasdaq aapl seek alpha ring allegedli let employe round clock access custom live stream idrop news exclus rami malek bohemian rhapsodi featur avail itun store appleinsid first look creat headphon audio super x fi appleinsid bank phone comput safer marketwatch appl spend year unit flight shanghai appleinsid starbuck next us brand warn china troubl appl goldman sach say cnbc aura band add addit health track smart appl watch appleinsid appl licens itun airplay strategi revers way appleinsid ce flashback folli curv tv screen mac observ ladi gaga remov track featur r kelli appl music itun amid sexual assault alleg appleinsid keep iphon repeatedli drop wi fi network connect appleinsid market segment definit exampl thestreet addit detail emerg first homekit doorbel robin telecom appleinsid truck carri secur appl payload crash san jose kill one appleinsid year stream war get real cnn video round iphon rumor includ usb c g appleinsid dump iphon android switcher regret other look back marketwatch explor homekit tv appleinsid damag mistak porinju bet leel goe awri stock tank moneycontrol appl vs bitcoin better long term invest beincrypto big buyback save appl stock motley fool alibaba stock fortun chang nyse baba seek alpha stun concept show iphon could evolv cult mac anker debut usb c lightn cabl march audio adapt april appleinsid delet facebook instagram galaxi mac observ rich chines still hungri luxuri good despit slowdown bloomberg amazon dividend debut motley fool samsung long histori mock appl copi appleinsid face id touch id unlock compel law enforc rule feder judg appleinsid thiev make k worth appl tech chicago area target idrop news diablo immort highlight activis blizzard nuanc mobil seek alpha cv vs walgreen better drug store nyse cv seek alpha hand hyperdr best usb c dock ipad pro yet appleinsid much appl pay qualcomm royalti motley fool review nimbl charger batteri solid stylish eco friendli way power appleinsid averag american retir portfolio twenti percent better seek alpha psa homepod count toward stream limit appl music appleinsid unit airlin take poster reveal appl largest mac controversi bbc veteran charli sloth host new rap show appl beat appleinsid first appl collabor sofia coppola rock appleinsid appl next gen ipod touch usb c iphon expect year idrop news appl car come eight thing need know idrop news make new secur mac boot extern drive appleinsid appl pay appl busi chat use fund td ameritrad account appleinsid appl work forc sens glove gestur control appleinsid immigr found nearli half fortun compani new data analysi show fortun appl china problem iphon problem nasdaq aapl seek alpha fiat chrysler stock could becom googl takeov target investorplac appl aapl sell new iphon case built batteri bloomberg feder bank q net profit seen yoy rs cr sharekhan moneycontrol new leak may expos full damag appl nasdaq unit airlin biggest custom appl spend year busi journal nomad debut new natur leather appl watch band airpod case appleinsid appl lose appeal million verdict favor virnetx appleinsid weed influenc onlin help firm get around advertis mac observ exchang rate fluctuat overcom palpit moneycontrol nike adapt bb iphon control self lace basketbal sneaker appleinsid netflix announc biggest ever price increas mac observ microsoft ceo satya nadella fuel humbl comeback fortun durabl innov nyse mmm seek alpha intel next ceo could one peopl thestreet delta air line use brand innov push premium busi journal u busi actual use tax cut bloomberg micron im flash post intel share purchas nasdaq tim cook highlight stori appl watch owner whose devic detect fib appleinsid way spot stock market peak u news world report money crompton greav consum electr q pat seen yoy rs cr prabhuda lilladh moneycontrol huawei founder ren zhengfei appl fan want live forev cnn iphon x beat galaxi cpu alleg benchmark test appleinsid alphabet swot analysi nasdaq goog seek alpha unit airlin biggest custom appl spend million year ticket news com kusa appl pay chief jennif bailey deliv keynot transact payment forum appleinsid consum discretionari sector outperform seek alpha motorola razr reviv foldabl display could cost iphon xs max appleinsid appl spent k tim cook person secur mac year imac pro benefit better perform prove valu appleinsid appl gave reinvent televis shacknew fifth gener ipad mini come first half say appleinsid futur lock iphon could open camera app automat held take photo appleinsid facebook ad prefer list user trait interest mac observ eye storm socgen say warn stock market problem enough marketwatch feel lone simpl cure get social media island bloomberg stimwav tout month mi sc trial result mass devic netflix nflx earn strategi growth grow pain bloomberg taiwan semiconductor sale forecast hammer chipmak thestreet china accus appl incorrect refer taiwan hong mac tim cook reiter call data privaci protect mac observ pro con invest pro wrestl powerhous wwe motley fool babi shark faang member wait bate breath take stock bloomberg appl green light episod sci fi seri simon kinberg david weil appleinsid explain rbi expand tokenis facil card file tokenis servic moneycontrol irhythm technolog inferior product line manageri seek alpha netflix reed hast revolution hollywood investor busi daili major data broker acxiom back tim cook call data privaci regul appleinsid health insur subsid appl watch motley fool niit tech announc q result jan key issu watch moneycontrol ahluwalia contract build multi year stori moneycontrol aapl stock recoup loss incur tim cook slash macrumor broken blue chip manulif power financi fight shake globe mail mayb ron johnson right j c penney motley fool foxconn cut contract job china nikkei reuter live appl absurdli complic music featur appl watch appleinsid microsoft suggest shift iphon window mobil end support date announc appleinsid bring app life withbundl ui design element social mac observ nvidia watch china nasdaq nvda seek alpha ing promis appl pay come soon spain could hint rollout appleinsid appl claim iphon avail retail enjoin german court appleinsid googl pay fossil smartwatch ip compet appl watch appleinsid byton open st store china follow soon cleantechnica netflix burn cash last forev cnn top seven macbook air featur make model great appleinsid american pay compani keep data privat answer marketwatch netflix think fortnit bigger competitor hbo marketwatch opinion vanguard jack bogl man save american billion marketwatch year bill gate step microsoft ceo motley fool ai boost employ india encourag evolut job market moneycontrol get start new homepod get appleinsid facebook mobil game ecosystem rapidli expand motley fool quick take acceler balanc sheet growth continu hdfc bank q moneycontrol leak email show appl tri use qualcomm modem mac composit scheme gst help real estat sector moneycontrol googl fi iphon solid travel still carrier custom servic nonsens appleinsid done win confid export ramal j daili news lic complet acquisit stake idbi bank final get moneycontrol icici lombard q fy review robust growth premium led motor insur buy dip moneycontrol mac evo concept imagin small liquid cool appl desktop cult mac bunch leverag commun servic etf hit market nasdaq china post slowest econom growth sinc cnn martin luther king jr day celebr appl homepag mac custom appl watch sport loop band set prize appl third mac choos music get store appl watch appleinsid jewish teacher fire report anti semit harass student lawsuit claim yahoo financ googl weigh pull news servic eu copyright law bloomberg cyient acquir remain stake edsm subsidiari moneycontrol coach updat appl watch band lineup three new color new style appleinsid macbook pro stage light problem caus tear thin cabl integr display appleinsid iphon xs max rank fourth dxomark selfi camera rank appleinsid dividend aristocrat nobl vs achiev vig head head seek alpha appl upper east side store nyc win aia award interior architectur appleinsid prabhat dairi sell flagship dairi biz french firm rs crore moneycontrol play market budget day like take kiki challeng moneycontrol wall street drop econom outlook corpor forecast sour reuter aviat data sector grow yoy indigo top market share moneycontrol appl pay add taco bell target speedway investor busi daili appl tim cook meet power broker davo say educ effort peopl appleinsid first max life beat lic claim settlement moneycontrol foxconn say tri hire peopl first quarter job cut reuter test use iphon xs smart batteri case iphon x appleinsid china gener z teen spend worri less bloomberg china overtak us world biggest retail market year cnn appl iphon batteri case worth motley fool hdfc amc q review aum growth led liquid fund investor cheer moneycontrol appl promot photographi shot iphon contest rip photograph appleinsid much ireland will pay boycott israel bloomberg naresh goyal want right price exit jet airway rs share moneycontrol index fund vs mutual fund choos thestreet play music appl watch speaker wireless headphon appleinsid great stock buy hold next decad kipling person financ favorit featur maco mojav mac observ compani visionari leader hurt ceo chairman role split marketwatch pixelm pro get new layer tool clip mask prism updat appleinsid show rahul fail bjp other react priyanka gandhi polit foray moneycontrol new report hint appl revamp icon ipod touch idrop news hg infra bag rs cr road project bharatmala programm moneycontrol data scientist best job america yahoo financ unitech case sc turn chandra brother bail plea yet moneycontrol averag home loan size women borrow higher men survey moneycontrol tim cook lisa jackson talk innov crown princ mac alleg sun pharma may tighten scrutini relat parti distribut model sector moneycontrol maruti suzuki set japan india institut manufactur haryana moneycontrol kpit technolog share due demerg engin divis moneycontrol tata motor bid adieu nano april moneycontrol appl iphon lineup pack punch thestreet microsoft search engin bing briefli block china cnn texa instrument may signal chip sector bottom semi stock thestreet appl su bluetooth commun devic go back iphon gs appleinsid iphon xr best sell iphon model claim percent us sale decemb appleinsid amd forget crypto come china nasdaq amd seek alpha latest io beta hint airpod hey siri setup screen appleinsid next homekit could precis geofenc accur within feet appleinsid appl poach samsung execut lead batteri develop team appleinsid intel intc q earn report alphastreet sono plan headphon move outsid home bloomberg upcom tivo app appl tv restrict p frame per second stream appleinsid iphon xs iphon xs max fare samsung galaxi appleinsid appl fire project titan employe mac observ best gui featur appl ever releas maco histori mac observ fulfil wwdc promis microsoft offic arriv mac app store appleinsid true cost leav iphon unprotect idrop news microsoft ceo said data like electr mac observ environment poison ga sensor futur iphon could save life appleinsid qi wireless charg problem appl fix idrop news cesc ventur spencer retail stock plung investor still profit moneycontrol appl music android get tablet support version appleinsid lowest price year appl macbook pro sale macbook pro appleinsid revamp nokia hope u rememb matrix two bloomberg outstand global stock fund morningstar laguardia chao may help push trump end shutdown bloomberg fix font problem mac make safari mail unread appleinsid look vsco privaci polici mac observ clovia rais fresh seri b fund capit other moneycontrol music watcho rare misfir appl design appleinsid icici bank impact stock due cbi implic former ceo temporari moneycontrol compar iphon xr iphon plu real world appleinsid cbi raid bhupind singh hooda resid dlf offic delhi gurgaon moneycontrol stop misinform bloomberg bloomberg new wechat home screen could seriou ramif mac idea profit ultratech eas cost pressur aid margin buy dip moneycontrol appl smartphon maker push export credit tariff cut india appleinsid week chart nifti end sensex slip check market perform moneycontrol take look rumor surround appl airpod appleinsid hon hai expand oper india vietnam amid trade tension bloomberg lupin unit pithampur plant get observ usfda moneycontrol tesla vs clayton christensen idea tech disrupt cleantechnica technic classroom make action trade plan use roc momentum oscil moneycontrol appl simplifi safari autofil touch id support maco appleinsid appl johni srouji supposedli not consid intel ceo posit appleinsid io beta suggest next gen ipad ipad mini might not sport face id refer new ipod touch appleinsid appl must give griev husband access cloud store famili photo judg rule marketwatch onida see tepid close year revenu growth moneycontrol power produc seek resolut issu augment coal output korba mine moneycontrol trade setup monday top thing know open bell moneycontrol cpwd ask offic constitut review committe speedi complet project moneycontrol car test keyless entri vulner electron theft idrop news googl shame iphon low light perform new pixel ad cult mac new appl patent suggest anoth possibl reason airpow delay idrop news microsoft msft q earn preview alphastreet incognito employe ce hint appl ar glass come idrop news appl game subscript servic reportedli earli stage develop appleinsid appl post video shot iphon xr plu behind scene footag appleinsid know appl troubl mass produc mac pro u fortun trigger crash zee group compani share januari moneycontrol get mojav updat dock learn replac entir appleinsid review zipp mini portabl airplay speaker need appleinsid sell procter gambl nyse pg seek alpha return never linear market moneycontrol exclus wockhardt confid busi take year aid india us antibiot moneycontrol appl ipad help transform hockey nhl commission tell appl employe appleinsid german govern rule autobahn speed limit yahoo financ look multibagg ambit capit shortlist stock basi six financi paramet moneycontrol emir cut check baggag limit lowest level economi fare feb moneycontrol georg fernand drive coca cola india moneycontrol nsel scam case joseph massey arrest hour long chase sent polic custodi till feb moneycontrol harley davidson inc profit miss see shipment lowest eight year moneycontrol spi dividend sdpr p index dividend payment analysi dividend investor unpopular take giant tech compani pay tax marketwatch appl project titan research smart seatbelt could control carplay devic appleinsid cv dangl appl watch lure keep eye custom health bloomberg chart explain disrupt invest forb turn facetim avoid appl eavesdrop bug cnn new ipod touch come soon rumor mill correct appleinsid bullish video game trend yahoo financ make dividend growth portfolio seek alpha corn stock pop g optic fiber growth appl busi investor busi daili fed hold steadi great news stock cnn appl share pop slight earn revenu beat thestreet shannon river hedg fund bet new york time much bloomberg chalet hotel ipo review attract busi high debt caus concern moneycontrol appl stock aapl leap higher long last see market author revok benami attach order shah rukh khan call action baseless moneycontrol appl revok facebook enterpris develop certif sideload violat u appleinsid appl cash nasdaq plan buy readi move apart need know moneycontrol wealth see time real wealth moneycontrol world largest compani microsoft report wednesday forb transcript kotak mahindra bank q fy earn confer call moneycontrol appl plan open larg retail outlet mumbai delhi ncr report moneycontrol jabil help skullcandi get deal best buy st pete catalyst better fear new analyst phrase describ earn bloomberg bf invest standalon decemb net sale rs crore moneycontrol sonnet launch new four port usb c pci e expans card mac pro tower appleinsid juul lab inc plan india e cigarett entri new hire subsidiari moneycontrol play fortnit ipad pro iphon xr control consider improv appleinsid hard china slowdown could hit global econom growth marketwatch vijay kedia rais stake stock q know chines bamboo tree approach moneycontrol siri shortcut use steal send person data develop warn appleinsid cardiogram premium enabl remot cross platform monitor appl watch wear os data appleinsid lifx homekit bulb appear store wi fi password unencrypt appleinsid appl stock ralli weak forecast analyst say compani wood marketwatch chines engin charg steal secret materi appl cnn timelin icici bank videocon loan case moneycontrol strong earn outlook attract valuat make icici bank must buy moneycontrol foxconn reconsid plan wisconsin plant tout trump gov scott walker marketwatch manag concentr risk portfolio seek alpha restaur ask govt new e commerc fdi rule appli zomato swiggi moneycontrol appl kill googl enterpris develop certif screenwis meter appleinsid facebook worth billion earn set potenti comeback stori marketwatch verizon g rollout stall reinforc claim tech not come iphon appleinsid bbc sound get carplay support mac observ give mac mini perform boost replac hard drive ssd appleinsid ford bronco fever heat six figur vintag restomod bloomberg playboy model imag use creat jpeg format mac observ true potenti neo smart economi cryptocurr neo seek alpha posit momentum neg momentum carnag within moneycontrol budget day snapshot bear domin street last year moneycontrol use termin chang look mac speed work appleinsid govern gener revenu spent moneycontrol appl fifth avenu cube reopen first half appleinsid nintendo mario kart tour iphon jump track delay summer appleinsid dr reddi appoint axi bank ex md shikha sharma independ director moneycontrol appl smartwatch china slowdown hurdl swatch bloomberg lind india delist valu premium greed moneycontrol appl inadvert confirm iphon sale motley fool centr revis fy gdp growth rate moneycontrol justic b n srikrishna go man govern corpor moneycontrol unemploy rate highest decad nsso survey moneycontrol budget impress homebuy moneycontrol idea profit hero motocorp raw materi price weigh q margin near term outlook weak moneycontrol china stock market terribl year could lot better cnn microsoft offici laptop sponsor super bowl liii tablet appleinsid custom think lyft sweet investor hope ruthless bloomberg budget metro budget alloc rs crore moneycontrol josh budget meet bollywood fm goyal quot uri moneycontrol budget govt increas food subsidi alloc rs lakh crore moneycontrol budget govt announc pm kisaan samman nidhi farmer get rs per year moneycontrol budget film industri say anti camcord provis go long way end piraci moneycontrol bridgewat associ prove self obsess actual work bloomberg comcast appear skip appl tv xfiniti app favor roku appleinsid walt disney compani card nyse di seek alpha io user unabl reach app store appl music itun appleinsid appl supplier face declin sale slump investopedia meet year old discov appl shock facetim bug marketwatch appl ban facebook tech tool track teen brows habit fiji time expect market februari investopedia appl remov siri team lead part ai strategi shift appleinsid appl rumor game subscript could big chang mobil game appleinsid appl buy lot stock high stop buy low marketwatch expect cfo leav nasdaq softbank bullish china consid billion invest guazi wccftech stock market power rank appl jack motley fool technic session identifi cup handl pattern set trade strategi moneycontrol appl watch seri fall detect summon emerg servic save elderli man appleinsid rcom stock erod investor wealth peak moneycontrol year old norwegian man life save appl watch seri idrop news rate agenc downgrad variou loan facil dhfl moneycontrol rain industri advers sc action materi impact busi model stay cautiou moneycontrol microsoft fend appl remain valuabl us compani fox busi amazon replac product sold seller cloudtail appario moneycontrol sugar output till januari arrear cane farmer touch rs cr isma moneycontrol giant shop spree show realli china economi bloomberg idea profit titan q jewelleri sparkl margin watch eyewear disappoint moneycontrol stock market trade lesson wild swing onion price moneycontrol appl becam world valuabl compani today mac spi bull trap sell ralli nysearca spi seek alpha appl includ confus g e connect icon io beta appleinsid review zendur supertank superport best choic yet portabl power appleinsid airpod could greater health monitor devic appl watch appleinsid roku rumor talk support appl airplay appleinsid whatsapp updat lock face id touch id mac observ lg launch mac readi inch k monitor usb c hdr appleinsid much would cost buy everyth advertis super bowl marketwatch first mfi usb c lightn cabl pre order cheaper appl appleinsid new york beat san francisco world best tech citi bloomberg earn preview expect googl parent alphabet today forb much instagram increas facebook stock thestreet fubotv come appl tv app mac observ appl proven much power tech giant yahoo financ strava partner slope ski snowboard track mac observ trader focus fang nasdaq futur thestreet appl snuck four new animoji charact io beta idrop news jim cramer amaz display power prestig realmoney appl hospit reit not take bite appl seek alpha ey announc finalist th ey entrepreneur year award program moneycontrol review rambo inspir richard mill rm watch bloomberg appl reportedli eye offic retail space manhattan hudson appleinsid free app order valentin flower mac observ usd cnh technic analysi bullish continu pattern hourli fxstreet unicod consortium final new emoji arriv iphon io appleinsid idea profit ramkrishna forg strong q near term outlook sluggish moneycontrol appl music memoji theme billboard pop ahead grammi award appleinsid review eve homekit lightstrip bright spot crowd market appleinsid explain invest rs lakh tax save fund moneycontrol merger not lead reduct branch dena bank moneycontrol zero product sale tata nano januari moneycontrol fii rais stake nearli compani decemb quarter moneycontrol grip stori pharma entrepreneur jayaram chigurupati lost fortun life moneycontrol jubil life foodwork pay sale royalti promot group moneycontrol touch id span entir iphon display work appl appleinsid bhel q review brokerag place posit bet good order book margin could improv moneycontrol appl retail chief angela ahrendt leav iphon sale declin marketwatch tc gain order win solidar bahrain moneycontrol global brokerag maintain buy rate jubil foodwork see upsid moneycontrol number everi investor must know track portfolio perform moneycontrol tax guid youtub blogger determin incom tax liabil moneycontrol review usb c uni dock hub great portabl rug accessori mac owner appleinsid appl deirdr brien name svp retail peopl cnbc hacker break icloud lock iphon mac observ popular io app use glassbox sdk record user screen without permiss u appleinsid appl beat teas graffiti style neymar jr edit studio wireless headphon appleinsid get termin use control mac appleinsid spotifi buy gimlet anchor combat itun podcast domin appleinsid review grovemad wireless charg pad gorgeou luxuri accessori appleinsid privat equiti firm adopt distribut earn nyse bx seek alpha arlo technolog stock plummet today motley fool cook thank angela ahrendt memo employe retail chief departur appleinsid pelosi respond trump state union smirk eye roll lawmak reviv bipartisan bill target drug price marketwatch stock amazon biggest competitor nasdaq review anker powerlin ii usb c lightn cabl cheaper durabl appl appleinsid jubil foodwork revers decis pay royalti promot moneycontrol hard stock market bear right chart drive home marketwatch anoth ad factoid pre test result bad ad mac find iphon warn murder victim assail locat minut death appleinsid research demo new maco keychain exploit hold data appl protest appleinsid question ask day move averag see market berger paint q fy review volum drive toplin crude price hurt margin moneycontrol internet softwar industri outlook growth prospect rich nasdaq startup india receiv angel tax notic survey moneycontrol narayana murthi step india need take becom trillion economi moneycontrol sensex gave posit return feb year hold moneycontrol footbal fratern rememb manchest unit fallen hero munich air disast moneycontrol earn season trade http www ig com hedg fund manag doug kass say stock market bull need wake marketwatch raymond call report promot entiti deal mislead moneycontrol use inexpens tv set monitor mac might not want appleinsid commvault name sanjay mirchandani new ceo moneycontrol ashutosh raghuvanshi narayana hrudayalaya forti health new ceo moneycontrol lowest price ever appl gb inch ipad pro sale u appleinsid lamborghini launch huracan evo price rs crore india moneycontrol cogniz rope vodafon chief brian humphri replac outgo ceo francisco souza moneycontrol eye air travel airbnb hire former virgin america ceo bloomberg cipla continu cost cut via portfolio rationalis manufactur network review moneycontrol hate crime bengaluru drunk local attack techi see speak malayalam moneycontrol best valentin day gift appl lover life appleinsid relianc jio largest investor west bengal digit space mukesh ambani moneycontrol appl ramp effort design radio chip instead mac appl develop g chip modem engin move chip design group idrop news new iphon xs iphon xr ad sell portrait mode background blur appleinsid oprah winfrey harpo product hire terri wood netflix head appl origin content product appleinsid chart day timelin nokia rise fall realmoney chines consum still spend big luxuri fashion beauti brand yahoo financ appl prove troublesom profession audio interfac user appleinsid twitter stock may find support earn plung thestreet review boost top flight iphon connect stealth electr skateboard appleinsid appl need new retail strategi cnn pharma entrepreneur jayaram chigurupati death case shift hyderabad polic mysteri deepen moneycontrol appl take memoji theme appl music ad youtub ahead grammi award appleinsid stock market dip keep buy say bank america merril lynch marketwatch netflix smart download come io mac observ analyst averag iphon upgrad cycl last four year mac lg ultrawid k k beast monitor thunderbolt appleinsid aurora cannabi flood cannabi market nasdaq acb seek alpha know three way zoom use iphon camera idrop news sprint sue ad bogu g e icon iphon devic appleinsid appl face backlash io app allow men stop women mac observ rise emoji caus big problem insid us judici system appleinsid first cut bpcl q fy weak perform inventori loss impact margin moneycontrol facebook earn surpris amount revenu china thestreet save million start seek alpha soybean futur jump month high support meal export moneycontrol viacom buy pluto tv nasdaq compar macbook air less expens model appleinsid appl su two factor authent iphon mac take much time appleinsid tata starbuck add around new outlet fiscal moneycontrol correct handl time valu decay option lead higher return moneycontrol creat simpl one step task autom save time mac appleinsid hedg fund manag stock buyback illeg cnn distribut day track market weak confirm uptrend moneycontrol sun tv network climb analyst remain posit q result moneycontrol review mujjo new touchscreen glove offer flexibl conveni warmth appleinsid bad china econom slump imposs tell cnn jeff bezo privaci nightmar could happen anyon prevent marketwatch success airpod appl product strategi mac observ appl name veteran iphon execut head augment mac appl black site give contractor perk littl secur bloomberg worst phone radiat offend rank appl spot may surpris idrop news appl news best tip get start use appl news app idrop news dhoot transmiss acquir san electromec undisclos sum moneycontrol offer free appl tv k new fiber internet custom appleinsid avoid valu trap seek alpha mumsnet updat user secur flaw mac observ nse launch trade weekli option nifti index moneycontrol citi amazon consid hq scrap nyc yahoo financ ariana grand break appl music record thank u next appleinsid tinder cow tudder mobil app breeder bloomberg weak hand may signal major market declin fund manag warn marketwatch review nomad titanium appl watch band afford altern appl metal link appleinsid airpod predict ship health featur improv sound better textur appleinsid buy manappuram financ target rs dinesh rohira moneycontrol starbuck done fine sinc howard schultz left cnn tata motor stock crash mutual fund scheme equiti worth rs cr moneycontrol new demat account touch year high million report moneycontrol updat io right not spi bug idrop news proof outperform right activ manag stock fund marketwatch liquid import make long term invest moneycontrol hand alpin new giant f carplay receiv appleinsid appl watch lead woman supraventricular tachycardia diagnosi idrop news report googl pixel fasest grow smartphon yoy googl mac desktop shootout imac k versu mac mini appleinsid hedg fund manag kyle bass think u stock lower end marketwatch first cut oil india q fy crude oil natur ga segment drive decent perform moneycontrol last call ipad pro plu free jbl e bt wireless headphon valu appleinsid live nation want williamson counti pit long term busi journal mid smallcap continu bleed high qualiti pick elara capit moneycontrol opinion gone wrong appl china mac saudi aramco take exxon mobil oil giant oversea oil investor busi daili exclus bimlendra jha ceo tata steel uk resign moneycontrol appl ramp augment realiti effort new ar market chief idrop news revis fdi norm e commerc consum durabl firm go back draw board moneycontrol review picaso lab ipad pro leather sleev protect altern appl appleinsid amazon buy eero want consum trust internet investorplac silicon valley use trade secret hide race problem bloomberg hand plugabl usb c nvme drive enclosur bring cost effect speed extern storag appleinsid tip becom better stock trader investorplac mighti us dollar get even stronger cnn appl compar valuat surpris nasdaq aapl seek alpha way invest like warren buffett u news world report money blackrock hire former fed offici stanley fischer advis memo moneycontrol nifti around dma nse stock long term averag worri moneycontrol bharat forg q profit jump rs cr oper incom rise moneycontrol swiggi move beyond food deliveri launch store deliv everyday need moneycontrol take bridg bigger home moneycontrol nestl set sell first starbuck coffe billion deal moneycontrol honda civic sedan make comeback india hit market next month moneycontrol someth not right twitter tech glitch caus like retweet count fluctuat moneycontrol rbi fine sbi bank baroda corpor bank union bank india violat norm moneycontrol kla tencor extend domin metrolog inspect seek alpha reason coca cola stock investorplac wilbur ross ivanka trump introduc workforc advisori board bloomberg siddhartha lal name ey entrepreneur year moneycontrol review mophi juic pack access keep iphon run wirelessli appleinsid skywork solut year motley fool hand cintiq artist tablet provid premium experi discount appleinsid appl fitbit leader grow smartwatch market alphastreet googl pay appl stagger amount money default thestreet review grovemad appl watch dock premium way power favorit wearabl appleinsid appl aapl driverless car need human intervent bloomberg appl biggest product flop time kipling person financ appl acquir u k base digit market startup datatig bloomberg much save import return invest moneycontrol sun pharma challeng build special biz us moneycontrol godrej lock tap b b b g segment achiev rs crore revenu fy moneycontrol video nvidia support abandon maco mojav appleinsid saudi aramco pick bank debut intern bond moneycontrol appl enterpris certif leverag distribut hack version popular app appleinsid podcast sanjay bakshi talk emot weigh invest decis moneycontrol grocer kroger launch qr code base payment servic snub appl pay appleinsid america fight huawei mess world g plan cnn airbu european dream white eleph moneycontrol lego return arkit hidden side haunt interact playset appleinsid akamai good compani not price nasdaq akam seek alpha cabl hack show trust random usb accessori idrop news best best fidel fund buy nasdaq director appl think differ campaign retir appleinsid canada goos ceo dani reiss powerless us china tension bloomberg us armi want steve job like iphon style design process next gener rifl appleinsid white hat hacker demonstr malici lightn cabl built wi fi appleinsid walgreen add alipay chines tourist mac observ jpmorgan coin bloomberg oscar win director use macbook pro produc moonlight appleinsid minda industri board approv merger harita seat system moneycontrol appl su faulti ipad batteri behind lethal apart fire new jersey appleinsid bharat biotech acquir chiron behr vaccin gsk undisclos amount moneycontrol samsung open full scale u retail store take appl idrop news appl beat releas nba collect studio wireless headphon six team color appleinsid bob iger restor disney magic kingdom creativ investor busi daili usfda form point repeat observ dr reddi bachup plant moneycontrol digit turbin mobil advertis platform play nasdaq app seek alpha cash back system demonetis say sbi report moneycontrol appl latest conflict miner report say five smelter refin remov appleinsid airpod rumor launch spring alongsid airpow featur new black color option appleinsid democrat suddenli stupid marketwatch warren buffett berkshir hathaway rapid u turn oracl cnn ikea apolog sell map miss new zealand yahoo financ tactic pick week ashok leyland moneycontrol still love mac user group mac observ iphon xs g speed least percent faster predecessor studi show appleinsid allstat acquir iphon repair outfit icrack join right repair appleinsid real world lte speed doubl sinc iphon big reason upgrad appleinsid move market today live updat cnn jaquar group eye rs crore revenu moneycontrol nasdaq escap longest bear market one measur year marketwatch video get egpu new mac mini appleinsid technic classroom use guppi multipl move averag devis trade strategi moneycontrol get high growth half risk seek alpha shortcut settl us could turn american dream nightmar moneycontrol appl googl urg remov saudi app track women cnn invest tougher us china eventu reach settlement berkshir hathaway charli munger moneycontrol funcl ai earbud might look like airpod whole lot cheaper still sound great appleinsid appl recruit former smartlock develop sam jadallah head home initi appleinsid dr reddi get green signal duvvada unit usfda investor moneycontrol explain six factor influenc interest rate economi moneycontrol review naim mu airplay speaker fill home style power sound appleinsid kansa introduc porn filter bill mac observ microsoft reach infin beyond nasdaq msft seek alpha hdfc bank plan cut branch expans aditya puri moneycontrol augment realiti mirrorworld mac observ appl hardwar roadmap call least new product appleinsid l arm win rs cr contract build major airport moneycontrol total usd portfolio review januari seek alpha vbl board approv plan acquir pepsico franchis right south west india moneycontrol stock news dr reddi lab tech mahindra ye bank jaype infratech wipro moneycontrol soundcloud add option distribut music directli servic like appl music appleinsid airpod wireless charg case may not need precis locat charg pad appleinsid hero electronix set semiconductor chip design centr bengaluru moneycontrol understand formula acceler financi independ moneycontrol pro audio glitch equip mac associ usb connect appleinsid govt approv construct km rapid transit system connect delhi meerut moneycontrol appl iphon still hold command lead smartphon sale japan appleinsid ipad mini cad file suggest spec bump major new featur appleinsid fed loretta mester say rate like need rise bit moneycontrol consum demand law curb fake product menac e commerc polici moneycontrol io develop beta offici releas new updat idrop news strategi analyt global smart speaker sale reach busi wire even walmart face slower sale china ceo say not bloomberg qualcomm new g modem radio chip help fend thestreet life indian pilot extra hour high emi fat salari often delay moneycontrol harshad mehta scam famili free rs cr incom tax demand year moneycontrol homepod sale fourth quarter amazon googl extend lead appleinsid appl activ appl pay servic saudi arabia ahead offici launch u appleinsid machin learn blockchain gartner identifi top data analyt technolog trend moneycontrol sachin bansal invest million ola moneycontrol morgan stanley pick big four indian bank sector moneycontrol saudi arabia see bn invest opportun india crown princ moham bin salman moneycontrol ny man uncov work year old appl comput parent attic idrop news garmin kandi technolog group magellan health motley fool winrar fix year old bug mac observ equal weight etf help diminish concentr risk etf trend garmin grmn report q earn result alphastreet samsung roll new flagship phone thestreet anti lgbt emoji glitch mac observ appl pay activ million iphon worldwid appleinsid editori appl make us wait new imac good reason appleinsid canara robeco mf expect euphoria elect recoveri like mid small cap stock moneycontrol mani stock trade year averag pe valu buy moneycontrol lloyd bank brush brexit fear billion investor payout moneycontrol review canon eo r fantast full frame mirrorless camera feel two year behind appleinsid subdu demand suffici stock weigh cotton price despit lower output forecast moneycontrol spectrum tv come appl tv mac observ ed regist money launder case former il fs top brass raid compani offic moneycontrol basic edit detail markup pdf mojav appleinsid use iphon updat nike adapt bb sneaker brick appleinsid india invest destin saudi arabia oil minist moneycontrol steve job rival hit hard time make remark bloomberg spi etf time short spdr p etf investorplac colleg student caught traffick drug io app titl still avail app store appleinsid mark zuckerberg meet uk offici want regul facebook cnn could appl k display video mac qualcomm push u import ban iphon idrop news invest mutual fund moneycontrol transact moneycontrol'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "titleColumn=df['title']\n",
        "titleColumn[0]\n",
        "\n",
        "# df=df.fillna(0)\n",
        "\n",
        "# df=df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summaryColumn=df['summary']\n",
        "summaryColumn[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "xK_JlCXXTT-N",
        "outputId": "f5067c15-84b4-4a19-831e-fcb52b8aebfc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'oil rich saudi arabia see invest opportun usd billion india variou sector said visit crown princ moham bin salman wednesday naddress media along prime minist narendra modi crown princ said saudi arabia alreadi invest usd billion india sinc visit modi gulf nation nhe also laud india strength inform technolog said saudi arabia invest lot sector n understand opportun usd billion invest india want strengthen invest econom tie ensur use return countri crown princ said nhe inform saudi arabia invest india petrochem diversifi sector toggl dark modewhen john pfaff found appl iie comput sit parent attic year expect still work order nand appl iie younger probabl nostalgia trip nan appl iie npic twitter com zl wwxoo john pfaff johnfpfaff februari amazingli appl iie bootabl npic twitter com ivet l john pfaff johnfpfaff februari appl iie comput first releas back appl desktop sold macintosh brand name stock market quiet wednesday differ benchmark react varieti news event nsever stock post strong advanc garmin grmn kandi technolog group kndi magellan health mgln among top perform ncheck latest garmin kandi technolog magellan health earn call transcript nkandi get go aheadelectr vehicl manufactur kandi technolog saw stock price skyrocket follow pivot decis u nation highway traffic safeti administr nfinal share magellan health finish higher winrar file compress app window recent patch bug fourteen year via arstechnica n ifixit genius advoc right repair winrar vulnerabilityth bug made possibl hacker execut malici code comput open boobi trap file nit involv flaw found unacev dll code librari updat sinc nthe code execut vulner winrar exist entir year sinc unacev librari creat possibl earlier check point research said blog post nin post compar proof concept exploit zero day attack exploit broker zerodium said would buy much recent bout lacklust earn result big name drag tradit market capit weight strategi tilt toward largest compani nexchang trade fund investor though diminish concentr risk equal weight etf nan equal weight index methodolog make sens portfolio especi sector volatil technolog nthe invesco p equal weight technolog etf ryt consist outperform p npotenti investor awar due equal weight index methodolog portfolio greater tilt toward mid size compani share garmin grmn gain pre market trade wednesday technolog firm report yet anoth market beat quarterli earn power wearabl segment npro forma ep gain per share fourth quarter surpass wall street consensu cent per share nanalyst project net sale around million garmin top deliv million year year nthese strong result partial offset continu weak auto segment fell compar period last year nlast quarter garmin acquir flight plan servic provid fltplan com last week said acquir tacx manufactur indoor bike trainer person tweet emoji rainbow flag overlaid prohibit symbol nthen peopl took notic got angri think anti lgbt emoji appl releas n fix iphon rainbow emoji messag crash anti lgbt emojithi new emoji exist ninstead glitch way unicod charact work nif put prohibit symbol unicod charact not emoji next emoji copi past appear top emoji appl pay continu grow major player mobil payment market thank loyal user loup ventur note estim percent iphon user around world enabl appl pay devic na major compon appl ever grow servic arm appl pay well use featur increas popular countri enabl nbase appl advic iphon instal base reach million devic extrapol current million appl pay user nit estim percent us base iphon user tri appl pay percent intern user done nwhile larg complementari appl pay growth loup ventur note one element slight disappoint appl took gambl reveal updat imac event gave us sneak peek decemb imac pro nappl may look mani peopl buy imac would drawn imac pro nexcept imac pro actual sale look appl wrote imac nif huge price differ surpris imac pro intend successor imac nyou might even sure power regular imac strong enough make peopl decid need imac pro may not euphor movement optim equiti market ahead gener elect schedul may believ nimesh chandan head invest equiti canara robeco mutual fund ncanara robeco mutual fund joint ventur canara bank india robeco group netherland nspeak mid small cap compani chandan said nifti end last year posit signific correct mid cap small cap space npost elect expect focu shift busi economi would help recoveri mid small cap compani ncurrent mani small cap compani valuat level make risk reward matrix attract said mani stock bse trade histor year averag pe nanalyst advis investor use low p e stock filter shortlist invest idea use quantit paramet invest nit common peopl mistak low p e stock valu stock may slightli mislead approach valu invest n compani trade year avg pe also pass filter given investor see growth potenti n high valuat ttm pe year avg pe depict investor confid busi manag compani britain biggest mortgag lender post percent rise net profit billion pound expect billion pound accord compani provid averag analyst forecast nit pledg pay penc per share total dividend percent unveil billion pound share buyback nlloyd also set asid million pound compens custom missold payment protect insur take total provis million pound nhorta osorio total pay packag year slip million pound million pound previou year remain significantli higher counterpart rb hsbc n lloyd indel plug uk economi shadow cast brexit mean bank share left cold appleinsid spent last month test canon first full frame mirrorless eo r shooter see stack ever grow mirrorless market ncanon eo rthe eo r lot competit nrecent nikon other thrown hat ring like nikon z nikon z appleinsid alreadi review ncanon eo r media slotcanon follow nikon lead includ one media card slot controversi omiss nshoot eo rget ergonom issu shoot eo r fantast price declin season despit forecast lower cotton product higher export figur first three month cotton season start octob nmoreov slow start cotton sow maharashtra gujarat hike minimum support price msp support domest cotton price nin latest usda monthli report world cotton consumpt revis lower million bale million nthe forecast end stock increas million bale million million bale increas china nmoreov cotton associ india cai latest press releas forecast cotton output lakh bale percent compar last year product lakh bale charter spectrum tv essenti come appl tv us month plu tax via appleinsid n charter spectrum app roll appl tv spectrum tvat launch servic includ channel spectrum tv app nthe spectrum app becam avail app store januari nwith move charter becam first basic cabl compani u support zero sign tvo n charter secur flaw expos custom data million enforc director ed regist case former top offici il fs includ former chairman ravi parthasarathi prevent money launder act pmla nthe investig bodi carri raid variou offic il fs includ bkc mumbai offic premis former offici ninfrastructur financi il fs news last year default oblig accumul debt rs crore nashish begwani director enso infrastructur p ltd file case offici il fs rail allegedli caus rs crore loss compani fraudul mean nthe ed probe fund gener illeg case launder creat illegitim asset accus yet though mac come pdf tool capabl use let talk use na stand maco mojav come excel pdf handl markup tool first class edit one not nyou markup pdf open one preview quick look find document tap spacebar nmarkupwhen pdf open preview display bar markup tool nthe mac come far better power pdf creation edit markup tool get credit nikeown nike adapt bb self lace sneaker tie loosen via smartphon app report high tech footwear brick android version app issu caus faulti deliveri new firmwar nlaunch januari sale sinc februari adapt bb shoe automat adjust keep shoe tight soon wearer slip nin first week avail cnet report shoe requir firmwar updat appli one could perform via io android app nit appear least android app case issu pick led user complain review nike adapt app googl play store nbi contrast owner use io app not appear suffer issu speak saudi india forum saudi oil minist khalid al falih said oil rich kingdom excit reform open market countri keen partner growth nsaudi arabia india main crude oil supplier lpg n energi cours major bridg saudi arabia india said nwe want saudi nation oil compani saudi aramco petrochem giant sabic becom household name india n india prioriti invest outsid kingdom saudi arabia happen npleas make sure browser support javascript cooki not block load nfor inform review term servic cooki polici uc santa cruz polic tip illicit app find poster public banana plug student uc santa cruz campu n banana plug remain avail download app store write market game involv ing banana plug n banana plug publish app store last octob updat twice recent novemb na note section appl app review guidelin softwar like banana plug strictli prohibit distribut app store napp encourag consumpt tobacco product illeg drug excess amount alcohol not permit app store cnn busi mark zuckerberg final come face face top uk offici like regul facebook nafter avoid multipl request testifi front uk parliamentari committe facebook fb ceo set meet thursday jeremi wright uk secretari digit cultur media sport nthe privat meet part wright silicon valley tour ahead releas plan lay uk govern could better regul internet compani nthe compani declin comment plan meet zuckerberg wright nthe tech compani wright jame visit trip includ twitter twtr appl aapl snap snap tinder yesterday post video outlin thought appl upcom k display nin end think appl upcom profession display basic true ultra wide k display k display nappl may market k display not realm possibl given k k dimens nwatch video present updat discuss appl k display nthe appl k display would featur pixel versu imac pro qualcomm mission past two year accus appl infring patent tri get appl iphon ban numer countri nit partial succeed least two case court china germani ban sale specif infring iphon model countri although countri entir differ reason nin u qualcomm made similar infring claim germani suggest iphon model use intel modem infring qualcomm patent nin file appl ask commiss addit six month extens event pender decis revers import ban impos compani nqualcomm therebi insist itc ban intel chip iphon time appl demonstr deploy fix remov infring qualcomm patent moneycontrolmoneycontrol launch brand new mutual fund invest platform moneycontrol transact android io app store nit end end solut mf investor not research learn mutual fund also invest mutual fund easi step complet onlin none download moneycontrol transact app googl play store appl app store nmoneycontrol transact personalis recommend featur recommend suitabl mutual fund user base multipl paramet nat launch gautam shelar busi head moneycontrol said launch initi version transact app base extens user research feedback moneycontrol user commun'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 889
        },
        "id": "jAxhAYfhAFU5",
        "outputId": "2b43c4a0-87e8-4c61-c6d9-f49a650a6938"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     datetime      close       open        low       high       volume  \\\n",
              "0  2019-02-20  41.624268  42.797501  42.747501  43.330002  104457600.0   \n",
              "1  2019-02-21  41.389565  42.950001  42.575001  43.092499   68998800.0   \n",
              "2  2019-02-22  41.851711  42.895000  42.845001  43.250000   75652800.0   \n",
              "3  2019-02-25  42.156578  43.540001  43.487499  43.967499   87493600.0   \n",
              "4  2019-02-26  42.180771  43.427502  43.292500  43.825001   68280800.0   \n",
              "\n",
              "   y_actual       evm   force_index        rsi  ...  Operating Cash Flow  \\\n",
              "0       0.0  0.097372  1.891971e+08  62.386241  ...           69391000.0   \n",
              "1       1.0  0.042723  8.899667e+07  60.091586  ...           69391000.0   \n",
              "2       1.0  0.043863  1.310842e+08  62.979083  ...           69391000.0   \n",
              "3       1.0  0.039235  7.856815e+07  64.788967  ...           69391000.0   \n",
              "4       1.0 -0.005992  1.476660e+07  64.935466  ...           69391000.0   \n",
              "\n",
              "   Investing Cash Flow  Financing Cash Flow  Free Cash Flow  Total Assets  \\\n",
              "0           45896000.0          -90976000.0      58896000.0   338516000.0   \n",
              "1           45896000.0          -90976000.0      58896000.0   338516000.0   \n",
              "2           45896000.0          -90976000.0      58896000.0   338516000.0   \n",
              "3           45896000.0          -90976000.0      58896000.0   338516000.0   \n",
              "4           45896000.0          -90976000.0      58896000.0   338516000.0   \n",
              "\n",
              "   Total Liabilities Net Minority Interest  \\\n",
              "0                              248028000.0   \n",
              "1                              248028000.0   \n",
              "2                              248028000.0   \n",
              "3                              248028000.0   \n",
              "4                              248028000.0   \n",
              "\n",
              "   Total Equity Gross Minority Interest  Total Capitalization  \\\n",
              "0                            90488000.0           182295000.0   \n",
              "1                            90488000.0           182295000.0   \n",
              "2                            90488000.0           182295000.0   \n",
              "3                            90488000.0           182295000.0   \n",
              "4                            90488000.0           182295000.0   \n",
              "\n",
              "                                             summary  \\\n",
              "0  oil rich saudi arabia see invest opportun usd ...   \n",
              "1  live bse livens live volum today l h shreesh b...   \n",
              "2  piram enterpris pel largest sell painkil sarid...   \n",
              "3  competit tough victoria secret lead substanti ...   \n",
              "4  happen npleas make sure browser support javasc...   \n",
              "\n",
              "                                               title  \n",
              "0  avan motor line six electr scooter launch one ...  \n",
              "1  outlier quick view varun beverag moneycontrol ...  \n",
              "2  saridon pain relief tablet sold everi second s...  \n",
              "3  appl surviv iphon challeng like microsoft appl...  \n",
              "4  rais bet tencent otcmkt tcehi seek alpha appl ...  \n",
              "\n",
              "[5 rows x 29 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a417b16-0bf9-4ad9-9db5-eae6ac88484c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>close</th>\n",
              "      <th>open</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "      <th>y_actual</th>\n",
              "      <th>evm</th>\n",
              "      <th>force_index</th>\n",
              "      <th>rsi</th>\n",
              "      <th>...</th>\n",
              "      <th>Operating Cash Flow</th>\n",
              "      <th>Investing Cash Flow</th>\n",
              "      <th>Financing Cash Flow</th>\n",
              "      <th>Free Cash Flow</th>\n",
              "      <th>Total Assets</th>\n",
              "      <th>Total Liabilities Net Minority Interest</th>\n",
              "      <th>Total Equity Gross Minority Interest</th>\n",
              "      <th>Total Capitalization</th>\n",
              "      <th>summary</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-02-20</td>\n",
              "      <td>41.624268</td>\n",
              "      <td>42.797501</td>\n",
              "      <td>42.747501</td>\n",
              "      <td>43.330002</td>\n",
              "      <td>104457600.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.097372</td>\n",
              "      <td>1.891971e+08</td>\n",
              "      <td>62.386241</td>\n",
              "      <td>...</td>\n",
              "      <td>69391000.0</td>\n",
              "      <td>45896000.0</td>\n",
              "      <td>-90976000.0</td>\n",
              "      <td>58896000.0</td>\n",
              "      <td>338516000.0</td>\n",
              "      <td>248028000.0</td>\n",
              "      <td>90488000.0</td>\n",
              "      <td>182295000.0</td>\n",
              "      <td>oil rich saudi arabia see invest opportun usd ...</td>\n",
              "      <td>avan motor line six electr scooter launch one ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-02-21</td>\n",
              "      <td>41.389565</td>\n",
              "      <td>42.950001</td>\n",
              "      <td>42.575001</td>\n",
              "      <td>43.092499</td>\n",
              "      <td>68998800.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.042723</td>\n",
              "      <td>8.899667e+07</td>\n",
              "      <td>60.091586</td>\n",
              "      <td>...</td>\n",
              "      <td>69391000.0</td>\n",
              "      <td>45896000.0</td>\n",
              "      <td>-90976000.0</td>\n",
              "      <td>58896000.0</td>\n",
              "      <td>338516000.0</td>\n",
              "      <td>248028000.0</td>\n",
              "      <td>90488000.0</td>\n",
              "      <td>182295000.0</td>\n",
              "      <td>live bse livens live volum today l h shreesh b...</td>\n",
              "      <td>outlier quick view varun beverag moneycontrol ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-02-22</td>\n",
              "      <td>41.851711</td>\n",
              "      <td>42.895000</td>\n",
              "      <td>42.845001</td>\n",
              "      <td>43.250000</td>\n",
              "      <td>75652800.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.043863</td>\n",
              "      <td>1.310842e+08</td>\n",
              "      <td>62.979083</td>\n",
              "      <td>...</td>\n",
              "      <td>69391000.0</td>\n",
              "      <td>45896000.0</td>\n",
              "      <td>-90976000.0</td>\n",
              "      <td>58896000.0</td>\n",
              "      <td>338516000.0</td>\n",
              "      <td>248028000.0</td>\n",
              "      <td>90488000.0</td>\n",
              "      <td>182295000.0</td>\n",
              "      <td>piram enterpris pel largest sell painkil sarid...</td>\n",
              "      <td>saridon pain relief tablet sold everi second s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-02-25</td>\n",
              "      <td>42.156578</td>\n",
              "      <td>43.540001</td>\n",
              "      <td>43.487499</td>\n",
              "      <td>43.967499</td>\n",
              "      <td>87493600.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.039235</td>\n",
              "      <td>7.856815e+07</td>\n",
              "      <td>64.788967</td>\n",
              "      <td>...</td>\n",
              "      <td>69391000.0</td>\n",
              "      <td>45896000.0</td>\n",
              "      <td>-90976000.0</td>\n",
              "      <td>58896000.0</td>\n",
              "      <td>338516000.0</td>\n",
              "      <td>248028000.0</td>\n",
              "      <td>90488000.0</td>\n",
              "      <td>182295000.0</td>\n",
              "      <td>competit tough victoria secret lead substanti ...</td>\n",
              "      <td>appl surviv iphon challeng like microsoft appl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-02-26</td>\n",
              "      <td>42.180771</td>\n",
              "      <td>43.427502</td>\n",
              "      <td>43.292500</td>\n",
              "      <td>43.825001</td>\n",
              "      <td>68280800.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.005992</td>\n",
              "      <td>1.476660e+07</td>\n",
              "      <td>64.935466</td>\n",
              "      <td>...</td>\n",
              "      <td>69391000.0</td>\n",
              "      <td>45896000.0</td>\n",
              "      <td>-90976000.0</td>\n",
              "      <td>58896000.0</td>\n",
              "      <td>338516000.0</td>\n",
              "      <td>248028000.0</td>\n",
              "      <td>90488000.0</td>\n",
              "      <td>182295000.0</td>\n",
              "      <td>happen npleas make sure browser support javasc...</td>\n",
              "      <td>rais bet tencent otcmkt tcehi seek alpha appl ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 29 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a417b16-0bf9-4ad9-9db5-eae6ac88484c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6a417b16-0bf9-4ad9-9db5-eae6ac88484c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6a417b16-0bf9-4ad9-9db5-eae6ac88484c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lBNiHbsIC6Te"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 837
        },
        "id": "FJ5g70zqDl2L",
        "outputId": "26045149-967d-4c8f-ec2d-dbd943c62afd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       datetime       close        open         low        high      volume  \\\n",
              "969  2022-12-22  132.028412  134.350006  130.300003  134.559998  77852100.0   \n",
              "970  2022-12-23  131.658981  130.919998  129.639999  132.419998  63814900.0   \n",
              "971  2022-12-27  129.831772  131.380005  128.720001  131.410004  69007800.0   \n",
              "972  2022-12-28  125.847855  129.669998  125.870003  131.029999  85438400.0   \n",
              "973  2022-12-29  129.412415  127.989998  127.730003  130.479996  75703700.0   \n",
              "\n",
              "     y_actual       evm   force_index        rsi  ...  Operating Cash Flow  \\\n",
              "969       0.0 -5.483888 -1.211086e+09  36.101057  ...          122151000.0   \n",
              "970       0.0 -6.731920 -9.411091e+08  35.694640  ...          122151000.0   \n",
              "971       0.0 -4.783137 -8.874656e+08  33.675324  ...          122151000.0   \n",
              "972       1.0 -4.469965 -1.271092e+09  29.726630  ...          122151000.0   \n",
              "973       1.0 -4.473906 -9.856706e+08  36.860470  ...          122151000.0   \n",
              "\n",
              "     Investing Cash Flow  Financing Cash Flow  Free Cash Flow  Total Assets  \\\n",
              "969          -22354000.0         -110749000.0     111443000.0   352755000.0   \n",
              "970          -22354000.0         -110749000.0     111443000.0   352755000.0   \n",
              "971          -22354000.0         -110749000.0     111443000.0   352755000.0   \n",
              "972          -22354000.0         -110749000.0     111443000.0   352755000.0   \n",
              "973          -22354000.0         -110749000.0     111443000.0   352755000.0   \n",
              "\n",
              "     Total Liabilities Net Minority Interest  \\\n",
              "969                              302083000.0   \n",
              "970                              302083000.0   \n",
              "971                              302083000.0   \n",
              "972                              302083000.0   \n",
              "973                              302083000.0   \n",
              "\n",
              "     Total Equity Gross Minority Interest  Total Capitalization  \\\n",
              "969                            50672000.0           149631000.0   \n",
              "970                            50672000.0           149631000.0   \n",
              "971                            50672000.0           149631000.0   \n",
              "972                            50672000.0           149631000.0   \n",
              "973                            50672000.0           149631000.0   \n",
              "\n",
              "                                               summary  \\\n",
              "969  crypto winter damn bitcoin ethereum investor s...   \n",
              "970  dec reuter appl inc aapl appl watch electrocar...   \n",
              "971  last month insid transact gn store nordin fact...   \n",
              "972  appl expect launch buy pay later servic call a...   \n",
              "973  led tech investor much cautiou opt make switch...   \n",
              "\n",
              "                                                 title  \n",
              "969  bitcoin interest surg crypto winter arriv morn...  \n",
              "970  appl watch violat alivecor patent import ban h...  \n",
              "971  merri christma us appleinsid appleinsid best a...  \n",
              "972  catalyst appl stock first major new product be...  \n",
              "973  netflix lead faang higher could fail thestreet...  \n",
              "\n",
              "[5 rows x 29 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-774f3dd2-97b8-4e10-be00-9fdaacb52e48\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>close</th>\n",
              "      <th>open</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "      <th>y_actual</th>\n",
              "      <th>evm</th>\n",
              "      <th>force_index</th>\n",
              "      <th>rsi</th>\n",
              "      <th>...</th>\n",
              "      <th>Operating Cash Flow</th>\n",
              "      <th>Investing Cash Flow</th>\n",
              "      <th>Financing Cash Flow</th>\n",
              "      <th>Free Cash Flow</th>\n",
              "      <th>Total Assets</th>\n",
              "      <th>Total Liabilities Net Minority Interest</th>\n",
              "      <th>Total Equity Gross Minority Interest</th>\n",
              "      <th>Total Capitalization</th>\n",
              "      <th>summary</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>969</th>\n",
              "      <td>2022-12-22</td>\n",
              "      <td>132.028412</td>\n",
              "      <td>134.350006</td>\n",
              "      <td>130.300003</td>\n",
              "      <td>134.559998</td>\n",
              "      <td>77852100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-5.483888</td>\n",
              "      <td>-1.211086e+09</td>\n",
              "      <td>36.101057</td>\n",
              "      <td>...</td>\n",
              "      <td>122151000.0</td>\n",
              "      <td>-22354000.0</td>\n",
              "      <td>-110749000.0</td>\n",
              "      <td>111443000.0</td>\n",
              "      <td>352755000.0</td>\n",
              "      <td>302083000.0</td>\n",
              "      <td>50672000.0</td>\n",
              "      <td>149631000.0</td>\n",
              "      <td>crypto winter damn bitcoin ethereum investor s...</td>\n",
              "      <td>bitcoin interest surg crypto winter arriv morn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>970</th>\n",
              "      <td>2022-12-23</td>\n",
              "      <td>131.658981</td>\n",
              "      <td>130.919998</td>\n",
              "      <td>129.639999</td>\n",
              "      <td>132.419998</td>\n",
              "      <td>63814900.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-6.731920</td>\n",
              "      <td>-9.411091e+08</td>\n",
              "      <td>35.694640</td>\n",
              "      <td>...</td>\n",
              "      <td>122151000.0</td>\n",
              "      <td>-22354000.0</td>\n",
              "      <td>-110749000.0</td>\n",
              "      <td>111443000.0</td>\n",
              "      <td>352755000.0</td>\n",
              "      <td>302083000.0</td>\n",
              "      <td>50672000.0</td>\n",
              "      <td>149631000.0</td>\n",
              "      <td>dec reuter appl inc aapl appl watch electrocar...</td>\n",
              "      <td>appl watch violat alivecor patent import ban h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>971</th>\n",
              "      <td>2022-12-27</td>\n",
              "      <td>129.831772</td>\n",
              "      <td>131.380005</td>\n",
              "      <td>128.720001</td>\n",
              "      <td>131.410004</td>\n",
              "      <td>69007800.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-4.783137</td>\n",
              "      <td>-8.874656e+08</td>\n",
              "      <td>33.675324</td>\n",
              "      <td>...</td>\n",
              "      <td>122151000.0</td>\n",
              "      <td>-22354000.0</td>\n",
              "      <td>-110749000.0</td>\n",
              "      <td>111443000.0</td>\n",
              "      <td>352755000.0</td>\n",
              "      <td>302083000.0</td>\n",
              "      <td>50672000.0</td>\n",
              "      <td>149631000.0</td>\n",
              "      <td>last month insid transact gn store nordin fact...</td>\n",
              "      <td>merri christma us appleinsid appleinsid best a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>972</th>\n",
              "      <td>2022-12-28</td>\n",
              "      <td>125.847855</td>\n",
              "      <td>129.669998</td>\n",
              "      <td>125.870003</td>\n",
              "      <td>131.029999</td>\n",
              "      <td>85438400.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-4.469965</td>\n",
              "      <td>-1.271092e+09</td>\n",
              "      <td>29.726630</td>\n",
              "      <td>...</td>\n",
              "      <td>122151000.0</td>\n",
              "      <td>-22354000.0</td>\n",
              "      <td>-110749000.0</td>\n",
              "      <td>111443000.0</td>\n",
              "      <td>352755000.0</td>\n",
              "      <td>302083000.0</td>\n",
              "      <td>50672000.0</td>\n",
              "      <td>149631000.0</td>\n",
              "      <td>appl expect launch buy pay later servic call a...</td>\n",
              "      <td>catalyst appl stock first major new product be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>973</th>\n",
              "      <td>2022-12-29</td>\n",
              "      <td>129.412415</td>\n",
              "      <td>127.989998</td>\n",
              "      <td>127.730003</td>\n",
              "      <td>130.479996</td>\n",
              "      <td>75703700.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-4.473906</td>\n",
              "      <td>-9.856706e+08</td>\n",
              "      <td>36.860470</td>\n",
              "      <td>...</td>\n",
              "      <td>122151000.0</td>\n",
              "      <td>-22354000.0</td>\n",
              "      <td>-110749000.0</td>\n",
              "      <td>111443000.0</td>\n",
              "      <td>352755000.0</td>\n",
              "      <td>302083000.0</td>\n",
              "      <td>50672000.0</td>\n",
              "      <td>149631000.0</td>\n",
              "      <td>led tech investor much cautiou opt make switch...</td>\n",
              "      <td>netflix lead faang higher could fail thestreet...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 29 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-774f3dd2-97b8-4e10-be00-9fdaacb52e48')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-774f3dd2-97b8-4e10-be00-9fdaacb52e48 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-774f3dd2-97b8-4e10-be00-9fdaacb52e48');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRB8p-REC6h1",
        "outputId": "4fb5cdb3-3e64-4a38-b81e-aab6a6ae9cd4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['datetime', 'close', 'open', 'low', 'high', 'volume', 'y_actual', 'evm',\n",
              "       'force_index', 'rsi', 'cci', 'macd-signal', 'atr', 'vwap', 'stx_7_3',\n",
              "       'Total Revenue', 'Cost of Revenue', 'Gross Profit', 'Normalized EBITDA',\n",
              "       'Operating Cash Flow', 'Investing Cash Flow', 'Financing Cash Flow',\n",
              "       'Free Cash Flow', 'Total Assets',\n",
              "       'Total Liabilities Net Minority Interest',\n",
              "       'Total Equity Gross Minority Interest', 'Total Capitalization',\n",
              "       'summary', 'title'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0FXwYJs8DrRD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xHLd2EOiLW1w"
      },
      "outputs": [],
      "source": [
        "# n,m=df.shape#975 27\n",
        "# daily = df['close'].shift(-1)/df['close'] - 1\n",
        "# print(type(daily))\n",
        "# # daily=daily.fillna(0)\n",
        "# # print(daily.isnull().sum())\n",
        "\n",
        "# y = np.zeros(n)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(n):\n",
        "#   if daily[i] >= 0:\n",
        "#     y[i] = 1 # up\n",
        "#   else:\n",
        "#     y[i] = 0 # down\n",
        "# print(len(y))\n",
        "# y = np.insert(y, 0, 0)\n",
        "# y=y[:-1]\n",
        "# print(len(y))\n",
        "# headers = ['y_lables']\n",
        "# y_df = pd.DataFrame(y, columns=headers)\n",
        "# y_df['datetime']=df['datetime']\n",
        "# y_df.head(5)"
      ],
      "metadata": {
        "id": "RK2mrlE8vJLn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['y_actual']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPsJ-omChBfX",
        "outputId": "d0f21d12-bdf2-4eaa-8eaf-272e6a3d6507"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0.0\n",
              "1      1.0\n",
              "2      1.0\n",
              "3      1.0\n",
              "4      1.0\n",
              "      ... \n",
              "969    0.0\n",
              "970    0.0\n",
              "971    0.0\n",
              "972    1.0\n",
              "973    1.0\n",
              "Name: y_actual, Length: 974, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=df['y_actual']\n",
        "# y=np.array(y)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJmB5QuZUAp6",
        "outputId": "233f1a66-12dd-4e1b-d5e3-701a918f1724"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0.0\n",
              "1      1.0\n",
              "2      1.0\n",
              "3      1.0\n",
              "4      1.0\n",
              "      ... \n",
              "969    0.0\n",
              "970    0.0\n",
              "971    0.0\n",
              "972    1.0\n",
              "973    1.0\n",
              "Name: y_actual, Length: 974, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "45FkDZbtiKck"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_names=[\"y_actual\"]\n",
        "\n",
        "# Create DataFrame by assigning column names\n",
        "y_df=pd.DataFrame(y, columns=column_names)"
      ],
      "metadata": {
        "id": "pvIOAG_6iKhG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "7hi11XBciKle",
        "outputId": "a3290981-e5de-4ac2-c185-8a5d19388359"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     y_actual\n",
              "0         0.0\n",
              "1         1.0\n",
              "2         1.0\n",
              "3         1.0\n",
              "4         1.0\n",
              "..        ...\n",
              "969       0.0\n",
              "970       0.0\n",
              "971       0.0\n",
              "972       1.0\n",
              "973       1.0\n",
              "\n",
              "[974 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-77ad3da6-c3d8-4cec-b634-33d1d13e2d11\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>969</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>970</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>971</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>972</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>973</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>974 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77ad3da6-c3d8-4cec-b634-33d1d13e2d11')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-77ad3da6-c3d8-4cec-b634-33d1d13e2d11 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-77ad3da6-c3d8-4cec-b634-33d1d13e2d11');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# headers = ['y_lables']\n",
        "# y_df = pd.DataFrame(y, columns=headers)\n",
        "y_df['datetime']=df['datetime']"
      ],
      "metadata": {
        "id": "hZqcYIGmhI35"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kDONl4yIUDkG",
        "outputId": "3b7fced2-9240-4834-b857-1ce290a3dbc4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   y_actual    datetime\n",
              "0       0.0  2019-02-20\n",
              "1       1.0  2019-02-21\n",
              "2       1.0  2019-02-22\n",
              "3       1.0  2019-02-25\n",
              "4       1.0  2019-02-26"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-18d9a6b4-5ba6-4e1b-9b0a-bac7e188d3f5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_actual</th>\n",
              "      <th>datetime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2019-02-20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2019-02-21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2019-02-22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2019-02-25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2019-02-26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18d9a6b4-5ba6-4e1b-9b0a-bac7e188d3f5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-18d9a6b4-5ba6-4e1b-9b0a-bac7e188d3f5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-18d9a6b4-5ba6-4e1b-9b0a-bac7e188d3f5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-3tTSWKUDnM",
        "outputId": "58931451-34fe-4604-98f5-23b5c1e9e498"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(974, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_df.tail(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8CnRooM4uy_Q",
        "outputId": "86303606-6d97-4915-e6e8-9ed7d8e6eebb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     y_actual    datetime\n",
              "969       0.0  2022-12-22\n",
              "970       0.0  2022-12-23\n",
              "971       0.0  2022-12-27\n",
              "972       1.0  2022-12-28\n",
              "973       1.0  2022-12-29"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c72533a-9356-4214-b3d8-35a681760551\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_actual</th>\n",
              "      <th>datetime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>969</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2022-12-22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>970</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2022-12-23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>971</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2022-12-27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>972</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2022-12-28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>973</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2022-12-29</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c72533a-9356-4214-b3d8-35a681760551')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6c72533a-9356-4214-b3d8-35a681760551 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6c72533a-9356-4214-b3d8-35a681760551');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "LzuRcgFHBo5d"
      },
      "outputs": [],
      "source": [
        "# df_title=df[['datetime','title']]\n",
        "df=df.drop(['datetime','title','summary','y_actual'],axis='columns')#dropping the date column\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "jEJ-9yxrgKlU"
      },
      "outputs": [],
      "source": [
        "scalar = StandardScaler()\n",
        "scaled_df = scalar.fit_transform(df) #scaling the csv data\n",
        "\n",
        "df=scaled_df\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBrdD6PQLqEd",
        "outputId": "cfb49536-f27e-48bb-bfea-926ef0e8e1c5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(974, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "U1OkQmI7NkiC"
      },
      "outputs": [],
      "source": [
        "\n",
        "text_vector=[]# will contain vector representation of titleColumn\n",
        "summary_vector=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "EZJlRFCBNJes"
      },
      "outputs": [],
      "source": [
        "for text in titleColumn:\n",
        "    sentence = text\n",
        "    message_embeddings = embed([sentence])\n",
        "    temp=np.array(message_embeddings[0])\n",
        "    temp=temp.T\n",
        "    text_vector.append(temp)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for summary in summaryColumn:\n",
        "    sentence = summary\n",
        "    message_embeddings = embed([sentence])\n",
        "    temp=np.array(message_embeddings[0])\n",
        "    temp=temp.T\n",
        "    summary_vector.append(temp)"
      ],
      "metadata": {
        "id": "uwaE5gKhU30C"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "LO3jjvT5O0QL"
      },
      "outputs": [],
      "source": [
        "text_vector=np.array(text_vector)\n",
        "summary_vector=np.array(summary_vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "O6mJCluaO3Dn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7214c23-ccdd-449f-d49c-f8785f1cf3a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(974, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "text_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary_vector.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bvgHNE8VKOf",
        "outputId": "26b89aa0-0bef-4bc3-d99a-fce0558a7b7e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(974, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "s5nMVv2APVh3"
      },
      "outputs": [],
      "source": [
        "\n",
        "scalar = StandardScaler()\n",
        "scaled_data_text = scalar.fit_transform(text_vector) #scaling the data\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scalar = StandardScaler()\n",
        "scaled_data_summary = scalar.fit_transform(summary_vector) #scaling the data"
      ],
      "metadata": {
        "id": "ervcS6WWVdO4"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "YI78ecE_PVqj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a43c57f6-dc75-410e-cebe-6a5b986e383a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[22.654774  , 19.68477   ,  7.1595306 , ..., -4.726308  ,\n",
              "         3.2850368 ,  5.298541  ],\n",
              "       [ 1.5638537 , -3.473331  , -3.7826233 , ..., -1.0812197 ,\n",
              "         2.0129745 ,  2.057868  ],\n",
              "       [-9.1792965 ,  2.8117106 , -5.913816  , ..., -0.32488275,\n",
              "         0.07076359,  2.414145  ],\n",
              "       ...,\n",
              "       [19.57706   , 10.722677  ,  2.962521  , ...,  1.948776  ,\n",
              "         0.68935764, -1.544311  ],\n",
              "       [ 1.831466  , -7.1388097 ,  5.7734194 , ...,  1.9756095 ,\n",
              "         0.7724328 , -2.2311869 ],\n",
              "       [ 5.774376  , -9.416828  ,  3.0518963 , ...,  0.85809696,\n",
              "         2.263319  , -1.5072662 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "pca = PCA(n_components = 25)\n",
        "pca.fit(scaled_data_text)\n",
        "data_pca_text = pca.transform(scaled_data_text)\n",
        "data_pca_text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components = 25)\n",
        "pca.fit(scaled_data_summary)\n",
        "data_pca_summary = pca.transform(scaled_data_summary)\n",
        "data_pca_summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltACpm1rVoJs",
        "outputId": "40225881-c57b-46ce-8a57-c44b34df02e5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-4.0974379e+00, -5.0511160e+00,  9.2467270e+00, ...,\n",
              "        -1.3215301e+00,  4.4715166e-02,  1.3527788e+00],\n",
              "       [-6.0066757e+00, -4.6314211e+00,  6.6807365e+00, ...,\n",
              "        -5.2633393e-01, -1.1545998e-01, -1.4741814e+00],\n",
              "       [-6.4462938e+00, -1.5700805e+00, -1.1642354e+00, ...,\n",
              "         5.6907296e-01,  2.6742041e-01,  5.7089001e-02],\n",
              "       ...,\n",
              "       [-5.8146448e+00, -1.9808619e+00,  3.5983148e-01, ...,\n",
              "        -1.6400170e+00, -7.3881727e-01,  8.4864616e-01],\n",
              "       [-6.6958251e+00, -3.6016133e+00,  2.8661485e+00, ...,\n",
              "         1.9204798e-01,  3.9414695e-01,  1.8608484e-02],\n",
              "       [-6.6291943e+00, -2.8937340e+00,  1.3680781e+00, ...,\n",
              "         1.1837969e+00, -4.4012964e-03, -9.8158485e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Aw0__yWZPzn2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c5be99c-6134-433e-b914-b208a367db6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(974, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "data_pca_text.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_pca_summary.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_HH5thXV9Ob",
        "outputId": "48ad1f88-d0a3-42eb-948d-d649eb030a55"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(974, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "HOyASLNYQYNd"
      },
      "outputs": [],
      "source": [
        "# text_vector_dataframe=pd.DataFrame()\n",
        "type(data_pca_text)\n",
        "# df_news  =pd.DataFrame(((x,) for x in data_pca), columns=['title'])\n",
        "mycolumns=['pca1','pca2','pca3','pca4','pca5','pca6','pca7','pca8','pca9','pca10','pca11','pca12','pca13','pca14','pca15','pca16','pca17','pca18','pca19','pca20','pca21','pca22','pca23','pca24','pca25']\n",
        "df_news_text=pd.DataFrame(data_pca_text, columns = mycolumns)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# text_vector_dataframe=pd.DataFrame()\n",
        "type(data_pca_summary)\n",
        "# df_news  =pd.DataFrame(((x,) for x in data_pca), columns=['title'])\n",
        "mycolumns=['Spca1','Spca2','Spca3','Spca4','Spca5','Spca6','Spca7','Spca8','Spca9','Spca10','Spca11','Spca12','Spca13','Spca14','Spca15','Spca16','Spca17','Spca18','Spca19','Spca20','Spca21','Spca22','Spca23','Spca24','Spca25']\n",
        "df_news_summary=pd.DataFrame(data_pca_summary, columns = mycolumns)"
      ],
      "metadata": {
        "id": "LtHzY1I5WeBS"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_news_text"
      ],
      "metadata": {
        "id": "AYImrFzORb8M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "89f8e3ba-f11d-4ca0-a3d2-fd2b321fc30b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          pca1       pca2      pca3      pca4      pca5       pca6      pca7  \\\n",
              "0    22.654774  19.684771  7.159531  3.603495 -6.838140  10.428587 -3.448949   \n",
              "1     1.563854  -3.473331 -3.782623 -2.508502 -4.720814   1.674747 -4.951632   \n",
              "2    -9.179296   2.811711 -5.913816  2.304858 -0.152320   1.853811  5.503058   \n",
              "3     9.169606  -2.382734 -1.226832 -3.851335 -2.208233  -3.531028  2.682847   \n",
              "4     0.687009  -3.714859 -5.819294 -0.615771 -4.170208  -0.667097  0.414284   \n",
              "..         ...        ...       ...       ...       ...        ...       ...   \n",
              "969   1.655340  -8.504667  4.405375 -0.847841 -0.786364   0.302262 -0.735276   \n",
              "970   7.225430  -8.447567  0.959062 -1.203224  1.661753   3.582793  0.565506   \n",
              "971  19.577061  10.722677  2.962521  0.333361 -1.239834  -0.534513  1.546886   \n",
              "972   1.831466  -7.138810  5.773419  0.343198  0.622320   5.114515  0.933785   \n",
              "973   5.774376  -9.416828  3.051896 -2.245615  2.824078   5.808450 -1.226643   \n",
              "\n",
              "         pca8      pca9     pca10  ...     pca16     pca17     pca18  \\\n",
              "0    6.120075 -1.294774  3.576098  ... -5.884901  7.498806  6.223081   \n",
              "1    1.372158  0.562664 -2.432447  ...  2.336582  1.624870 -3.441215   \n",
              "2   -3.226789 -0.228151 -2.627688  ...  1.694156  4.000993 -3.171506   \n",
              "3    2.726148 -1.379948 -1.851651  ... -0.456782  2.354859 -0.507906   \n",
              "4   -0.899177  2.319784  1.319087  ... -0.003716  4.049840 -2.685757   \n",
              "..        ...       ...       ...  ...       ...       ...       ...   \n",
              "969  0.922597  2.524419 -1.151824  ... -1.274392  0.681736 -0.204180   \n",
              "970 -1.327860  1.392817  0.685632  ...  1.539603  0.964195 -0.464519   \n",
              "971 -3.370409 -0.934301 -0.480977  ...  2.078183 -3.787397 -0.221134   \n",
              "972 -2.884283 -0.926939 -0.179519  ...  3.556339  2.177893  0.769836   \n",
              "973  1.554699  2.275150  1.608927  ... -0.010354  0.042172  0.167044   \n",
              "\n",
              "        pca19     pca20     pca21     pca22     pca23     pca24     pca25  \n",
              "0   -0.133425 -4.311012 -2.451073  9.751688 -4.726308  3.285037  5.298541  \n",
              "1    2.344890 -0.679703  2.300196  3.617532 -1.081220  2.012975  2.057868  \n",
              "2    2.159171  0.398422 -0.849247 -1.344516 -0.324883  0.070764  2.414145  \n",
              "3    0.181548  1.894903 -0.502952 -1.094769 -4.337394  0.208617  2.613868  \n",
              "4   -0.060991 -2.502755  0.822862  1.103148 -0.816562  1.442738  1.051238  \n",
              "..        ...       ...       ...       ...       ...       ...       ...  \n",
              "969  0.265542 -0.919507 -1.737674  0.853302 -0.736642 -0.459571 -0.771534  \n",
              "970  1.898905 -1.834263 -1.860763  0.770940  0.618487  1.777401 -0.459317  \n",
              "971  0.543944 -0.113350  0.515963 -1.029364  1.948776  0.689358 -1.544311  \n",
              "972  0.450071  0.577868 -0.536674 -0.230359  1.975610  0.772433 -2.231187  \n",
              "973 -0.405059 -1.033929 -1.970254 -1.082098  0.858097  2.263319 -1.507266  \n",
              "\n",
              "[974 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0b6e9cec-22f3-402d-9a95-d15cef898ad9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pca1</th>\n",
              "      <th>pca2</th>\n",
              "      <th>pca3</th>\n",
              "      <th>pca4</th>\n",
              "      <th>pca5</th>\n",
              "      <th>pca6</th>\n",
              "      <th>pca7</th>\n",
              "      <th>pca8</th>\n",
              "      <th>pca9</th>\n",
              "      <th>pca10</th>\n",
              "      <th>...</th>\n",
              "      <th>pca16</th>\n",
              "      <th>pca17</th>\n",
              "      <th>pca18</th>\n",
              "      <th>pca19</th>\n",
              "      <th>pca20</th>\n",
              "      <th>pca21</th>\n",
              "      <th>pca22</th>\n",
              "      <th>pca23</th>\n",
              "      <th>pca24</th>\n",
              "      <th>pca25</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22.654774</td>\n",
              "      <td>19.684771</td>\n",
              "      <td>7.159531</td>\n",
              "      <td>3.603495</td>\n",
              "      <td>-6.838140</td>\n",
              "      <td>10.428587</td>\n",
              "      <td>-3.448949</td>\n",
              "      <td>6.120075</td>\n",
              "      <td>-1.294774</td>\n",
              "      <td>3.576098</td>\n",
              "      <td>...</td>\n",
              "      <td>-5.884901</td>\n",
              "      <td>7.498806</td>\n",
              "      <td>6.223081</td>\n",
              "      <td>-0.133425</td>\n",
              "      <td>-4.311012</td>\n",
              "      <td>-2.451073</td>\n",
              "      <td>9.751688</td>\n",
              "      <td>-4.726308</td>\n",
              "      <td>3.285037</td>\n",
              "      <td>5.298541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.563854</td>\n",
              "      <td>-3.473331</td>\n",
              "      <td>-3.782623</td>\n",
              "      <td>-2.508502</td>\n",
              "      <td>-4.720814</td>\n",
              "      <td>1.674747</td>\n",
              "      <td>-4.951632</td>\n",
              "      <td>1.372158</td>\n",
              "      <td>0.562664</td>\n",
              "      <td>-2.432447</td>\n",
              "      <td>...</td>\n",
              "      <td>2.336582</td>\n",
              "      <td>1.624870</td>\n",
              "      <td>-3.441215</td>\n",
              "      <td>2.344890</td>\n",
              "      <td>-0.679703</td>\n",
              "      <td>2.300196</td>\n",
              "      <td>3.617532</td>\n",
              "      <td>-1.081220</td>\n",
              "      <td>2.012975</td>\n",
              "      <td>2.057868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-9.179296</td>\n",
              "      <td>2.811711</td>\n",
              "      <td>-5.913816</td>\n",
              "      <td>2.304858</td>\n",
              "      <td>-0.152320</td>\n",
              "      <td>1.853811</td>\n",
              "      <td>5.503058</td>\n",
              "      <td>-3.226789</td>\n",
              "      <td>-0.228151</td>\n",
              "      <td>-2.627688</td>\n",
              "      <td>...</td>\n",
              "      <td>1.694156</td>\n",
              "      <td>4.000993</td>\n",
              "      <td>-3.171506</td>\n",
              "      <td>2.159171</td>\n",
              "      <td>0.398422</td>\n",
              "      <td>-0.849247</td>\n",
              "      <td>-1.344516</td>\n",
              "      <td>-0.324883</td>\n",
              "      <td>0.070764</td>\n",
              "      <td>2.414145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9.169606</td>\n",
              "      <td>-2.382734</td>\n",
              "      <td>-1.226832</td>\n",
              "      <td>-3.851335</td>\n",
              "      <td>-2.208233</td>\n",
              "      <td>-3.531028</td>\n",
              "      <td>2.682847</td>\n",
              "      <td>2.726148</td>\n",
              "      <td>-1.379948</td>\n",
              "      <td>-1.851651</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.456782</td>\n",
              "      <td>2.354859</td>\n",
              "      <td>-0.507906</td>\n",
              "      <td>0.181548</td>\n",
              "      <td>1.894903</td>\n",
              "      <td>-0.502952</td>\n",
              "      <td>-1.094769</td>\n",
              "      <td>-4.337394</td>\n",
              "      <td>0.208617</td>\n",
              "      <td>2.613868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.687009</td>\n",
              "      <td>-3.714859</td>\n",
              "      <td>-5.819294</td>\n",
              "      <td>-0.615771</td>\n",
              "      <td>-4.170208</td>\n",
              "      <td>-0.667097</td>\n",
              "      <td>0.414284</td>\n",
              "      <td>-0.899177</td>\n",
              "      <td>2.319784</td>\n",
              "      <td>1.319087</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003716</td>\n",
              "      <td>4.049840</td>\n",
              "      <td>-2.685757</td>\n",
              "      <td>-0.060991</td>\n",
              "      <td>-2.502755</td>\n",
              "      <td>0.822862</td>\n",
              "      <td>1.103148</td>\n",
              "      <td>-0.816562</td>\n",
              "      <td>1.442738</td>\n",
              "      <td>1.051238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>969</th>\n",
              "      <td>1.655340</td>\n",
              "      <td>-8.504667</td>\n",
              "      <td>4.405375</td>\n",
              "      <td>-0.847841</td>\n",
              "      <td>-0.786364</td>\n",
              "      <td>0.302262</td>\n",
              "      <td>-0.735276</td>\n",
              "      <td>0.922597</td>\n",
              "      <td>2.524419</td>\n",
              "      <td>-1.151824</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.274392</td>\n",
              "      <td>0.681736</td>\n",
              "      <td>-0.204180</td>\n",
              "      <td>0.265542</td>\n",
              "      <td>-0.919507</td>\n",
              "      <td>-1.737674</td>\n",
              "      <td>0.853302</td>\n",
              "      <td>-0.736642</td>\n",
              "      <td>-0.459571</td>\n",
              "      <td>-0.771534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>970</th>\n",
              "      <td>7.225430</td>\n",
              "      <td>-8.447567</td>\n",
              "      <td>0.959062</td>\n",
              "      <td>-1.203224</td>\n",
              "      <td>1.661753</td>\n",
              "      <td>3.582793</td>\n",
              "      <td>0.565506</td>\n",
              "      <td>-1.327860</td>\n",
              "      <td>1.392817</td>\n",
              "      <td>0.685632</td>\n",
              "      <td>...</td>\n",
              "      <td>1.539603</td>\n",
              "      <td>0.964195</td>\n",
              "      <td>-0.464519</td>\n",
              "      <td>1.898905</td>\n",
              "      <td>-1.834263</td>\n",
              "      <td>-1.860763</td>\n",
              "      <td>0.770940</td>\n",
              "      <td>0.618487</td>\n",
              "      <td>1.777401</td>\n",
              "      <td>-0.459317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>971</th>\n",
              "      <td>19.577061</td>\n",
              "      <td>10.722677</td>\n",
              "      <td>2.962521</td>\n",
              "      <td>0.333361</td>\n",
              "      <td>-1.239834</td>\n",
              "      <td>-0.534513</td>\n",
              "      <td>1.546886</td>\n",
              "      <td>-3.370409</td>\n",
              "      <td>-0.934301</td>\n",
              "      <td>-0.480977</td>\n",
              "      <td>...</td>\n",
              "      <td>2.078183</td>\n",
              "      <td>-3.787397</td>\n",
              "      <td>-0.221134</td>\n",
              "      <td>0.543944</td>\n",
              "      <td>-0.113350</td>\n",
              "      <td>0.515963</td>\n",
              "      <td>-1.029364</td>\n",
              "      <td>1.948776</td>\n",
              "      <td>0.689358</td>\n",
              "      <td>-1.544311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>972</th>\n",
              "      <td>1.831466</td>\n",
              "      <td>-7.138810</td>\n",
              "      <td>5.773419</td>\n",
              "      <td>0.343198</td>\n",
              "      <td>0.622320</td>\n",
              "      <td>5.114515</td>\n",
              "      <td>0.933785</td>\n",
              "      <td>-2.884283</td>\n",
              "      <td>-0.926939</td>\n",
              "      <td>-0.179519</td>\n",
              "      <td>...</td>\n",
              "      <td>3.556339</td>\n",
              "      <td>2.177893</td>\n",
              "      <td>0.769836</td>\n",
              "      <td>0.450071</td>\n",
              "      <td>0.577868</td>\n",
              "      <td>-0.536674</td>\n",
              "      <td>-0.230359</td>\n",
              "      <td>1.975610</td>\n",
              "      <td>0.772433</td>\n",
              "      <td>-2.231187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>973</th>\n",
              "      <td>5.774376</td>\n",
              "      <td>-9.416828</td>\n",
              "      <td>3.051896</td>\n",
              "      <td>-2.245615</td>\n",
              "      <td>2.824078</td>\n",
              "      <td>5.808450</td>\n",
              "      <td>-1.226643</td>\n",
              "      <td>1.554699</td>\n",
              "      <td>2.275150</td>\n",
              "      <td>1.608927</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.010354</td>\n",
              "      <td>0.042172</td>\n",
              "      <td>0.167044</td>\n",
              "      <td>-0.405059</td>\n",
              "      <td>-1.033929</td>\n",
              "      <td>-1.970254</td>\n",
              "      <td>-1.082098</td>\n",
              "      <td>0.858097</td>\n",
              "      <td>2.263319</td>\n",
              "      <td>-1.507266</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>974 rows × 25 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b6e9cec-22f3-402d-9a95-d15cef898ad9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0b6e9cec-22f3-402d-9a95-d15cef898ad9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0b6e9cec-22f3-402d-9a95-d15cef898ad9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_news_summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "Car6jPEQYwG4",
        "outputId": "e6bbe364-436a-41f7-940e-fd31fdd5ed37"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Spca1     Spca2     Spca3     Spca4     Spca5     Spca6     Spca7  \\\n",
              "0   -4.097438 -5.051116  9.246727 -3.664545  4.503671  3.414853 -2.192408   \n",
              "1   -6.006676 -4.631421  6.680737 -1.282974  1.987336 -0.930859  1.333789   \n",
              "2   -6.446294 -1.570081 -1.164235  1.155925 -2.105601  1.013681  1.973031   \n",
              "3   -6.669613 -3.886621  3.157756 -0.066977 -0.683434 -0.402385  1.849448   \n",
              "4   -6.065101 -4.833769  4.544207 -0.517819  2.771022 -1.551171 -1.458420   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "969 -5.741839  1.578586 -4.794973  1.394566 -1.604301 -0.661164  2.360312   \n",
              "970 -5.849784 -5.012734  6.648133 -1.643568  4.144670  0.928861 -1.634946   \n",
              "971 -5.814645 -1.980862  0.359831  0.751724 -2.832372 -0.580992  1.352487   \n",
              "972 -6.695825 -3.601613  2.866148 -0.293933 -1.249721  0.684557  0.608598   \n",
              "973 -6.629194 -2.893734  1.368078  1.369865 -1.929313 -2.572479  0.640532   \n",
              "\n",
              "        Spca8     Spca9    Spca10  ...    Spca16    Spca17    Spca18  \\\n",
              "0   -0.816809 -0.655531 -0.113480  ...  1.818383 -0.914117 -2.074325   \n",
              "1    0.147976 -0.838744  2.233258  ...  1.650529 -0.181376  0.587466   \n",
              "2   -0.653831 -0.393226 -2.480187  ... -0.941116  0.429186 -1.367047   \n",
              "3   -0.358618 -0.574249 -0.090964  ...  0.295991 -0.981859  0.993470   \n",
              "4   -0.127880 -0.668664  0.083365  ...  1.060050  0.447202 -2.514552   \n",
              "..        ...       ...       ...  ...       ...       ...       ...   \n",
              "969  0.755894 -1.045721  1.970019  ...  1.727583  2.827416  1.035260   \n",
              "970 -0.966670 -0.288928 -0.395151  ...  2.306204 -2.243432 -0.066597   \n",
              "971  1.028613  2.240692  0.896156  ...  0.873453 -2.523095 -0.288524   \n",
              "972 -0.053866  2.054352 -0.328348  ...  0.050719 -2.594426  0.332053   \n",
              "973  0.543223  0.398193  1.050784  ... -0.774901 -0.598481  1.938935   \n",
              "\n",
              "       Spca19    Spca20    Spca21    Spca22    Spca23    Spca24    Spca25  \n",
              "0    0.913988  0.112712  1.926086  0.260297 -1.321530  0.044715  1.352779  \n",
              "1   -1.511634  1.054598 -1.483433 -1.453117 -0.526334 -0.115460 -1.474181  \n",
              "2    0.464688 -0.060432  0.348901  0.847478  0.569073  0.267420  0.057089  \n",
              "3   -1.462695 -0.706416 -0.579468  0.472940  0.470021  0.762850 -1.404587  \n",
              "4    2.650107 -2.557092 -0.502712  2.301711  0.643496 -0.231621 -0.870302  \n",
              "..        ...       ...       ...       ...       ...       ...       ...  \n",
              "969 -1.005180 -0.452188  1.798969 -0.634948 -1.344085 -0.228949 -2.238541  \n",
              "970  1.084826 -2.327940 -1.495850  0.988852 -0.155374  0.065605  1.730080  \n",
              "971 -1.318568  0.659262 -0.309576  1.374979 -1.640017 -0.738817  0.848646  \n",
              "972 -0.011782 -1.045049 -0.123244  2.000252  0.192048  0.394147  0.018608  \n",
              "973 -2.207575 -0.223497 -0.409510 -0.086743  1.183797 -0.004401 -0.981585  \n",
              "\n",
              "[974 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b8b5e049-e629-4d88-b42d-946abea31879\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Spca1</th>\n",
              "      <th>Spca2</th>\n",
              "      <th>Spca3</th>\n",
              "      <th>Spca4</th>\n",
              "      <th>Spca5</th>\n",
              "      <th>Spca6</th>\n",
              "      <th>Spca7</th>\n",
              "      <th>Spca8</th>\n",
              "      <th>Spca9</th>\n",
              "      <th>Spca10</th>\n",
              "      <th>...</th>\n",
              "      <th>Spca16</th>\n",
              "      <th>Spca17</th>\n",
              "      <th>Spca18</th>\n",
              "      <th>Spca19</th>\n",
              "      <th>Spca20</th>\n",
              "      <th>Spca21</th>\n",
              "      <th>Spca22</th>\n",
              "      <th>Spca23</th>\n",
              "      <th>Spca24</th>\n",
              "      <th>Spca25</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-4.097438</td>\n",
              "      <td>-5.051116</td>\n",
              "      <td>9.246727</td>\n",
              "      <td>-3.664545</td>\n",
              "      <td>4.503671</td>\n",
              "      <td>3.414853</td>\n",
              "      <td>-2.192408</td>\n",
              "      <td>-0.816809</td>\n",
              "      <td>-0.655531</td>\n",
              "      <td>-0.113480</td>\n",
              "      <td>...</td>\n",
              "      <td>1.818383</td>\n",
              "      <td>-0.914117</td>\n",
              "      <td>-2.074325</td>\n",
              "      <td>0.913988</td>\n",
              "      <td>0.112712</td>\n",
              "      <td>1.926086</td>\n",
              "      <td>0.260297</td>\n",
              "      <td>-1.321530</td>\n",
              "      <td>0.044715</td>\n",
              "      <td>1.352779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-6.006676</td>\n",
              "      <td>-4.631421</td>\n",
              "      <td>6.680737</td>\n",
              "      <td>-1.282974</td>\n",
              "      <td>1.987336</td>\n",
              "      <td>-0.930859</td>\n",
              "      <td>1.333789</td>\n",
              "      <td>0.147976</td>\n",
              "      <td>-0.838744</td>\n",
              "      <td>2.233258</td>\n",
              "      <td>...</td>\n",
              "      <td>1.650529</td>\n",
              "      <td>-0.181376</td>\n",
              "      <td>0.587466</td>\n",
              "      <td>-1.511634</td>\n",
              "      <td>1.054598</td>\n",
              "      <td>-1.483433</td>\n",
              "      <td>-1.453117</td>\n",
              "      <td>-0.526334</td>\n",
              "      <td>-0.115460</td>\n",
              "      <td>-1.474181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-6.446294</td>\n",
              "      <td>-1.570081</td>\n",
              "      <td>-1.164235</td>\n",
              "      <td>1.155925</td>\n",
              "      <td>-2.105601</td>\n",
              "      <td>1.013681</td>\n",
              "      <td>1.973031</td>\n",
              "      <td>-0.653831</td>\n",
              "      <td>-0.393226</td>\n",
              "      <td>-2.480187</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.941116</td>\n",
              "      <td>0.429186</td>\n",
              "      <td>-1.367047</td>\n",
              "      <td>0.464688</td>\n",
              "      <td>-0.060432</td>\n",
              "      <td>0.348901</td>\n",
              "      <td>0.847478</td>\n",
              "      <td>0.569073</td>\n",
              "      <td>0.267420</td>\n",
              "      <td>0.057089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-6.669613</td>\n",
              "      <td>-3.886621</td>\n",
              "      <td>3.157756</td>\n",
              "      <td>-0.066977</td>\n",
              "      <td>-0.683434</td>\n",
              "      <td>-0.402385</td>\n",
              "      <td>1.849448</td>\n",
              "      <td>-0.358618</td>\n",
              "      <td>-0.574249</td>\n",
              "      <td>-0.090964</td>\n",
              "      <td>...</td>\n",
              "      <td>0.295991</td>\n",
              "      <td>-0.981859</td>\n",
              "      <td>0.993470</td>\n",
              "      <td>-1.462695</td>\n",
              "      <td>-0.706416</td>\n",
              "      <td>-0.579468</td>\n",
              "      <td>0.472940</td>\n",
              "      <td>0.470021</td>\n",
              "      <td>0.762850</td>\n",
              "      <td>-1.404587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-6.065101</td>\n",
              "      <td>-4.833769</td>\n",
              "      <td>4.544207</td>\n",
              "      <td>-0.517819</td>\n",
              "      <td>2.771022</td>\n",
              "      <td>-1.551171</td>\n",
              "      <td>-1.458420</td>\n",
              "      <td>-0.127880</td>\n",
              "      <td>-0.668664</td>\n",
              "      <td>0.083365</td>\n",
              "      <td>...</td>\n",
              "      <td>1.060050</td>\n",
              "      <td>0.447202</td>\n",
              "      <td>-2.514552</td>\n",
              "      <td>2.650107</td>\n",
              "      <td>-2.557092</td>\n",
              "      <td>-0.502712</td>\n",
              "      <td>2.301711</td>\n",
              "      <td>0.643496</td>\n",
              "      <td>-0.231621</td>\n",
              "      <td>-0.870302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>969</th>\n",
              "      <td>-5.741839</td>\n",
              "      <td>1.578586</td>\n",
              "      <td>-4.794973</td>\n",
              "      <td>1.394566</td>\n",
              "      <td>-1.604301</td>\n",
              "      <td>-0.661164</td>\n",
              "      <td>2.360312</td>\n",
              "      <td>0.755894</td>\n",
              "      <td>-1.045721</td>\n",
              "      <td>1.970019</td>\n",
              "      <td>...</td>\n",
              "      <td>1.727583</td>\n",
              "      <td>2.827416</td>\n",
              "      <td>1.035260</td>\n",
              "      <td>-1.005180</td>\n",
              "      <td>-0.452188</td>\n",
              "      <td>1.798969</td>\n",
              "      <td>-0.634948</td>\n",
              "      <td>-1.344085</td>\n",
              "      <td>-0.228949</td>\n",
              "      <td>-2.238541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>970</th>\n",
              "      <td>-5.849784</td>\n",
              "      <td>-5.012734</td>\n",
              "      <td>6.648133</td>\n",
              "      <td>-1.643568</td>\n",
              "      <td>4.144670</td>\n",
              "      <td>0.928861</td>\n",
              "      <td>-1.634946</td>\n",
              "      <td>-0.966670</td>\n",
              "      <td>-0.288928</td>\n",
              "      <td>-0.395151</td>\n",
              "      <td>...</td>\n",
              "      <td>2.306204</td>\n",
              "      <td>-2.243432</td>\n",
              "      <td>-0.066597</td>\n",
              "      <td>1.084826</td>\n",
              "      <td>-2.327940</td>\n",
              "      <td>-1.495850</td>\n",
              "      <td>0.988852</td>\n",
              "      <td>-0.155374</td>\n",
              "      <td>0.065605</td>\n",
              "      <td>1.730080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>971</th>\n",
              "      <td>-5.814645</td>\n",
              "      <td>-1.980862</td>\n",
              "      <td>0.359831</td>\n",
              "      <td>0.751724</td>\n",
              "      <td>-2.832372</td>\n",
              "      <td>-0.580992</td>\n",
              "      <td>1.352487</td>\n",
              "      <td>1.028613</td>\n",
              "      <td>2.240692</td>\n",
              "      <td>0.896156</td>\n",
              "      <td>...</td>\n",
              "      <td>0.873453</td>\n",
              "      <td>-2.523095</td>\n",
              "      <td>-0.288524</td>\n",
              "      <td>-1.318568</td>\n",
              "      <td>0.659262</td>\n",
              "      <td>-0.309576</td>\n",
              "      <td>1.374979</td>\n",
              "      <td>-1.640017</td>\n",
              "      <td>-0.738817</td>\n",
              "      <td>0.848646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>972</th>\n",
              "      <td>-6.695825</td>\n",
              "      <td>-3.601613</td>\n",
              "      <td>2.866148</td>\n",
              "      <td>-0.293933</td>\n",
              "      <td>-1.249721</td>\n",
              "      <td>0.684557</td>\n",
              "      <td>0.608598</td>\n",
              "      <td>-0.053866</td>\n",
              "      <td>2.054352</td>\n",
              "      <td>-0.328348</td>\n",
              "      <td>...</td>\n",
              "      <td>0.050719</td>\n",
              "      <td>-2.594426</td>\n",
              "      <td>0.332053</td>\n",
              "      <td>-0.011782</td>\n",
              "      <td>-1.045049</td>\n",
              "      <td>-0.123244</td>\n",
              "      <td>2.000252</td>\n",
              "      <td>0.192048</td>\n",
              "      <td>0.394147</td>\n",
              "      <td>0.018608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>973</th>\n",
              "      <td>-6.629194</td>\n",
              "      <td>-2.893734</td>\n",
              "      <td>1.368078</td>\n",
              "      <td>1.369865</td>\n",
              "      <td>-1.929313</td>\n",
              "      <td>-2.572479</td>\n",
              "      <td>0.640532</td>\n",
              "      <td>0.543223</td>\n",
              "      <td>0.398193</td>\n",
              "      <td>1.050784</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.774901</td>\n",
              "      <td>-0.598481</td>\n",
              "      <td>1.938935</td>\n",
              "      <td>-2.207575</td>\n",
              "      <td>-0.223497</td>\n",
              "      <td>-0.409510</td>\n",
              "      <td>-0.086743</td>\n",
              "      <td>1.183797</td>\n",
              "      <td>-0.004401</td>\n",
              "      <td>-0.981585</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>974 rows × 25 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8b5e049-e629-4d88-b42d-946abea31879')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b8b5e049-e629-4d88-b42d-946abea31879 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b8b5e049-e629-4d88-b42d-946abea31879');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df=df.drop(['y_actual'],axis='columns')"
      ],
      "metadata": {
        "id": "y8NeCuZ9eYnX"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.columns"
      ],
      "metadata": {
        "id": "aUshjtSti8IT"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "K08q3QZMRCnT"
      },
      "outputs": [],
      "source": [
        "column=['close', 'open', 'low', 'high', 'volume','evm',  'force_index', 'rsi', 'cci', 'macd-signal', 'atr', 'vwap', 'stx_7_3',\n",
        "  'Total Revenue', 'Cost of Revenue', 'Gross Profit', 'Normalized EBITDA',  'Operating Cash Flow', 'Investing Cash Flow', 'Financing Cash Flow',\n",
        "   'Free Cash Flow', 'Total Assets',  'Total Liabilities Net Minority Interest', 'Total Equity Gross Minority Interest', 'Total Capitalization']\n",
        "\n",
        "df=pd.DataFrame(df,columns=column)\n",
        "    #  'volume', 'y_actual', 'evm',\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df=df.drop(['y_actual'],axis='columns')"
      ],
      "metadata": {
        "id": "Ay3LcfVae6oM"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "id": "CmuNNp3v7SVV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "f2a968fc-41e2-4646-bcbc-c20678e4d567"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      close      open       low      high    volume       evm  force_index  \\\n",
              "0 -1.668620 -1.675547 -1.666923 -1.675847 -0.128616  0.043426     0.067413   \n",
              "1 -1.674196 -1.671910 -1.671093 -1.681444 -0.801205  0.019802    -0.019172   \n",
              "2 -1.663216 -1.673221 -1.664566 -1.677733 -0.674991  0.020294     0.017197   \n",
              "3 -1.655972 -1.657837 -1.649033 -1.660824 -0.450393  0.018294    -0.028183   \n",
              "4 -1.655397 -1.660520 -1.653747 -1.664182 -0.814824 -0.001258    -0.083315   \n",
              "\n",
              "        rsi       cci  macd-signal  ...  Gross Profit  Normalized EBITDA  \\\n",
              "0  0.500617  0.438943    -0.048217  ...     -1.120053          -1.038348   \n",
              "1  0.317097 -0.070093    -0.069058  ...     -1.120053          -1.038348   \n",
              "2  0.548031  0.423097    -0.052112  ...     -1.120053          -1.038348   \n",
              "3  0.692781  1.240594    -0.024504  ...     -1.120053          -1.038348   \n",
              "4  0.704498  0.953321    -0.013233  ...     -1.120053          -1.038348   \n",
              "\n",
              "   Operating Cash Flow  Investing Cash Flow  Financing Cash Flow  \\\n",
              "0            -1.254581             1.796214             0.499973   \n",
              "1            -1.254581             1.796214             0.499973   \n",
              "2            -1.254581             1.796214             0.499973   \n",
              "3            -1.254581             1.796214             0.499973   \n",
              "4            -1.254581             1.796214             0.499973   \n",
              "\n",
              "   Free Cash Flow  Total Assets  Total Liabilities Net Minority Interest  \\\n",
              "0       -1.329357     -0.262246                                -1.248318   \n",
              "1       -1.329357     -0.262246                                -1.248318   \n",
              "2       -1.329357     -0.262246                                -1.248318   \n",
              "3       -1.329357     -0.262246                                -1.248318   \n",
              "4       -1.329357     -0.262246                                -1.248318   \n",
              "\n",
              "   Total Equity Gross Minority Interest  Total Capitalization  \n",
              "0                              1.698495              1.335001  \n",
              "1                              1.698495              1.335001  \n",
              "2                              1.698495              1.335001  \n",
              "3                              1.698495              1.335001  \n",
              "4                              1.698495              1.335001  \n",
              "\n",
              "[5 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f0bc934d-69b3-44a0-84bb-34ce8a064e4e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>close</th>\n",
              "      <th>open</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "      <th>evm</th>\n",
              "      <th>force_index</th>\n",
              "      <th>rsi</th>\n",
              "      <th>cci</th>\n",
              "      <th>macd-signal</th>\n",
              "      <th>...</th>\n",
              "      <th>Gross Profit</th>\n",
              "      <th>Normalized EBITDA</th>\n",
              "      <th>Operating Cash Flow</th>\n",
              "      <th>Investing Cash Flow</th>\n",
              "      <th>Financing Cash Flow</th>\n",
              "      <th>Free Cash Flow</th>\n",
              "      <th>Total Assets</th>\n",
              "      <th>Total Liabilities Net Minority Interest</th>\n",
              "      <th>Total Equity Gross Minority Interest</th>\n",
              "      <th>Total Capitalization</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.668620</td>\n",
              "      <td>-1.675547</td>\n",
              "      <td>-1.666923</td>\n",
              "      <td>-1.675847</td>\n",
              "      <td>-0.128616</td>\n",
              "      <td>0.043426</td>\n",
              "      <td>0.067413</td>\n",
              "      <td>0.500617</td>\n",
              "      <td>0.438943</td>\n",
              "      <td>-0.048217</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.120053</td>\n",
              "      <td>-1.038348</td>\n",
              "      <td>-1.254581</td>\n",
              "      <td>1.796214</td>\n",
              "      <td>0.499973</td>\n",
              "      <td>-1.329357</td>\n",
              "      <td>-0.262246</td>\n",
              "      <td>-1.248318</td>\n",
              "      <td>1.698495</td>\n",
              "      <td>1.335001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.674196</td>\n",
              "      <td>-1.671910</td>\n",
              "      <td>-1.671093</td>\n",
              "      <td>-1.681444</td>\n",
              "      <td>-0.801205</td>\n",
              "      <td>0.019802</td>\n",
              "      <td>-0.019172</td>\n",
              "      <td>0.317097</td>\n",
              "      <td>-0.070093</td>\n",
              "      <td>-0.069058</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.120053</td>\n",
              "      <td>-1.038348</td>\n",
              "      <td>-1.254581</td>\n",
              "      <td>1.796214</td>\n",
              "      <td>0.499973</td>\n",
              "      <td>-1.329357</td>\n",
              "      <td>-0.262246</td>\n",
              "      <td>-1.248318</td>\n",
              "      <td>1.698495</td>\n",
              "      <td>1.335001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.663216</td>\n",
              "      <td>-1.673221</td>\n",
              "      <td>-1.664566</td>\n",
              "      <td>-1.677733</td>\n",
              "      <td>-0.674991</td>\n",
              "      <td>0.020294</td>\n",
              "      <td>0.017197</td>\n",
              "      <td>0.548031</td>\n",
              "      <td>0.423097</td>\n",
              "      <td>-0.052112</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.120053</td>\n",
              "      <td>-1.038348</td>\n",
              "      <td>-1.254581</td>\n",
              "      <td>1.796214</td>\n",
              "      <td>0.499973</td>\n",
              "      <td>-1.329357</td>\n",
              "      <td>-0.262246</td>\n",
              "      <td>-1.248318</td>\n",
              "      <td>1.698495</td>\n",
              "      <td>1.335001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.655972</td>\n",
              "      <td>-1.657837</td>\n",
              "      <td>-1.649033</td>\n",
              "      <td>-1.660824</td>\n",
              "      <td>-0.450393</td>\n",
              "      <td>0.018294</td>\n",
              "      <td>-0.028183</td>\n",
              "      <td>0.692781</td>\n",
              "      <td>1.240594</td>\n",
              "      <td>-0.024504</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.120053</td>\n",
              "      <td>-1.038348</td>\n",
              "      <td>-1.254581</td>\n",
              "      <td>1.796214</td>\n",
              "      <td>0.499973</td>\n",
              "      <td>-1.329357</td>\n",
              "      <td>-0.262246</td>\n",
              "      <td>-1.248318</td>\n",
              "      <td>1.698495</td>\n",
              "      <td>1.335001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.655397</td>\n",
              "      <td>-1.660520</td>\n",
              "      <td>-1.653747</td>\n",
              "      <td>-1.664182</td>\n",
              "      <td>-0.814824</td>\n",
              "      <td>-0.001258</td>\n",
              "      <td>-0.083315</td>\n",
              "      <td>0.704498</td>\n",
              "      <td>0.953321</td>\n",
              "      <td>-0.013233</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.120053</td>\n",
              "      <td>-1.038348</td>\n",
              "      <td>-1.254581</td>\n",
              "      <td>1.796214</td>\n",
              "      <td>0.499973</td>\n",
              "      <td>-1.329357</td>\n",
              "      <td>-0.262246</td>\n",
              "      <td>-1.248318</td>\n",
              "      <td>1.698495</td>\n",
              "      <td>1.335001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 25 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0bc934d-69b3-44a0-84bb-34ce8a064e4e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f0bc934d-69b3-44a0-84bb-34ce8a064e4e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f0bc934d-69b3-44a0-84bb-34ce8a064e4e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "YSd3ApEcQsZb"
      },
      "outputs": [],
      "source": [
        "newDF=pd.concat([dateColumn,df,df_news_text,df_news_summary],axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "tIckXIm8Q5BW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "addbf60a-a41c-4502-d7b4-12099b89e847"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(974, 76)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "newDF.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "1zxAj31FQ5EA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "fbcb61b0-e2fd-4173-cb16-1d71b11da948"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     datetime     close      open       low      high    volume       evm  \\\n",
              "0  2019-02-20 -1.668620 -1.675547 -1.666923 -1.675847 -0.128616  0.043426   \n",
              "1  2019-02-21 -1.674196 -1.671910 -1.671093 -1.681444 -0.801205  0.019802   \n",
              "2  2019-02-22 -1.663216 -1.673221 -1.664566 -1.677733 -0.674991  0.020294   \n",
              "3  2019-02-25 -1.655972 -1.657837 -1.649033 -1.660824 -0.450393  0.018294   \n",
              "4  2019-02-26 -1.655397 -1.660520 -1.653747 -1.664182 -0.814824 -0.001258   \n",
              "\n",
              "   force_index       rsi       cci  ...    Spca16    Spca17    Spca18  \\\n",
              "0     0.067413  0.500617  0.438943  ...  1.818383 -0.914117 -2.074325   \n",
              "1    -0.019172  0.317097 -0.070093  ...  1.650529 -0.181376  0.587466   \n",
              "2     0.017197  0.548031  0.423097  ... -0.941116  0.429186 -1.367047   \n",
              "3    -0.028183  0.692781  1.240594  ...  0.295991 -0.981859  0.993470   \n",
              "4    -0.083315  0.704498  0.953321  ...  1.060050  0.447202 -2.514552   \n",
              "\n",
              "     Spca19    Spca20    Spca21    Spca22    Spca23    Spca24    Spca25  \n",
              "0  0.913988  0.112712  1.926086  0.260297 -1.321530  0.044715  1.352779  \n",
              "1 -1.511634  1.054598 -1.483433 -1.453117 -0.526334 -0.115460 -1.474181  \n",
              "2  0.464688 -0.060432  0.348901  0.847478  0.569073  0.267420  0.057089  \n",
              "3 -1.462695 -0.706416 -0.579468  0.472940  0.470021  0.762850 -1.404587  \n",
              "4  2.650107 -2.557092 -0.502712  2.301711  0.643496 -0.231621 -0.870302  \n",
              "\n",
              "[5 rows x 76 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bbc5c666-60fd-4081-92d7-ed14e77386bd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>close</th>\n",
              "      <th>open</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "      <th>evm</th>\n",
              "      <th>force_index</th>\n",
              "      <th>rsi</th>\n",
              "      <th>cci</th>\n",
              "      <th>...</th>\n",
              "      <th>Spca16</th>\n",
              "      <th>Spca17</th>\n",
              "      <th>Spca18</th>\n",
              "      <th>Spca19</th>\n",
              "      <th>Spca20</th>\n",
              "      <th>Spca21</th>\n",
              "      <th>Spca22</th>\n",
              "      <th>Spca23</th>\n",
              "      <th>Spca24</th>\n",
              "      <th>Spca25</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-02-20</td>\n",
              "      <td>-1.668620</td>\n",
              "      <td>-1.675547</td>\n",
              "      <td>-1.666923</td>\n",
              "      <td>-1.675847</td>\n",
              "      <td>-0.128616</td>\n",
              "      <td>0.043426</td>\n",
              "      <td>0.067413</td>\n",
              "      <td>0.500617</td>\n",
              "      <td>0.438943</td>\n",
              "      <td>...</td>\n",
              "      <td>1.818383</td>\n",
              "      <td>-0.914117</td>\n",
              "      <td>-2.074325</td>\n",
              "      <td>0.913988</td>\n",
              "      <td>0.112712</td>\n",
              "      <td>1.926086</td>\n",
              "      <td>0.260297</td>\n",
              "      <td>-1.321530</td>\n",
              "      <td>0.044715</td>\n",
              "      <td>1.352779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-02-21</td>\n",
              "      <td>-1.674196</td>\n",
              "      <td>-1.671910</td>\n",
              "      <td>-1.671093</td>\n",
              "      <td>-1.681444</td>\n",
              "      <td>-0.801205</td>\n",
              "      <td>0.019802</td>\n",
              "      <td>-0.019172</td>\n",
              "      <td>0.317097</td>\n",
              "      <td>-0.070093</td>\n",
              "      <td>...</td>\n",
              "      <td>1.650529</td>\n",
              "      <td>-0.181376</td>\n",
              "      <td>0.587466</td>\n",
              "      <td>-1.511634</td>\n",
              "      <td>1.054598</td>\n",
              "      <td>-1.483433</td>\n",
              "      <td>-1.453117</td>\n",
              "      <td>-0.526334</td>\n",
              "      <td>-0.115460</td>\n",
              "      <td>-1.474181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-02-22</td>\n",
              "      <td>-1.663216</td>\n",
              "      <td>-1.673221</td>\n",
              "      <td>-1.664566</td>\n",
              "      <td>-1.677733</td>\n",
              "      <td>-0.674991</td>\n",
              "      <td>0.020294</td>\n",
              "      <td>0.017197</td>\n",
              "      <td>0.548031</td>\n",
              "      <td>0.423097</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.941116</td>\n",
              "      <td>0.429186</td>\n",
              "      <td>-1.367047</td>\n",
              "      <td>0.464688</td>\n",
              "      <td>-0.060432</td>\n",
              "      <td>0.348901</td>\n",
              "      <td>0.847478</td>\n",
              "      <td>0.569073</td>\n",
              "      <td>0.267420</td>\n",
              "      <td>0.057089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-02-25</td>\n",
              "      <td>-1.655972</td>\n",
              "      <td>-1.657837</td>\n",
              "      <td>-1.649033</td>\n",
              "      <td>-1.660824</td>\n",
              "      <td>-0.450393</td>\n",
              "      <td>0.018294</td>\n",
              "      <td>-0.028183</td>\n",
              "      <td>0.692781</td>\n",
              "      <td>1.240594</td>\n",
              "      <td>...</td>\n",
              "      <td>0.295991</td>\n",
              "      <td>-0.981859</td>\n",
              "      <td>0.993470</td>\n",
              "      <td>-1.462695</td>\n",
              "      <td>-0.706416</td>\n",
              "      <td>-0.579468</td>\n",
              "      <td>0.472940</td>\n",
              "      <td>0.470021</td>\n",
              "      <td>0.762850</td>\n",
              "      <td>-1.404587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-02-26</td>\n",
              "      <td>-1.655397</td>\n",
              "      <td>-1.660520</td>\n",
              "      <td>-1.653747</td>\n",
              "      <td>-1.664182</td>\n",
              "      <td>-0.814824</td>\n",
              "      <td>-0.001258</td>\n",
              "      <td>-0.083315</td>\n",
              "      <td>0.704498</td>\n",
              "      <td>0.953321</td>\n",
              "      <td>...</td>\n",
              "      <td>1.060050</td>\n",
              "      <td>0.447202</td>\n",
              "      <td>-2.514552</td>\n",
              "      <td>2.650107</td>\n",
              "      <td>-2.557092</td>\n",
              "      <td>-0.502712</td>\n",
              "      <td>2.301711</td>\n",
              "      <td>0.643496</td>\n",
              "      <td>-0.231621</td>\n",
              "      <td>-0.870302</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 76 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bbc5c666-60fd-4081-92d7-ed14e77386bd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bbc5c666-60fd-4081-92d7-ed14e77386bd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bbc5c666-60fd-4081-92d7-ed14e77386bd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "newDF.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "eK82oLLrkiFo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhdna_axklbH"
      },
      "source": [
        "Start applying model after this.\n",
        "\n",
        "Take data before 2022-9-30 as training and after as testing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "u_HjY-1DM1_W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59c37355-e261-46f7-bb1a-1b38fbaf38c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train x:  (724, 76) train y:  (724, 2)\n",
            "test x:  (250, 76) test y:  (250, 2)\n"
          ]
        }
      ],
      "source": [
        "file_train = newDF[(newDF['datetime'] <'2022-01-01')]\n",
        "file_test = newDF[(newDF['datetime'] >='2022-01-01')]\n",
        "y_df_train = y_df[(y_df['datetime'] <'2022-01-01')]\n",
        "y_df_test = y_df[(y_df['datetime'] >='2022-01-01')]\n",
        "print(\"train x: \",file_train.shape,\"train y: \",y_df_train.shape)\n",
        "print(\"test x: \",file_test.shape,\"test y: \",y_df_test.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_train = file_train.drop('datetime', axis=1)\n",
        "# file_train = file_train.drop('title', axis=1)\n",
        "file_test = file_test.drop('datetime', axis=1)\n",
        "y_df_train = y_df_train.drop('datetime', axis=1)\n",
        "y_df_test = y_df_test.drop('datetime', axis=1)\n",
        "file_train"
      ],
      "metadata": {
        "id": "8CFCLvdPVxVG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "b67adbb9-7884-4e42-e907-ae98c04ffb47"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        close      open       low      high    volume       evm  force_index  \\\n",
              "0   -1.668620 -1.675547 -1.666923 -1.675847 -0.128616  0.043426     0.067413   \n",
              "1   -1.674196 -1.671910 -1.671093 -1.681444 -0.801205  0.019802    -0.019172   \n",
              "2   -1.663216 -1.673221 -1.664566 -1.677733 -0.674991  0.020294     0.017197   \n",
              "3   -1.655972 -1.657837 -1.649033 -1.660824 -0.450393  0.018294    -0.028183   \n",
              "4   -1.655397 -1.660520 -1.653747 -1.664182 -0.814824 -0.001258    -0.083315   \n",
              "..        ...       ...       ...       ...       ...       ...          ...   \n",
              "719  1.595814  1.527659  1.580393  1.554807 -0.688898  1.786220     0.868584   \n",
              "720  1.571284  1.600886  1.615689  1.576252 -0.608764  1.593279     0.454527   \n",
              "721  1.573407  1.581089  1.606261  1.559756 -0.927342  1.058239     0.133907   \n",
              "722  1.545575  1.584428  1.605052  1.558342 -0.976202  0.890338     0.090565   \n",
              "723  1.530714  1.551512  1.584986  1.526763 -0.894842  0.546081    -0.199391   \n",
              "\n",
              "          rsi       cci  macd-signal  ...    Spca16    Spca17    Spca18  \\\n",
              "0    0.500617  0.438943    -0.048217  ...  1.818383 -0.914117 -2.074325   \n",
              "1    0.317097 -0.070093    -0.069058  ...  1.650529 -0.181376  0.587466   \n",
              "2    0.548031  0.423097    -0.052112  ... -0.941116  0.429186 -1.367047   \n",
              "3    0.692781  1.240594    -0.024504  ...  0.295991 -0.981859  0.993470   \n",
              "4    0.704498  0.953321    -0.013233  ...  1.060050  0.447202 -2.514552   \n",
              "..        ...       ...          ...  ...       ...       ...       ...   \n",
              "719  0.862153  0.986832    -0.143126  ... -1.348111  0.013094  0.202696   \n",
              "720  0.707009  0.906312    -0.057541  ...  0.664806 -0.215095  1.006945   \n",
              "721  0.714561  0.637582    -0.053188  ...  4.536310  0.733698 -1.868503   \n",
              "722  0.523835  0.423435    -0.204403  ... -1.731146  1.021985  1.190620   \n",
              "723  0.420371  0.207487    -0.399385  ... -0.353832 -1.481709  0.201111   \n",
              "\n",
              "       Spca19    Spca20    Spca21    Spca22    Spca23    Spca24    Spca25  \n",
              "0    0.913988  0.112712  1.926086  0.260297 -1.321530  0.044715  1.352779  \n",
              "1   -1.511634  1.054598 -1.483433 -1.453117 -0.526334 -0.115460 -1.474181  \n",
              "2    0.464688 -0.060432  0.348901  0.847478  0.569073  0.267420  0.057089  \n",
              "3   -1.462695 -0.706416 -0.579468  0.472940  0.470021  0.762850 -1.404587  \n",
              "4    2.650107 -2.557092 -0.502712  2.301711  0.643496 -0.231621 -0.870302  \n",
              "..        ...       ...       ...       ...       ...       ...       ...  \n",
              "719 -0.228257  0.259967  0.291705 -0.137759  0.458343 -0.255312  0.598122  \n",
              "720  0.182568 -0.245883  0.613784 -0.223907  0.452797 -1.003748  0.330362  \n",
              "721 -3.433487 -1.594664  1.632244 -2.006359 -3.219759 -2.049082 -1.532502  \n",
              "722  1.504136  0.151652 -0.923247  0.089130 -0.337751  0.956670  0.907953  \n",
              "723 -1.972602  0.640799  0.618131  0.149418 -2.365974 -0.123700  0.405590  \n",
              "\n",
              "[724 rows x 75 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-85810405-cce4-4c50-a7e7-0f7fe3951072\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>close</th>\n",
              "      <th>open</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "      <th>evm</th>\n",
              "      <th>force_index</th>\n",
              "      <th>rsi</th>\n",
              "      <th>cci</th>\n",
              "      <th>macd-signal</th>\n",
              "      <th>...</th>\n",
              "      <th>Spca16</th>\n",
              "      <th>Spca17</th>\n",
              "      <th>Spca18</th>\n",
              "      <th>Spca19</th>\n",
              "      <th>Spca20</th>\n",
              "      <th>Spca21</th>\n",
              "      <th>Spca22</th>\n",
              "      <th>Spca23</th>\n",
              "      <th>Spca24</th>\n",
              "      <th>Spca25</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.668620</td>\n",
              "      <td>-1.675547</td>\n",
              "      <td>-1.666923</td>\n",
              "      <td>-1.675847</td>\n",
              "      <td>-0.128616</td>\n",
              "      <td>0.043426</td>\n",
              "      <td>0.067413</td>\n",
              "      <td>0.500617</td>\n",
              "      <td>0.438943</td>\n",
              "      <td>-0.048217</td>\n",
              "      <td>...</td>\n",
              "      <td>1.818383</td>\n",
              "      <td>-0.914117</td>\n",
              "      <td>-2.074325</td>\n",
              "      <td>0.913988</td>\n",
              "      <td>0.112712</td>\n",
              "      <td>1.926086</td>\n",
              "      <td>0.260297</td>\n",
              "      <td>-1.321530</td>\n",
              "      <td>0.044715</td>\n",
              "      <td>1.352779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.674196</td>\n",
              "      <td>-1.671910</td>\n",
              "      <td>-1.671093</td>\n",
              "      <td>-1.681444</td>\n",
              "      <td>-0.801205</td>\n",
              "      <td>0.019802</td>\n",
              "      <td>-0.019172</td>\n",
              "      <td>0.317097</td>\n",
              "      <td>-0.070093</td>\n",
              "      <td>-0.069058</td>\n",
              "      <td>...</td>\n",
              "      <td>1.650529</td>\n",
              "      <td>-0.181376</td>\n",
              "      <td>0.587466</td>\n",
              "      <td>-1.511634</td>\n",
              "      <td>1.054598</td>\n",
              "      <td>-1.483433</td>\n",
              "      <td>-1.453117</td>\n",
              "      <td>-0.526334</td>\n",
              "      <td>-0.115460</td>\n",
              "      <td>-1.474181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.663216</td>\n",
              "      <td>-1.673221</td>\n",
              "      <td>-1.664566</td>\n",
              "      <td>-1.677733</td>\n",
              "      <td>-0.674991</td>\n",
              "      <td>0.020294</td>\n",
              "      <td>0.017197</td>\n",
              "      <td>0.548031</td>\n",
              "      <td>0.423097</td>\n",
              "      <td>-0.052112</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.941116</td>\n",
              "      <td>0.429186</td>\n",
              "      <td>-1.367047</td>\n",
              "      <td>0.464688</td>\n",
              "      <td>-0.060432</td>\n",
              "      <td>0.348901</td>\n",
              "      <td>0.847478</td>\n",
              "      <td>0.569073</td>\n",
              "      <td>0.267420</td>\n",
              "      <td>0.057089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.655972</td>\n",
              "      <td>-1.657837</td>\n",
              "      <td>-1.649033</td>\n",
              "      <td>-1.660824</td>\n",
              "      <td>-0.450393</td>\n",
              "      <td>0.018294</td>\n",
              "      <td>-0.028183</td>\n",
              "      <td>0.692781</td>\n",
              "      <td>1.240594</td>\n",
              "      <td>-0.024504</td>\n",
              "      <td>...</td>\n",
              "      <td>0.295991</td>\n",
              "      <td>-0.981859</td>\n",
              "      <td>0.993470</td>\n",
              "      <td>-1.462695</td>\n",
              "      <td>-0.706416</td>\n",
              "      <td>-0.579468</td>\n",
              "      <td>0.472940</td>\n",
              "      <td>0.470021</td>\n",
              "      <td>0.762850</td>\n",
              "      <td>-1.404587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.655397</td>\n",
              "      <td>-1.660520</td>\n",
              "      <td>-1.653747</td>\n",
              "      <td>-1.664182</td>\n",
              "      <td>-0.814824</td>\n",
              "      <td>-0.001258</td>\n",
              "      <td>-0.083315</td>\n",
              "      <td>0.704498</td>\n",
              "      <td>0.953321</td>\n",
              "      <td>-0.013233</td>\n",
              "      <td>...</td>\n",
              "      <td>1.060050</td>\n",
              "      <td>0.447202</td>\n",
              "      <td>-2.514552</td>\n",
              "      <td>2.650107</td>\n",
              "      <td>-2.557092</td>\n",
              "      <td>-0.502712</td>\n",
              "      <td>2.301711</td>\n",
              "      <td>0.643496</td>\n",
              "      <td>-0.231621</td>\n",
              "      <td>-0.870302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>719</th>\n",
              "      <td>1.595814</td>\n",
              "      <td>1.527659</td>\n",
              "      <td>1.580393</td>\n",
              "      <td>1.554807</td>\n",
              "      <td>-0.688898</td>\n",
              "      <td>1.786220</td>\n",
              "      <td>0.868584</td>\n",
              "      <td>0.862153</td>\n",
              "      <td>0.986832</td>\n",
              "      <td>-0.143126</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.348111</td>\n",
              "      <td>0.013094</td>\n",
              "      <td>0.202696</td>\n",
              "      <td>-0.228257</td>\n",
              "      <td>0.259967</td>\n",
              "      <td>0.291705</td>\n",
              "      <td>-0.137759</td>\n",
              "      <td>0.458343</td>\n",
              "      <td>-0.255312</td>\n",
              "      <td>0.598122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>720</th>\n",
              "      <td>1.571284</td>\n",
              "      <td>1.600886</td>\n",
              "      <td>1.615689</td>\n",
              "      <td>1.576252</td>\n",
              "      <td>-0.608764</td>\n",
              "      <td>1.593279</td>\n",
              "      <td>0.454527</td>\n",
              "      <td>0.707009</td>\n",
              "      <td>0.906312</td>\n",
              "      <td>-0.057541</td>\n",
              "      <td>...</td>\n",
              "      <td>0.664806</td>\n",
              "      <td>-0.215095</td>\n",
              "      <td>1.006945</td>\n",
              "      <td>0.182568</td>\n",
              "      <td>-0.245883</td>\n",
              "      <td>0.613784</td>\n",
              "      <td>-0.223907</td>\n",
              "      <td>0.452797</td>\n",
              "      <td>-1.003748</td>\n",
              "      <td>0.330362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>721</th>\n",
              "      <td>1.573407</td>\n",
              "      <td>1.581089</td>\n",
              "      <td>1.606261</td>\n",
              "      <td>1.559756</td>\n",
              "      <td>-0.927342</td>\n",
              "      <td>1.058239</td>\n",
              "      <td>0.133907</td>\n",
              "      <td>0.714561</td>\n",
              "      <td>0.637582</td>\n",
              "      <td>-0.053188</td>\n",
              "      <td>...</td>\n",
              "      <td>4.536310</td>\n",
              "      <td>0.733698</td>\n",
              "      <td>-1.868503</td>\n",
              "      <td>-3.433487</td>\n",
              "      <td>-1.594664</td>\n",
              "      <td>1.632244</td>\n",
              "      <td>-2.006359</td>\n",
              "      <td>-3.219759</td>\n",
              "      <td>-2.049082</td>\n",
              "      <td>-1.532502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>722</th>\n",
              "      <td>1.545575</td>\n",
              "      <td>1.584428</td>\n",
              "      <td>1.605052</td>\n",
              "      <td>1.558342</td>\n",
              "      <td>-0.976202</td>\n",
              "      <td>0.890338</td>\n",
              "      <td>0.090565</td>\n",
              "      <td>0.523835</td>\n",
              "      <td>0.423435</td>\n",
              "      <td>-0.204403</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.731146</td>\n",
              "      <td>1.021985</td>\n",
              "      <td>1.190620</td>\n",
              "      <td>1.504136</td>\n",
              "      <td>0.151652</td>\n",
              "      <td>-0.923247</td>\n",
              "      <td>0.089130</td>\n",
              "      <td>-0.337751</td>\n",
              "      <td>0.956670</td>\n",
              "      <td>0.907953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>723</th>\n",
              "      <td>1.530714</td>\n",
              "      <td>1.551512</td>\n",
              "      <td>1.584986</td>\n",
              "      <td>1.526763</td>\n",
              "      <td>-0.894842</td>\n",
              "      <td>0.546081</td>\n",
              "      <td>-0.199391</td>\n",
              "      <td>0.420371</td>\n",
              "      <td>0.207487</td>\n",
              "      <td>-0.399385</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.353832</td>\n",
              "      <td>-1.481709</td>\n",
              "      <td>0.201111</td>\n",
              "      <td>-1.972602</td>\n",
              "      <td>0.640799</td>\n",
              "      <td>0.618131</td>\n",
              "      <td>0.149418</td>\n",
              "      <td>-2.365974</td>\n",
              "      <td>-0.123700</td>\n",
              "      <td>0.405590</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>724 rows × 75 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85810405-cce4-4c50-a7e7-0f7fe3951072')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-85810405-cce4-4c50-a7e7-0f7fe3951072 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-85810405-cce4-4c50-a7e7-0f7fe3951072');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_test"
      ],
      "metadata": {
        "id": "s6kTZOv0XDo_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "60318ee4-82e9-44a5-f295-4cb6cb8c3fad"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        close      open       low      high    volume       evm  force_index  \\\n",
              "724  1.635440  1.545310  1.595865  1.612779 -0.128042  0.637190     0.465917   \n",
              "725  1.580955  1.659802  1.629952  1.614193 -0.226249  1.196772     0.361399   \n",
              "726  1.468209  1.587767  1.521646  1.548915 -0.316781  0.384472    -0.451278   \n",
              "727  1.399336  1.422947  1.449120  1.434149 -0.271894 -0.082995    -0.117687   \n",
              "728  1.403345  1.427479  1.434373  1.406813 -0.465273  0.079685    -0.019464   \n",
              "..        ...       ...       ...       ...       ...       ...          ...   \n",
              "969  0.479385  0.508205  0.449704  0.474073 -0.633274 -2.369341    -1.142599   \n",
              "970  0.470608  0.426391  0.433748  0.423642 -0.899534 -2.908863    -0.909306   \n",
              "971  0.427193  0.437363  0.411507  0.399840 -0.801034 -2.066408    -0.862952   \n",
              "972  0.332535  0.396576  0.342606  0.390885 -0.489376 -1.931024    -1.194451   \n",
              "973  0.417229  0.356503  0.387573  0.377924 -0.674025 -1.932728    -0.947813   \n",
              "\n",
              "          rsi       cci  macd-signal  ...    Spca16    Spca17    Spca18  \\\n",
              "724  0.838662  0.735515    -0.193051  ...  0.966060 -0.679832  0.123816   \n",
              "725  0.462909  0.543095    -0.301427  ... -0.447437 -1.647548  0.504535   \n",
              "726 -0.209672 -0.259246    -0.804068  ...  1.640600 -2.829193 -1.326733   \n",
              "727 -0.560674 -0.935698    -1.372400  ...  0.710886  1.753162 -0.970937   \n",
              "728 -0.539856 -1.074780    -1.694447  ... -1.315761 -1.001168  0.238707   \n",
              "..        ...       ...          ...  ...       ...       ...       ...   \n",
              "969 -1.601605 -1.238043    -1.503718  ...  1.727583  2.827416  1.035260   \n",
              "970 -1.634109 -1.214319    -1.413523  ...  2.306204 -2.243432 -0.066597   \n",
              "971 -1.795609 -1.217095    -1.403124  ...  0.873453 -2.523095 -0.288524   \n",
              "972 -2.111416 -1.328902    -1.618963  ...  0.050719 -2.594426  0.332053   \n",
              "973 -1.540869 -1.050791    -1.335297  ... -0.774901 -0.598481  1.938935   \n",
              "\n",
              "       Spca19    Spca20    Spca21    Spca22    Spca23    Spca24    Spca25  \n",
              "724 -1.970873 -0.838483  1.107797 -2.106236  0.665066 -2.408328  0.372906  \n",
              "725 -0.479987 -1.655417  0.026204  0.824727  0.751534  0.823216  0.291274  \n",
              "726  1.925505 -0.255668 -2.274602  1.217723  1.646906 -0.700347 -1.139291  \n",
              "727 -1.120789  1.117059 -1.780029 -0.589923  0.170238 -0.360842  0.333469  \n",
              "728  0.242876  2.077984  1.655151  2.048571  1.135930 -1.441565 -1.901032  \n",
              "..        ...       ...       ...       ...       ...       ...       ...  \n",
              "969 -1.005180 -0.452188  1.798969 -0.634948 -1.344085 -0.228949 -2.238541  \n",
              "970  1.084826 -2.327940 -1.495850  0.988852 -0.155374  0.065605  1.730080  \n",
              "971 -1.318568  0.659262 -0.309576  1.374979 -1.640017 -0.738817  0.848646  \n",
              "972 -0.011782 -1.045049 -0.123244  2.000252  0.192048  0.394147  0.018608  \n",
              "973 -2.207575 -0.223497 -0.409510 -0.086743  1.183797 -0.004401 -0.981585  \n",
              "\n",
              "[250 rows x 75 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32dc90b8-ca27-4cc7-b8fe-519f75a94159\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>close</th>\n",
              "      <th>open</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "      <th>evm</th>\n",
              "      <th>force_index</th>\n",
              "      <th>rsi</th>\n",
              "      <th>cci</th>\n",
              "      <th>macd-signal</th>\n",
              "      <th>...</th>\n",
              "      <th>Spca16</th>\n",
              "      <th>Spca17</th>\n",
              "      <th>Spca18</th>\n",
              "      <th>Spca19</th>\n",
              "      <th>Spca20</th>\n",
              "      <th>Spca21</th>\n",
              "      <th>Spca22</th>\n",
              "      <th>Spca23</th>\n",
              "      <th>Spca24</th>\n",
              "      <th>Spca25</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>724</th>\n",
              "      <td>1.635440</td>\n",
              "      <td>1.545310</td>\n",
              "      <td>1.595865</td>\n",
              "      <td>1.612779</td>\n",
              "      <td>-0.128042</td>\n",
              "      <td>0.637190</td>\n",
              "      <td>0.465917</td>\n",
              "      <td>0.838662</td>\n",
              "      <td>0.735515</td>\n",
              "      <td>-0.193051</td>\n",
              "      <td>...</td>\n",
              "      <td>0.966060</td>\n",
              "      <td>-0.679832</td>\n",
              "      <td>0.123816</td>\n",
              "      <td>-1.970873</td>\n",
              "      <td>-0.838483</td>\n",
              "      <td>1.107797</td>\n",
              "      <td>-2.106236</td>\n",
              "      <td>0.665066</td>\n",
              "      <td>-2.408328</td>\n",
              "      <td>0.372906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>725</th>\n",
              "      <td>1.580955</td>\n",
              "      <td>1.659802</td>\n",
              "      <td>1.629952</td>\n",
              "      <td>1.614193</td>\n",
              "      <td>-0.226249</td>\n",
              "      <td>1.196772</td>\n",
              "      <td>0.361399</td>\n",
              "      <td>0.462909</td>\n",
              "      <td>0.543095</td>\n",
              "      <td>-0.301427</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.447437</td>\n",
              "      <td>-1.647548</td>\n",
              "      <td>0.504535</td>\n",
              "      <td>-0.479987</td>\n",
              "      <td>-1.655417</td>\n",
              "      <td>0.026204</td>\n",
              "      <td>0.824727</td>\n",
              "      <td>0.751534</td>\n",
              "      <td>0.823216</td>\n",
              "      <td>0.291274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>726</th>\n",
              "      <td>1.468209</td>\n",
              "      <td>1.587767</td>\n",
              "      <td>1.521646</td>\n",
              "      <td>1.548915</td>\n",
              "      <td>-0.316781</td>\n",
              "      <td>0.384472</td>\n",
              "      <td>-0.451278</td>\n",
              "      <td>-0.209672</td>\n",
              "      <td>-0.259246</td>\n",
              "      <td>-0.804068</td>\n",
              "      <td>...</td>\n",
              "      <td>1.640600</td>\n",
              "      <td>-2.829193</td>\n",
              "      <td>-1.326733</td>\n",
              "      <td>1.925505</td>\n",
              "      <td>-0.255668</td>\n",
              "      <td>-2.274602</td>\n",
              "      <td>1.217723</td>\n",
              "      <td>1.646906</td>\n",
              "      <td>-0.700347</td>\n",
              "      <td>-1.139291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>727</th>\n",
              "      <td>1.399336</td>\n",
              "      <td>1.422947</td>\n",
              "      <td>1.449120</td>\n",
              "      <td>1.434149</td>\n",
              "      <td>-0.271894</td>\n",
              "      <td>-0.082995</td>\n",
              "      <td>-0.117687</td>\n",
              "      <td>-0.560674</td>\n",
              "      <td>-0.935698</td>\n",
              "      <td>-1.372400</td>\n",
              "      <td>...</td>\n",
              "      <td>0.710886</td>\n",
              "      <td>1.753162</td>\n",
              "      <td>-0.970937</td>\n",
              "      <td>-1.120789</td>\n",
              "      <td>1.117059</td>\n",
              "      <td>-1.780029</td>\n",
              "      <td>-0.589923</td>\n",
              "      <td>0.170238</td>\n",
              "      <td>-0.360842</td>\n",
              "      <td>0.333469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>728</th>\n",
              "      <td>1.403345</td>\n",
              "      <td>1.427479</td>\n",
              "      <td>1.434373</td>\n",
              "      <td>1.406813</td>\n",
              "      <td>-0.465273</td>\n",
              "      <td>0.079685</td>\n",
              "      <td>-0.019464</td>\n",
              "      <td>-0.539856</td>\n",
              "      <td>-1.074780</td>\n",
              "      <td>-1.694447</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.315761</td>\n",
              "      <td>-1.001168</td>\n",
              "      <td>0.238707</td>\n",
              "      <td>0.242876</td>\n",
              "      <td>2.077984</td>\n",
              "      <td>1.655151</td>\n",
              "      <td>2.048571</td>\n",
              "      <td>1.135930</td>\n",
              "      <td>-1.441565</td>\n",
              "      <td>-1.901032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>969</th>\n",
              "      <td>0.479385</td>\n",
              "      <td>0.508205</td>\n",
              "      <td>0.449704</td>\n",
              "      <td>0.474073</td>\n",
              "      <td>-0.633274</td>\n",
              "      <td>-2.369341</td>\n",
              "      <td>-1.142599</td>\n",
              "      <td>-1.601605</td>\n",
              "      <td>-1.238043</td>\n",
              "      <td>-1.503718</td>\n",
              "      <td>...</td>\n",
              "      <td>1.727583</td>\n",
              "      <td>2.827416</td>\n",
              "      <td>1.035260</td>\n",
              "      <td>-1.005180</td>\n",
              "      <td>-0.452188</td>\n",
              "      <td>1.798969</td>\n",
              "      <td>-0.634948</td>\n",
              "      <td>-1.344085</td>\n",
              "      <td>-0.228949</td>\n",
              "      <td>-2.238541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>970</th>\n",
              "      <td>0.470608</td>\n",
              "      <td>0.426391</td>\n",
              "      <td>0.433748</td>\n",
              "      <td>0.423642</td>\n",
              "      <td>-0.899534</td>\n",
              "      <td>-2.908863</td>\n",
              "      <td>-0.909306</td>\n",
              "      <td>-1.634109</td>\n",
              "      <td>-1.214319</td>\n",
              "      <td>-1.413523</td>\n",
              "      <td>...</td>\n",
              "      <td>2.306204</td>\n",
              "      <td>-2.243432</td>\n",
              "      <td>-0.066597</td>\n",
              "      <td>1.084826</td>\n",
              "      <td>-2.327940</td>\n",
              "      <td>-1.495850</td>\n",
              "      <td>0.988852</td>\n",
              "      <td>-0.155374</td>\n",
              "      <td>0.065605</td>\n",
              "      <td>1.730080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>971</th>\n",
              "      <td>0.427193</td>\n",
              "      <td>0.437363</td>\n",
              "      <td>0.411507</td>\n",
              "      <td>0.399840</td>\n",
              "      <td>-0.801034</td>\n",
              "      <td>-2.066408</td>\n",
              "      <td>-0.862952</td>\n",
              "      <td>-1.795609</td>\n",
              "      <td>-1.217095</td>\n",
              "      <td>-1.403124</td>\n",
              "      <td>...</td>\n",
              "      <td>0.873453</td>\n",
              "      <td>-2.523095</td>\n",
              "      <td>-0.288524</td>\n",
              "      <td>-1.318568</td>\n",
              "      <td>0.659262</td>\n",
              "      <td>-0.309576</td>\n",
              "      <td>1.374979</td>\n",
              "      <td>-1.640017</td>\n",
              "      <td>-0.738817</td>\n",
              "      <td>0.848646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>972</th>\n",
              "      <td>0.332535</td>\n",
              "      <td>0.396576</td>\n",
              "      <td>0.342606</td>\n",
              "      <td>0.390885</td>\n",
              "      <td>-0.489376</td>\n",
              "      <td>-1.931024</td>\n",
              "      <td>-1.194451</td>\n",
              "      <td>-2.111416</td>\n",
              "      <td>-1.328902</td>\n",
              "      <td>-1.618963</td>\n",
              "      <td>...</td>\n",
              "      <td>0.050719</td>\n",
              "      <td>-2.594426</td>\n",
              "      <td>0.332053</td>\n",
              "      <td>-0.011782</td>\n",
              "      <td>-1.045049</td>\n",
              "      <td>-0.123244</td>\n",
              "      <td>2.000252</td>\n",
              "      <td>0.192048</td>\n",
              "      <td>0.394147</td>\n",
              "      <td>0.018608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>973</th>\n",
              "      <td>0.417229</td>\n",
              "      <td>0.356503</td>\n",
              "      <td>0.387573</td>\n",
              "      <td>0.377924</td>\n",
              "      <td>-0.674025</td>\n",
              "      <td>-1.932728</td>\n",
              "      <td>-0.947813</td>\n",
              "      <td>-1.540869</td>\n",
              "      <td>-1.050791</td>\n",
              "      <td>-1.335297</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.774901</td>\n",
              "      <td>-0.598481</td>\n",
              "      <td>1.938935</td>\n",
              "      <td>-2.207575</td>\n",
              "      <td>-0.223497</td>\n",
              "      <td>-0.409510</td>\n",
              "      <td>-0.086743</td>\n",
              "      <td>1.183797</td>\n",
              "      <td>-0.004401</td>\n",
              "      <td>-0.981585</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>250 rows × 75 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32dc90b8-ca27-4cc7-b8fe-519f75a94159')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-32dc90b8-ca27-4cc7-b8fe-519f75a94159 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-32dc90b8-ca27-4cc7-b8fe-519f75a94159');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_df_train"
      ],
      "metadata": {
        "id": "e7hNJEXRXDfG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "2dc8d408-a17d-4ef5-dc9a-46be3789845e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     y_actual\n",
              "0         0.0\n",
              "1         1.0\n",
              "2         1.0\n",
              "3         1.0\n",
              "4         1.0\n",
              "..        ...\n",
              "719       0.0\n",
              "720       1.0\n",
              "721       0.0\n",
              "722       0.0\n",
              "723       1.0\n",
              "\n",
              "[724 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-83a68a41-80bb-47b1-86f0-037fe62093ba\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>719</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>720</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>721</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>722</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>723</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>724 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83a68a41-80bb-47b1-86f0-037fe62093ba')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-83a68a41-80bb-47b1-86f0-037fe62093ba button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-83a68a41-80bb-47b1-86f0-037fe62093ba');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_df_test"
      ],
      "metadata": {
        "id": "BUpH-wW3XDS9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "2ea207b0-54d7-435f-cb67-6a2325c663f7"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     y_actual\n",
              "724       0.0\n",
              "725       0.0\n",
              "726       0.0\n",
              "727       1.0\n",
              "728       1.0\n",
              "..        ...\n",
              "969       0.0\n",
              "970       0.0\n",
              "971       0.0\n",
              "972       1.0\n",
              "973       1.0\n",
              "\n",
              "[250 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b3da2301-4174-45b8-8fdc-18c2f1f8ee16\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>724</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>725</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>726</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>727</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>728</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>969</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>970</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>971</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>972</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>973</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>250 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3da2301-4174-45b8-8fdc-18c2f1f8ee16')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b3da2301-4174-45b8-8fdc-18c2f1f8ee16 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b3da2301-4174-45b8-8fdc-18c2f1f8ee16');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # file_train.columns = file_train.iloc[0]\n",
        "# file_train = file_train.iloc[1:]\n",
        "\n",
        "# # file_test.columns = file_test.iloc[0]\n",
        "# file_test = file_test.iloc[1:]\n",
        "\n",
        "\n",
        "# # y_df_train.columns = y_df_train.iloc[0]\n",
        "# y_df_train = y_df_train.iloc[1:]\n",
        "\n",
        "\n",
        "# # y_df_test.columns = y_df_test.iloc[0]\n",
        "# y_df_test = y_df_test.iloc[1:]"
      ],
      "metadata": {
        "id": "tFZ3xyBKUAVg"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_df_test)"
      ],
      "metadata": {
        "id": "ay7cmCaNU2nw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3946a3b8-8df7-4302-85f9-d6b466c9ee13"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     y_actual\n",
            "724       0.0\n",
            "725       0.0\n",
            "726       0.0\n",
            "727       1.0\n",
            "728       1.0\n",
            "..        ...\n",
            "969       0.0\n",
            "970       0.0\n",
            "971       0.0\n",
            "972       1.0\n",
            "973       1.0\n",
            "\n",
            "[250 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "baseline_LR = LogisticRegression(C = 1e10, tol=0.000000001, max_iter=100000)\n",
        "baseline_LR.fit(file_train, y_df_train)\n",
        "    # print('Coefficients: \\n', baseline_LR.coef_)\n",
        "print(\"training accracy: %.4f\" % baseline_LR.score(file_train, y_df_train))\n",
        "print(\"test accuracy: %.4f\" % baseline_LR.score(file_test, y_df_test))\n",
        "y_fit_LR = baseline_LR.predict(file_test)\n",
        "# print(y_fit_LR)\n",
        "# print(y_df_test)\n",
        "print('Accuracy:', accuracy_score(y_df_test, y_fit_LR))\n",
        "print('ROC AUC Score:', roc_auc_score(y_df_test, y_fit_LR))\n",
        "print('F1 score:', f1_score(y_df_test, y_fit_LR))\n",
        "print()\n",
        "print('\\n clasification report:\\n', classification_report(y_df_test, y_fit_LR))\n",
        "print('\\n confussion matrix:\\n',confusion_matrix(y_df_test, y_fit_LR))"
      ],
      "metadata": {
        "id": "kBWHjlXwT_Iy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df8d5840-3b92-4536-c457-051d7a49d540"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training accracy: 0.6478\n",
            "test accuracy: 0.5440\n",
            "Accuracy: 0.544\n",
            "ROC AUC Score: 0.5410963305700148\n",
            "F1 score: 0.5043478260869566\n",
            "\n",
            "\n",
            " clasification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.57      0.59      0.58       133\n",
            "         1.0       0.51      0.50      0.50       117\n",
            "\n",
            "    accuracy                           0.54       250\n",
            "   macro avg       0.54      0.54      0.54       250\n",
            "weighted avg       0.54      0.54      0.54       250\n",
            "\n",
            "\n",
            " confussion matrix:\n",
            " [[78 55]\n",
            " [59 58]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nD57Vda-WWsb"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm"
      ],
      "metadata": {
        "id": "TZqDq1sIWWx3"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit and report SVM\n",
        "    # c = 0.5\n",
        "svm_rbf = svm.SVC(C=0.5, kernel='rbf',max_iter=50000)\n",
        "svm_rbf.fit(file_train, y_df_train)\n",
        "# Training acc\n",
        "pred = svm_rbf.predict(file_train)\n",
        "accuracy = accuracy_score(pred, y_df_train)\n",
        "print('The training accuracy of the SVM is ', accuracy)\n",
        "# Test acc\n",
        "y_hat = svm_rbf.predict(file_test)\n",
        "test_accuracy = accuracy_score(y_hat, y_df_test)\n",
        "print('The test accuracy of the SVM is ', test_accuracy)\n",
        "# Conf matrix\n",
        "print('\\n Training classification report:\\n', classification_report(y_df_train, pred))\n",
        "print('\\n confusion matrix:\\n',confusion_matrix(y_df_train, pred))\n",
        "print('\\n Test classification report:\\n', classification_report(y_df_test, y_hat))\n",
        "print('\\n confusion matrix:\\n',confusion_matrix(y_df_test, y_hat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4B8-EZQsWW1l",
        "outputId": "2448d061-1abc-4b58-cabc-0c493092cf70"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training accuracy of the SVM is  0.6174033149171271\n",
            "The test accuracy of the SVM is  0.508\n",
            "\n",
            " Training classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.80      0.20      0.32       327\n",
            "         1.0       0.59      0.96      0.73       397\n",
            "\n",
            "    accuracy                           0.62       724\n",
            "   macro avg       0.70      0.58      0.53       724\n",
            "weighted avg       0.69      0.62      0.55       724\n",
            "\n",
            "\n",
            " confusion matrix:\n",
            " [[ 66 261]\n",
            " [ 16 381]]\n",
            "\n",
            " Test classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.62      0.19      0.29       133\n",
            "         1.0       0.49      0.87      0.62       117\n",
            "\n",
            "    accuracy                           0.51       250\n",
            "   macro avg       0.56      0.53      0.46       250\n",
            "weighted avg       0.56      0.51      0.45       250\n",
            "\n",
            "\n",
            " confusion matrix:\n",
            " [[ 25 108]\n",
            " [ 15 102]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "32jek76-WZqj"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "OBI1YMwKWZtl"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=10, oob_score=True, random_state=0)\n",
        "rf.fit(file_train, y_df_train)\n",
        "# Training acc\n",
        "pred = rf.predict(file_train)\n",
        "accuracy = accuracy_score(pred, y_df_train)\n",
        "print('The training accuracy of the Random Forest is ', accuracy)\n",
        "# Test acc\n",
        "y_hat = rf.predict(file_test)\n",
        "test_accuracy = accuracy_score(y_hat, y_df_test)\n",
        "print('The test accuracy of the Random Forest is ', test_accuracy)\n",
        "# Conf matrix\n",
        "print('\\n Training clasification report:\\n', classification_report(y_df_train, pred))\n",
        "print('\\n confusion matrix:\\n',confusion_matrix(y_df_train, pred))\n",
        "print('\\n Test clasification report:\\n', classification_report(y_df_test, y_hat))\n",
        "print('\\n confusion matrix:\\n',confusion_matrix(y_df_test, y_hat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXIUv_UNWZw6",
        "outputId": "ee217197-5ba7-4f8e-c6a8-8b703e4398f0"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training accuracy of the Random Forest is  0.9834254143646409\n",
            "The test accuracy of the Random Forest is  0.472\n",
            "\n",
            " Training clasification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.97      1.00      0.98       327\n",
            "         1.0       1.00      0.97      0.98       397\n",
            "\n",
            "    accuracy                           0.98       724\n",
            "   macro avg       0.98      0.98      0.98       724\n",
            "weighted avg       0.98      0.98      0.98       724\n",
            "\n",
            "\n",
            " confusion matrix:\n",
            " [[326   1]\n",
            " [ 11 386]]\n",
            "\n",
            " Test clasification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.53      0.52       133\n",
            "         1.0       0.43      0.40      0.42       117\n",
            "\n",
            "    accuracy                           0.47       250\n",
            "   macro avg       0.47      0.47      0.47       250\n",
            "weighted avg       0.47      0.47      0.47       250\n",
            "\n",
            "\n",
            " confusion matrix:\n",
            " [[71 62]\n",
            " [70 47]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-62-30f767e98b6f>:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  rf.fit(file_train, y_df_train)\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_forest.py:583: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GwEQlSZnkAR_"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FtWIaIHMkd_z"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from keras.optimizers import RMSprop,Adam\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D"
      ],
      "metadata": {
        "id": "aA6hPLlXkeCu"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m1, n1 = file_train.shape\n",
        "x_train = np.array(file_train).reshape(m1, n1, 1)\n",
        "m2, n2 = file_test.shape\n",
        "x_test= np.array(file_test).reshape(m2, n2, 1)"
      ],
      "metadata": {
        "id": "_NESJf9JkA3j"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_confusion = np.zeros((2, 2))\n",
        "test_confusion = np.zeros((2, 2))\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 80\n",
        "model = Sequential()\n",
        "model.add(Conv1D(64, 3, activation='relu', input_shape=x_train.shape[1:3]))\n",
        "\n",
        "#model.add(Conv1D(128, 3, activation='relu'))\n",
        "model.add(MaxPooling1D(3))\n",
        "\n",
        "#model.add(Conv1D(128, 3, activation='relu'))\n",
        "model.add(Conv1D(128, 3, activation='relu'))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\"\"\"\n",
        "#model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2, input_shape=x_train.shape[1:3]))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\"\"\"\n",
        "model.compile(loss='binary_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n",
        "print(x_train.shape)\n",
        "# print(filename)\n",
        "# if x_train.shape[0] == 0:\n",
        "#     continue\n",
        "\n",
        "# Train model\n",
        "history = model.fit(x_train, y_df_train,batch_size=batch_size,   epochs=epochs,verbose=1)\n",
        "                \n",
        "             \n",
        "\n",
        "# Training report\n",
        "train_eval = model.evaluate(x_train, y_df_train, verbose=0)\n",
        "print('Training loss:', train_eval[0])\n",
        "print('Training accuracy:', train_eval[1])\n",
        "pred = model.predict(x_train)\n",
        "pred = (pred > 0.5)\n",
        "train_conf = confusion_matrix(y_df_train, pred)\n",
        "train_confusion += train_conf\n",
        "\n",
        "# Test report\n",
        "test_eval = model.evaluate(x_test, y_df_test, verbose=0)\n",
        "print('Test loss:', test_eval[0])\n",
        "print('Test accuracy:',test_eval[1])\n",
        "y_hat = model.predict(x_test)\n",
        "y_hat = (y_hat > 0.5)\n",
        "test_conf = confusion_matrix(y_df_test, y_hat)\n",
        "test_confusion += test_conf\n",
        "print(test_conf)\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pIRXmOrkA6J",
        "outputId": "6375c3c6-c41d-4a87-df5b-ff7c5a2079ca"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(724, 75, 1)\n",
            "Epoch 1/80\n",
            "6/6 [==============================] - 1s 24ms/step - loss: 0.7187 - accuracy: 0.5138\n",
            "Epoch 2/80\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.6929 - accuracy: 0.5180\n",
            "Epoch 3/80\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6924 - accuracy: 0.5290\n",
            "Epoch 4/80\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.6992 - accuracy: 0.5359\n",
            "Epoch 5/80\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6925 - accuracy: 0.5290\n",
            "Epoch 6/80\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.6896 - accuracy: 0.5525\n",
            "Epoch 7/80\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6902 - accuracy: 0.5359\n",
            "Epoch 8/80\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6899 - accuracy: 0.5290\n",
            "Epoch 9/80\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6892 - accuracy: 0.5622\n",
            "Epoch 10/80\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.6889 - accuracy: 0.5387\n",
            "Epoch 11/80\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.6876 - accuracy: 0.5262\n",
            "Epoch 12/80\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6930 - accuracy: 0.5539\n",
            "Epoch 13/80\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6884 - accuracy: 0.5442\n",
            "Epoch 14/80\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6885 - accuracy: 0.5318\n",
            "Epoch 15/80\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6856 - accuracy: 0.5497\n",
            "Epoch 16/80\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6923 - accuracy: 0.5414\n",
            "Epoch 17/80\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.6894 - accuracy: 0.5304\n",
            "Epoch 18/80\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6853 - accuracy: 0.5428\n",
            "Epoch 19/80\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.6879 - accuracy: 0.5525\n",
            "Epoch 20/80\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 0.6872 - accuracy: 0.5525\n",
            "Epoch 21/80\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 0.6870 - accuracy: 0.5235\n",
            "Epoch 22/80\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.6889 - accuracy: 0.5456\n",
            "Epoch 23/80\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.6839 - accuracy: 0.5539\n",
            "Epoch 24/80\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.6876 - accuracy: 0.5608\n",
            "Epoch 25/80\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.6848 - accuracy: 0.5552\n",
            "Epoch 26/80\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 0.6863 - accuracy: 0.5401\n",
            "Epoch 27/80\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 0.6840 - accuracy: 0.5691\n",
            "Epoch 28/80\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.6884 - accuracy: 0.5594\n",
            "Epoch 29/80\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 0.6873 - accuracy: 0.5663\n",
            "Epoch 30/80\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 0.6849 - accuracy: 0.5663\n",
            "Epoch 31/80\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 0.6836 - accuracy: 0.5470\n",
            "Epoch 32/80\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 0.6821 - accuracy: 0.5497\n",
            "Epoch 33/80\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 0.6842 - accuracy: 0.5691\n",
            "Epoch 34/80\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6847 - accuracy: 0.5718\n",
            "Epoch 35/80\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.6820 - accuracy: 0.5483\n",
            "Epoch 36/80\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6817 - accuracy: 0.5663\n",
            "Epoch 37/80\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.6820 - accuracy: 0.5608\n",
            "Epoch 38/80\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.6818 - accuracy: 0.5594\n",
            "Epoch 39/80\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6825 - accuracy: 0.5635\n",
            "Epoch 40/80\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.6813 - accuracy: 0.5552\n",
            "Epoch 41/80\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6821 - accuracy: 0.5594\n",
            "Epoch 42/80\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6817 - accuracy: 0.5649\n",
            "Epoch 43/80\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6857 - accuracy: 0.5787\n",
            "Epoch 44/80\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6872 - accuracy: 0.5622\n",
            "Epoch 45/80\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.6821 - accuracy: 0.5539\n",
            "Epoch 46/80\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.6813 - accuracy: 0.5511\n",
            "Epoch 47/80\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6812 - accuracy: 0.5884\n",
            "Epoch 48/80\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6802 - accuracy: 0.5552\n",
            "Epoch 49/80\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.6822 - accuracy: 0.5691\n",
            "Epoch 50/80\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6766 - accuracy: 0.5801\n",
            "Epoch 51/80\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6831 - accuracy: 0.5691\n",
            "Epoch 52/80\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6819 - accuracy: 0.5511\n",
            "Epoch 53/80\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.6764 - accuracy: 0.5704\n",
            "Epoch 54/80\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.6765 - accuracy: 0.5773\n",
            "Epoch 55/80\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6788 - accuracy: 0.5760\n",
            "Epoch 56/80\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6792 - accuracy: 0.5718\n",
            "Epoch 57/80\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6792 - accuracy: 0.5552\n",
            "Epoch 58/80\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6764 - accuracy: 0.6105\n",
            "Epoch 59/80\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.6739 - accuracy: 0.5691\n",
            "Epoch 60/80\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6742 - accuracy: 0.5691\n",
            "Epoch 61/80\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6841 - accuracy: 0.5663\n",
            "Epoch 62/80\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6709 - accuracy: 0.5815\n",
            "Epoch 63/80\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6748 - accuracy: 0.5801\n",
            "Epoch 64/80\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6776 - accuracy: 0.5732\n",
            "Epoch 65/80\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6723 - accuracy: 0.6091\n",
            "Epoch 66/80\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.6718 - accuracy: 0.6064\n",
            "Epoch 67/80\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6704 - accuracy: 0.5856\n",
            "Epoch 68/80\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.6769 - accuracy: 0.5870\n",
            "Epoch 69/80\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6789 - accuracy: 0.5704\n",
            "Epoch 70/80\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6703 - accuracy: 0.5994\n",
            "Epoch 71/80\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6843 - accuracy: 0.5456\n",
            "Epoch 72/80\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6738 - accuracy: 0.5663\n",
            "Epoch 73/80\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6736 - accuracy: 0.5994\n",
            "Epoch 74/80\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.6701 - accuracy: 0.5898\n",
            "Epoch 75/80\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.6712 - accuracy: 0.6105\n",
            "Epoch 76/80\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6693 - accuracy: 0.5967\n",
            "Epoch 77/80\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.6706 - accuracy: 0.6022\n",
            "Epoch 78/80\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.6695 - accuracy: 0.5801\n",
            "Epoch 79/80\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.6678 - accuracy: 0.5925\n",
            "Epoch 80/80\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6754 - accuracy: 0.5746\n",
            "Training loss: 0.6663974523544312\n",
            "Training accuracy: 0.5621547102928162\n",
            "23/23 [==============================] - 0s 3ms/step\n",
            "Test loss: 0.7116702795028687\n",
            "Test accuracy: 0.47200000286102295\n",
            "8/8 [==============================] - 0s 4ms/step\n",
            "[[  1 132]\n",
            " [  0 117]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_confusion = np.zeros((2, 2))\n",
        "# test_confusion = np.zeros((2, 2))\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 200\n",
        "model = Sequential()\n",
        "model.add(Conv1D(64, 3, activation='relu', input_shape=x_train.shape[1:3]))\n",
        "\n",
        "#model.add(Conv1D(128, 3, activation='relu'))\n",
        "model.add(MaxPooling1D(3))\n",
        "\n",
        "#model.add(Conv1D(128, 3, activation='relu'))\n",
        "model.add(Conv1D(128, 3, activation='relu'))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\"\"\"\n",
        "#model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2, input_shape=x_train.shape[1:3]))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\"\"\"\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "print(x_train.shape)\n",
        "\n",
        "\n",
        "# Train model\n",
        "history = model.fit(x_train, y_df_train,batch_size=batch_size,   epochs=epochs,verbose=1)\n",
        "                \n",
        "             \n",
        "\n",
        "# Training report\n",
        "train_eval = model.evaluate(x_train, y_df_train, verbose=0)\n",
        "print('CNN training loss:', train_eval[0])\n",
        "print('CNN training accuracy:', train_eval[1])\n",
        "pred = model.predict(x_train)\n",
        "pred = (pred > 0.5)\n",
        "train_conf = confusion_matrix(y_df_train, pred)\n",
        "# train_confusion += train_conf\n",
        "print(\"Training confusion matrix \\n\",train_conf)\n",
        "\n",
        "# Test report\n",
        "test_eval = model.evaluate(x_test, y_df_test, verbose=0)\n",
        "print('CNN test loss:', test_eval[0])\n",
        "print('CNN test accuracy:',test_eval[1])\n",
        "y_hat = model.predict(x_test)\n",
        "y_hat = (y_hat > 0.5)\n",
        "test_conf = confusion_matrix(y_df_test, y_hat)\n",
        "# test_confusion += test_conf\n",
        "print(\"Testing confusion matrix \\n\",test_conf)\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rODE3f3GftXI",
        "outputId": "9e0132f8-9fa2-4161-8c7b-8aefc80e7c0f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(724, 75, 1)\n",
            "Epoch 1/200\n",
            "23/23 [==============================] - 1s 10ms/step - loss: 0.7019 - accuracy: 0.5262\n",
            "Epoch 2/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5318\n",
            "Epoch 3/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6911 - accuracy: 0.5456\n",
            "Epoch 4/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6955 - accuracy: 0.5552\n",
            "Epoch 5/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6945 - accuracy: 0.5483\n",
            "Epoch 6/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6908 - accuracy: 0.5373\n",
            "Epoch 7/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5428\n",
            "Epoch 8/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6867 - accuracy: 0.5428\n",
            "Epoch 9/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6874 - accuracy: 0.5511\n",
            "Epoch 10/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6865 - accuracy: 0.5566\n",
            "Epoch 11/200\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.6885 - accuracy: 0.5511\n",
            "Epoch 12/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6849 - accuracy: 0.5483\n",
            "Epoch 13/200\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.6854 - accuracy: 0.5497\n",
            "Epoch 14/200\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.6851 - accuracy: 0.5414\n",
            "Epoch 15/200\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.6836 - accuracy: 0.5594\n",
            "Epoch 16/200\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.6858 - accuracy: 0.5345\n",
            "Epoch 17/200\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.6846 - accuracy: 0.5470\n",
            "Epoch 18/200\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.6841 - accuracy: 0.5608\n",
            "Epoch 19/200\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.6838 - accuracy: 0.5608\n",
            "Epoch 20/200\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.6848 - accuracy: 0.5622\n",
            "Epoch 21/200\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.6909 - accuracy: 0.5594\n",
            "Epoch 22/200\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.6866 - accuracy: 0.5580\n",
            "Epoch 23/200\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.6834 - accuracy: 0.5663\n",
            "Epoch 24/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6844 - accuracy: 0.5470\n",
            "Epoch 25/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6823 - accuracy: 0.5649\n",
            "Epoch 26/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6826 - accuracy: 0.5663\n",
            "Epoch 27/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6835 - accuracy: 0.5608\n",
            "Epoch 28/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6784 - accuracy: 0.5663\n",
            "Epoch 29/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6872 - accuracy: 0.5732\n",
            "Epoch 30/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6833 - accuracy: 0.5539\n",
            "Epoch 31/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6836 - accuracy: 0.5594\n",
            "Epoch 32/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6844 - accuracy: 0.5608\n",
            "Epoch 33/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6845 - accuracy: 0.5580\n",
            "Epoch 34/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6837 - accuracy: 0.5622\n",
            "Epoch 35/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6813 - accuracy: 0.5704\n",
            "Epoch 36/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6798 - accuracy: 0.5649\n",
            "Epoch 37/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6788 - accuracy: 0.5663\n",
            "Epoch 38/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6754 - accuracy: 0.5787\n",
            "Epoch 39/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6771 - accuracy: 0.5815\n",
            "Epoch 40/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6723 - accuracy: 0.6243\n",
            "Epoch 41/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6797 - accuracy: 0.5691\n",
            "Epoch 42/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6777 - accuracy: 0.5414\n",
            "Epoch 43/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6785 - accuracy: 0.5870\n",
            "Epoch 44/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6745 - accuracy: 0.5815\n",
            "Epoch 45/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6668 - accuracy: 0.5953\n",
            "Epoch 46/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6731 - accuracy: 0.6022\n",
            "Epoch 47/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6825 - accuracy: 0.5456\n",
            "Epoch 48/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6754 - accuracy: 0.5912\n",
            "Epoch 49/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6712 - accuracy: 0.5760\n",
            "Epoch 50/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6706 - accuracy: 0.6036\n",
            "Epoch 51/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6716 - accuracy: 0.5870\n",
            "Epoch 52/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6716 - accuracy: 0.5981\n",
            "Epoch 53/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6672 - accuracy: 0.6202\n",
            "Epoch 54/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6692 - accuracy: 0.5939\n",
            "Epoch 55/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6605 - accuracy: 0.6174\n",
            "Epoch 56/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6621 - accuracy: 0.6050\n",
            "Epoch 57/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6565 - accuracy: 0.6271\n",
            "Epoch 58/200\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.6603 - accuracy: 0.6050\n",
            "Epoch 59/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6562 - accuracy: 0.6202\n",
            "Epoch 60/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6617 - accuracy: 0.6133\n",
            "Epoch 61/200\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.6578 - accuracy: 0.6450\n",
            "Epoch 62/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6577 - accuracy: 0.6271\n",
            "Epoch 63/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6520 - accuracy: 0.6285\n",
            "Epoch 64/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6515 - accuracy: 0.6381\n",
            "Epoch 65/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6520 - accuracy: 0.6354\n",
            "Epoch 66/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6526 - accuracy: 0.6312\n",
            "Epoch 67/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6498 - accuracy: 0.6257\n",
            "Epoch 68/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6424 - accuracy: 0.6506\n",
            "Epoch 69/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6460 - accuracy: 0.6119\n",
            "Epoch 70/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6408 - accuracy: 0.6450\n",
            "Epoch 71/200\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.6459 - accuracy: 0.6298\n",
            "Epoch 72/200\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.6336 - accuracy: 0.6657\n",
            "Epoch 73/200\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.6406 - accuracy: 0.6215\n",
            "Epoch 74/200\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.6372 - accuracy: 0.6450\n",
            "Epoch 75/200\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.6431 - accuracy: 0.6436\n",
            "Epoch 76/200\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.6338 - accuracy: 0.6354\n",
            "Epoch 77/200\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.6308 - accuracy: 0.6423\n",
            "Epoch 78/200\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.6268 - accuracy: 0.6796\n",
            "Epoch 79/200\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.6212 - accuracy: 0.6740\n",
            "Epoch 80/200\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.6336 - accuracy: 0.6547\n",
            "Epoch 81/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6281 - accuracy: 0.6506\n",
            "Epoch 82/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6256 - accuracy: 0.6506\n",
            "Epoch 83/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6160 - accuracy: 0.6713\n",
            "Epoch 84/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6282 - accuracy: 0.6588\n",
            "Epoch 85/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6220 - accuracy: 0.6809\n",
            "Epoch 86/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6221 - accuracy: 0.6699\n",
            "Epoch 87/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6165 - accuracy: 0.6768\n",
            "Epoch 88/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6048 - accuracy: 0.6837\n",
            "Epoch 89/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6087 - accuracy: 0.6823\n",
            "Epoch 90/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6233 - accuracy: 0.6354\n",
            "Epoch 91/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6096 - accuracy: 0.6754\n",
            "Epoch 92/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6045 - accuracy: 0.6837\n",
            "Epoch 93/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6148 - accuracy: 0.6588\n",
            "Epoch 94/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6285 - accuracy: 0.6657\n",
            "Epoch 95/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6169 - accuracy: 0.6644\n",
            "Epoch 96/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6045 - accuracy: 0.6754\n",
            "Epoch 97/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6011 - accuracy: 0.6837\n",
            "Epoch 98/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5981 - accuracy: 0.6878\n",
            "Epoch 99/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5950 - accuracy: 0.6865\n",
            "Epoch 100/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5977 - accuracy: 0.6754\n",
            "Epoch 101/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5990 - accuracy: 0.6685\n",
            "Epoch 102/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5928 - accuracy: 0.6961\n",
            "Epoch 103/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6039 - accuracy: 0.6754\n",
            "Epoch 104/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5951 - accuracy: 0.6685\n",
            "Epoch 105/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5832 - accuracy: 0.7017\n",
            "Epoch 106/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5878 - accuracy: 0.6906\n",
            "Epoch 107/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5829 - accuracy: 0.6961\n",
            "Epoch 108/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5975 - accuracy: 0.6837\n",
            "Epoch 109/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5870 - accuracy: 0.6906\n",
            "Epoch 110/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5845 - accuracy: 0.7169\n",
            "Epoch 111/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5809 - accuracy: 0.7155\n",
            "Epoch 112/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5830 - accuracy: 0.7058\n",
            "Epoch 113/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5801 - accuracy: 0.6865\n",
            "Epoch 114/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5740 - accuracy: 0.7320\n",
            "Epoch 115/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6192 - accuracy: 0.6602\n",
            "Epoch 116/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5716 - accuracy: 0.7113\n",
            "Epoch 117/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5743 - accuracy: 0.6961\n",
            "Epoch 118/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5627 - accuracy: 0.7058\n",
            "Epoch 119/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5744 - accuracy: 0.6975\n",
            "Epoch 120/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5750 - accuracy: 0.7044\n",
            "Epoch 121/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5656 - accuracy: 0.7017\n",
            "Epoch 122/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5601 - accuracy: 0.7086\n",
            "Epoch 123/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5596 - accuracy: 0.7265\n",
            "Epoch 124/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5636 - accuracy: 0.7348\n",
            "Epoch 125/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5504 - accuracy: 0.7210\n",
            "Epoch 126/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5573 - accuracy: 0.7362\n",
            "Epoch 127/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5620 - accuracy: 0.7099\n",
            "Epoch 128/200\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.5584 - accuracy: 0.7251\n",
            "Epoch 129/200\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.5662 - accuracy: 0.7210\n",
            "Epoch 130/200\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.5735 - accuracy: 0.6934\n",
            "Epoch 131/200\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.5536 - accuracy: 0.7293\n",
            "Epoch 132/200\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.5558 - accuracy: 0.7196\n",
            "Epoch 133/200\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.5771 - accuracy: 0.6809\n",
            "Epoch 134/200\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.5756 - accuracy: 0.6961\n",
            "Epoch 135/200\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.5667 - accuracy: 0.7196\n",
            "Epoch 136/200\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.5311 - accuracy: 0.7417\n",
            "Epoch 137/200\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.5409 - accuracy: 0.7293\n",
            "Epoch 138/200\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.5468 - accuracy: 0.7293\n",
            "Epoch 139/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5324 - accuracy: 0.7514\n",
            "Epoch 140/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5351 - accuracy: 0.7417\n",
            "Epoch 141/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5398 - accuracy: 0.7376\n",
            "Epoch 142/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5254 - accuracy: 0.7514\n",
            "Epoch 143/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5220 - accuracy: 0.7528\n",
            "Epoch 144/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5189 - accuracy: 0.7459\n",
            "Epoch 145/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5327 - accuracy: 0.7500\n",
            "Epoch 146/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5248 - accuracy: 0.7541\n",
            "Epoch 147/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5243 - accuracy: 0.7431\n",
            "Epoch 148/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5193 - accuracy: 0.7638\n",
            "Epoch 149/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5418 - accuracy: 0.7072\n",
            "Epoch 150/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5444 - accuracy: 0.7459\n",
            "Epoch 151/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5386 - accuracy: 0.7334\n",
            "Epoch 152/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5308 - accuracy: 0.7500\n",
            "Epoch 153/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5279 - accuracy: 0.7486\n",
            "Epoch 154/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5222 - accuracy: 0.7431\n",
            "Epoch 155/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5364 - accuracy: 0.7376\n",
            "Epoch 156/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5196 - accuracy: 0.7624\n",
            "Epoch 157/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5297 - accuracy: 0.7238\n",
            "Epoch 158/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5265 - accuracy: 0.7555\n",
            "Epoch 159/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5500 - accuracy: 0.7141\n",
            "Epoch 160/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5344 - accuracy: 0.7348\n",
            "Epoch 161/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5032 - accuracy: 0.7610\n",
            "Epoch 162/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5076 - accuracy: 0.7721\n",
            "Epoch 163/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5138 - accuracy: 0.7459\n",
            "Epoch 164/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5040 - accuracy: 0.7624\n",
            "Epoch 165/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4948 - accuracy: 0.7749\n",
            "Epoch 166/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5315 - accuracy: 0.7472\n",
            "Epoch 167/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5085 - accuracy: 0.7528\n",
            "Epoch 168/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5143 - accuracy: 0.7597\n",
            "Epoch 169/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5133 - accuracy: 0.7445\n",
            "Epoch 170/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5126 - accuracy: 0.7486\n",
            "Epoch 171/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5007 - accuracy: 0.7804\n",
            "Epoch 172/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5019 - accuracy: 0.7569\n",
            "Epoch 173/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5210 - accuracy: 0.7417\n",
            "Epoch 174/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4836 - accuracy: 0.7928\n",
            "Epoch 175/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4837 - accuracy: 0.7873\n",
            "Epoch 176/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4983 - accuracy: 0.7693\n",
            "Epoch 177/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4975 - accuracy: 0.7597\n",
            "Epoch 178/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4897 - accuracy: 0.7652\n",
            "Epoch 179/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4876 - accuracy: 0.7569\n",
            "Epoch 180/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4886 - accuracy: 0.7749\n",
            "Epoch 181/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4838 - accuracy: 0.7707\n",
            "Epoch 182/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4965 - accuracy: 0.7569\n",
            "Epoch 183/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4787 - accuracy: 0.7845\n",
            "Epoch 184/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4859 - accuracy: 0.7790\n",
            "Epoch 185/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4846 - accuracy: 0.7901\n",
            "Epoch 186/200\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.4800 - accuracy: 0.7666\n",
            "Epoch 187/200\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.4684 - accuracy: 0.7983\n",
            "Epoch 188/200\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.4671 - accuracy: 0.7873\n",
            "Epoch 189/200\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.4453 - accuracy: 0.8094\n",
            "Epoch 190/200\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.4780 - accuracy: 0.7845\n",
            "Epoch 191/200\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.4771 - accuracy: 0.7901\n",
            "Epoch 192/200\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.5042 - accuracy: 0.7390\n",
            "Epoch 193/200\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.4656 - accuracy: 0.8066\n",
            "Epoch 194/200\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.4627 - accuracy: 0.7942\n",
            "Epoch 195/200\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.4679 - accuracy: 0.7956\n",
            "Epoch 196/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4678 - accuracy: 0.7983\n",
            "Epoch 197/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4534 - accuracy: 0.8025\n",
            "Epoch 198/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4812 - accuracy: 0.7721\n",
            "Epoch 199/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4660 - accuracy: 0.7776\n",
            "Epoch 200/200\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4675 - accuracy: 0.7887\n",
            "CNN training loss: 0.4386020600795746\n",
            "CNN training accuracy: 0.830110490322113\n",
            "23/23 [==============================] - 0s 4ms/step\n",
            "Training confusion matrix \n",
            " [[303  24]\n",
            " [ 99 298]]\n",
            "CNN test loss: 0.766356348991394\n",
            "CNN test accuracy: 0.515999972820282\n",
            "8/8 [==============================] - 0s 4ms/step\n",
            "Testing confusion matrix \n",
            " [[79 54]\n",
            " [67 50]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_confusion = np.zeros((2, 2))\n",
        "# test_confusion = np.zeros((2, 2))\n",
        "\n",
        "batch_size = 16\n",
        "epochs = 500\n",
        "model = Sequential()\n",
        "model.add(Conv1D(64, 3, activation='relu', input_shape=x_train.shape[1:3]))\n",
        "\n",
        "#model.add(Conv1D(128, 3, activation='relu'))\n",
        "model.add(MaxPooling1D(3))\n",
        "\n",
        "#model.add(Conv1D(128, 3, activation='relu'))\n",
        "model.add(Conv1D(128, 3, activation='relu'))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\"\"\"\n",
        "#model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2, input_shape=x_train.shape[1:3]))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\"\"\"\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "print(x_train.shape)\n",
        "\n",
        "\n",
        "# Train model\n",
        "history = model.fit(x_train, y_df_train,batch_size=batch_size,   epochs=epochs,verbose=1)\n",
        "                \n",
        "             \n",
        "\n",
        "# Training report\n",
        "train_eval = model.evaluate(x_train, y_df_train, verbose=0)\n",
        "print('CNN training loss:', train_eval[0])\n",
        "print('CNN training accuracy:', train_eval[1])\n",
        "pred = model.predict(x_train)\n",
        "pred = (pred > 0.5)\n",
        "train_conf = confusion_matrix(y_df_train, pred)\n",
        "# train_confusion += train_conf\n",
        "print(\"Training confusion matrix \\n\",train_conf)\n",
        "\n",
        "# Test report\n",
        "test_eval = model.evaluate(x_test, y_df_test, verbose=0)\n",
        "print('CNN test loss:', test_eval[0])\n",
        "print('CNN test accuracy:',test_eval[1])\n",
        "y_hat = model.predict(x_test)\n",
        "y_hat = (y_hat > 0.5)\n",
        "test_conf = confusion_matrix(y_df_test, y_hat)\n",
        "# test_confusion += test_conf\n",
        "print(\"Testing confusion matrix \\n\",test_conf)\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPXDOLe4kYjx",
        "outputId": "a8cf49e9-58f8-437a-b003-ea9c30a23014"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(724, 75, 1)\n",
            "Epoch 1/500\n",
            "46/46 [==============================] - 1s 6ms/step - loss: 0.6978 - accuracy: 0.5207\n",
            "Epoch 2/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.6900 - accuracy: 0.5539\n",
            "Epoch 3/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6901 - accuracy: 0.5401\n",
            "Epoch 4/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6941 - accuracy: 0.5525\n",
            "Epoch 5/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6988 - accuracy: 0.5069\n",
            "Epoch 6/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6909 - accuracy: 0.5359\n",
            "Epoch 7/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.6902 - accuracy: 0.5318\n",
            "Epoch 8/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6895 - accuracy: 0.5414\n",
            "Epoch 9/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6879 - accuracy: 0.5483\n",
            "Epoch 10/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.6861 - accuracy: 0.5552\n",
            "Epoch 11/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.6889 - accuracy: 0.5442\n",
            "Epoch 12/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6869 - accuracy: 0.5456\n",
            "Epoch 13/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6859 - accuracy: 0.5580\n",
            "Epoch 14/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5483\n",
            "Epoch 15/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.6883 - accuracy: 0.5511\n",
            "Epoch 16/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.6865 - accuracy: 0.5456\n",
            "Epoch 17/500\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 0.6882 - accuracy: 0.5497\n",
            "Epoch 18/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.6877 - accuracy: 0.5483\n",
            "Epoch 19/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.6861 - accuracy: 0.5511\n",
            "Epoch 20/500\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 0.6901 - accuracy: 0.5304\n",
            "Epoch 21/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6854 - accuracy: 0.5483\n",
            "Epoch 22/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6855 - accuracy: 0.5483\n",
            "Epoch 23/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6822 - accuracy: 0.5497\n",
            "Epoch 24/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6858 - accuracy: 0.5483\n",
            "Epoch 25/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6863 - accuracy: 0.5497\n",
            "Epoch 26/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6883 - accuracy: 0.5580\n",
            "Epoch 27/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6854 - accuracy: 0.5483\n",
            "Epoch 28/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6847 - accuracy: 0.5608\n",
            "Epoch 29/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6826 - accuracy: 0.5525\n",
            "Epoch 30/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6850 - accuracy: 0.5691\n",
            "Epoch 31/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6849 - accuracy: 0.5580\n",
            "Epoch 32/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6850 - accuracy: 0.5525\n",
            "Epoch 33/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6823 - accuracy: 0.5608\n",
            "Epoch 34/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6816 - accuracy: 0.5428\n",
            "Epoch 35/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6813 - accuracy: 0.5691\n",
            "Epoch 36/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6795 - accuracy: 0.5718\n",
            "Epoch 37/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.6873 - accuracy: 0.5552\n",
            "Epoch 38/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6797 - accuracy: 0.5829\n",
            "Epoch 39/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6806 - accuracy: 0.5635\n",
            "Epoch 40/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6802 - accuracy: 0.5691\n",
            "Epoch 41/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6784 - accuracy: 0.5663\n",
            "Epoch 42/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6822 - accuracy: 0.5635\n",
            "Epoch 43/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6759 - accuracy: 0.5967\n",
            "Epoch 44/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.6737 - accuracy: 0.6022\n",
            "Epoch 45/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6794 - accuracy: 0.5760\n",
            "Epoch 46/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6731 - accuracy: 0.5856\n",
            "Epoch 47/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6714 - accuracy: 0.6188\n",
            "Epoch 48/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6693 - accuracy: 0.6036\n",
            "Epoch 49/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6707 - accuracy: 0.6022\n",
            "Epoch 50/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6699 - accuracy: 0.6091\n",
            "Epoch 51/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.6677 - accuracy: 0.6064\n",
            "Epoch 52/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.6631 - accuracy: 0.5967\n",
            "Epoch 53/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6753 - accuracy: 0.5704\n",
            "Epoch 54/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6653 - accuracy: 0.6257\n",
            "Epoch 55/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6631 - accuracy: 0.6091\n",
            "Epoch 56/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6584 - accuracy: 0.5967\n",
            "Epoch 57/500\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 0.6679 - accuracy: 0.5994\n",
            "Epoch 58/500\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 0.6549 - accuracy: 0.6326\n",
            "Epoch 59/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.6549 - accuracy: 0.6271\n",
            "Epoch 60/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.6560 - accuracy: 0.6091\n",
            "Epoch 61/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.6473 - accuracy: 0.6492\n",
            "Epoch 62/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.6508 - accuracy: 0.6285\n",
            "Epoch 63/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.6504 - accuracy: 0.6119\n",
            "Epoch 64/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6490 - accuracy: 0.6312\n",
            "Epoch 65/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6485 - accuracy: 0.6395\n",
            "Epoch 66/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6489 - accuracy: 0.6312\n",
            "Epoch 67/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6523 - accuracy: 0.6243\n",
            "Epoch 68/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6471 - accuracy: 0.6215\n",
            "Epoch 69/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6415 - accuracy: 0.6533\n",
            "Epoch 70/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6385 - accuracy: 0.6533\n",
            "Epoch 71/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6207 - accuracy: 0.6754\n",
            "Epoch 72/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6287 - accuracy: 0.6602\n",
            "Epoch 73/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6371 - accuracy: 0.6464\n",
            "Epoch 74/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6230 - accuracy: 0.6575\n",
            "Epoch 75/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6333 - accuracy: 0.6409\n",
            "Epoch 76/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6154 - accuracy: 0.6699\n",
            "Epoch 77/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6195 - accuracy: 0.6644\n",
            "Epoch 78/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6188 - accuracy: 0.6809\n",
            "Epoch 79/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6151 - accuracy: 0.6602\n",
            "Epoch 80/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.6266 - accuracy: 0.6367\n",
            "Epoch 81/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6273 - accuracy: 0.6478\n",
            "Epoch 82/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6136 - accuracy: 0.6630\n",
            "Epoch 83/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6127 - accuracy: 0.6837\n",
            "Epoch 84/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6226 - accuracy: 0.6533\n",
            "Epoch 85/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.6122 - accuracy: 0.6671\n",
            "Epoch 86/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6096 - accuracy: 0.6685\n",
            "Epoch 87/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6130 - accuracy: 0.6713\n",
            "Epoch 88/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.6114 - accuracy: 0.6796\n",
            "Epoch 89/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.5932 - accuracy: 0.6948\n",
            "Epoch 90/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.5938 - accuracy: 0.6961\n",
            "Epoch 91/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.5942 - accuracy: 0.7003\n",
            "Epoch 92/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.5922 - accuracy: 0.7003\n",
            "Epoch 93/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.5818 - accuracy: 0.7044\n",
            "Epoch 94/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.5915 - accuracy: 0.6906\n",
            "Epoch 95/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.5866 - accuracy: 0.7017\n",
            "Epoch 96/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.5748 - accuracy: 0.7113\n",
            "Epoch 97/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.5774 - accuracy: 0.6989\n",
            "Epoch 98/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.6040 - accuracy: 0.6685\n",
            "Epoch 99/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.5805 - accuracy: 0.7058\n",
            "Epoch 100/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.5752 - accuracy: 0.6948\n",
            "Epoch 101/500\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 0.5669 - accuracy: 0.7072\n",
            "Epoch 102/500\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 0.5636 - accuracy: 0.7113\n",
            "Epoch 103/500\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 0.5767 - accuracy: 0.6906\n",
            "Epoch 104/500\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 0.5769 - accuracy: 0.7210\n",
            "Epoch 105/500\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 0.5781 - accuracy: 0.7086\n",
            "Epoch 106/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.5540 - accuracy: 0.7224\n",
            "Epoch 107/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.5617 - accuracy: 0.7251\n",
            "Epoch 108/500\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 0.5572 - accuracy: 0.7334\n",
            "Epoch 109/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.5526 - accuracy: 0.7334\n",
            "Epoch 110/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.5678 - accuracy: 0.7113\n",
            "Epoch 111/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.5582 - accuracy: 0.7279\n",
            "Epoch 112/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.5611 - accuracy: 0.7196\n",
            "Epoch 113/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.5720 - accuracy: 0.7127\n",
            "Epoch 114/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.5551 - accuracy: 0.7279\n",
            "Epoch 115/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.5527 - accuracy: 0.7320\n",
            "Epoch 116/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.5517 - accuracy: 0.7417\n",
            "Epoch 117/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.5342 - accuracy: 0.7445\n",
            "Epoch 118/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.5352 - accuracy: 0.7348\n",
            "Epoch 119/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.5289 - accuracy: 0.7472\n",
            "Epoch 120/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.5310 - accuracy: 0.7638\n",
            "Epoch 121/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.5208 - accuracy: 0.7500\n",
            "Epoch 122/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.5492 - accuracy: 0.7279\n",
            "Epoch 123/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.5521 - accuracy: 0.7210\n",
            "Epoch 124/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.5215 - accuracy: 0.7514\n",
            "Epoch 125/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.5151 - accuracy: 0.7417\n",
            "Epoch 126/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.5293 - accuracy: 0.7431\n",
            "Epoch 127/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.5254 - accuracy: 0.7583\n",
            "Epoch 128/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.5297 - accuracy: 0.7431\n",
            "Epoch 129/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.5183 - accuracy: 0.7555\n",
            "Epoch 130/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.5399 - accuracy: 0.7251\n",
            "Epoch 131/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.5212 - accuracy: 0.7514\n",
            "Epoch 132/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.5171 - accuracy: 0.7472\n",
            "Epoch 133/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.5127 - accuracy: 0.7514\n",
            "Epoch 134/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.5013 - accuracy: 0.7652\n",
            "Epoch 135/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.5031 - accuracy: 0.7666\n",
            "Epoch 136/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.4972 - accuracy: 0.7652\n",
            "Epoch 137/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.5002 - accuracy: 0.7555\n",
            "Epoch 138/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.5023 - accuracy: 0.7569\n",
            "Epoch 139/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.5021 - accuracy: 0.7583\n",
            "Epoch 140/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.5076 - accuracy: 0.7624\n",
            "Epoch 141/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.4996 - accuracy: 0.7735\n",
            "Epoch 142/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.4895 - accuracy: 0.7486\n",
            "Epoch 143/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4908 - accuracy: 0.7845\n",
            "Epoch 144/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4975 - accuracy: 0.7555\n",
            "Epoch 145/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.4979 - accuracy: 0.7749\n",
            "Epoch 146/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.4874 - accuracy: 0.7693\n",
            "Epoch 147/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.4779 - accuracy: 0.7845\n",
            "Epoch 148/500\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 0.4744 - accuracy: 0.7997\n",
            "Epoch 149/500\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 0.4814 - accuracy: 0.7680\n",
            "Epoch 150/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.4921 - accuracy: 0.7638\n",
            "Epoch 151/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.4869 - accuracy: 0.7693\n",
            "Epoch 152/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.5004 - accuracy: 0.7610\n",
            "Epoch 153/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4627 - accuracy: 0.7707\n",
            "Epoch 154/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4612 - accuracy: 0.7970\n",
            "Epoch 155/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.4712 - accuracy: 0.7749\n",
            "Epoch 156/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4722 - accuracy: 0.7845\n",
            "Epoch 157/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4941 - accuracy: 0.7583\n",
            "Epoch 158/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4883 - accuracy: 0.7818\n",
            "Epoch 159/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4727 - accuracy: 0.7901\n",
            "Epoch 160/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4630 - accuracy: 0.8052\n",
            "Epoch 161/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4493 - accuracy: 0.7997\n",
            "Epoch 162/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4764 - accuracy: 0.7735\n",
            "Epoch 163/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4615 - accuracy: 0.7873\n",
            "Epoch 164/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4320 - accuracy: 0.8025\n",
            "Epoch 165/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4569 - accuracy: 0.7970\n",
            "Epoch 166/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4399 - accuracy: 0.8218\n",
            "Epoch 167/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4547 - accuracy: 0.7845\n",
            "Epoch 168/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.4522 - accuracy: 0.7831\n",
            "Epoch 169/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4503 - accuracy: 0.7970\n",
            "Epoch 170/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4334 - accuracy: 0.8177\n",
            "Epoch 171/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4346 - accuracy: 0.8039\n",
            "Epoch 172/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4615 - accuracy: 0.7831\n",
            "Epoch 173/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4445 - accuracy: 0.8052\n",
            "Epoch 174/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4296 - accuracy: 0.8163\n",
            "Epoch 175/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.8039\n",
            "Epoch 176/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.8204\n",
            "Epoch 177/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4275 - accuracy: 0.8218\n",
            "Epoch 178/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.4381 - accuracy: 0.7970\n",
            "Epoch 179/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4299 - accuracy: 0.8025\n",
            "Epoch 180/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.8273\n",
            "Epoch 181/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.8135\n",
            "Epoch 182/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.8246\n",
            "Epoch 183/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4304 - accuracy: 0.7928\n",
            "Epoch 184/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4346 - accuracy: 0.8066\n",
            "Epoch 185/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4292 - accuracy: 0.8066\n",
            "Epoch 186/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3994 - accuracy: 0.8329\n",
            "Epoch 187/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.8039\n",
            "Epoch 188/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.8370\n",
            "Epoch 189/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.4053 - accuracy: 0.8204\n",
            "Epoch 190/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.3974 - accuracy: 0.8398\n",
            "Epoch 191/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.4624 - accuracy: 0.7721\n",
            "Epoch 192/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.4195 - accuracy: 0.8094\n",
            "Epoch 193/500\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 0.3863 - accuracy: 0.8273\n",
            "Epoch 194/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.4159 - accuracy: 0.8108\n",
            "Epoch 195/500\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 0.3980 - accuracy: 0.8163\n",
            "Epoch 196/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.3954 - accuracy: 0.8398\n",
            "Epoch 197/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4030 - accuracy: 0.8301\n",
            "Epoch 198/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.8177\n",
            "Epoch 199/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4176 - accuracy: 0.8191\n",
            "Epoch 200/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4311 - accuracy: 0.8163\n",
            "Epoch 201/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.8315\n",
            "Epoch 202/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3760 - accuracy: 0.8329\n",
            "Epoch 203/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3812 - accuracy: 0.8412\n",
            "Epoch 204/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3945 - accuracy: 0.8356\n",
            "Epoch 205/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4035 - accuracy: 0.8122\n",
            "Epoch 206/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4030 - accuracy: 0.8273\n",
            "Epoch 207/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3533 - accuracy: 0.8550\n",
            "Epoch 208/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3930 - accuracy: 0.8260\n",
            "Epoch 209/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3830 - accuracy: 0.8439\n",
            "Epoch 210/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3692 - accuracy: 0.8494\n",
            "Epoch 211/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3774 - accuracy: 0.8453\n",
            "Epoch 212/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3729 - accuracy: 0.8494\n",
            "Epoch 213/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.8356\n",
            "Epoch 214/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.8425\n",
            "Epoch 215/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3756 - accuracy: 0.8453\n",
            "Epoch 216/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3692 - accuracy: 0.8481\n",
            "Epoch 217/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3500 - accuracy: 0.8757\n",
            "Epoch 218/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3591 - accuracy: 0.8522\n",
            "Epoch 219/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3629 - accuracy: 0.8564\n",
            "Epoch 220/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3899 - accuracy: 0.8370\n",
            "Epoch 221/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3907 - accuracy: 0.8315\n",
            "Epoch 222/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3609 - accuracy: 0.8467\n",
            "Epoch 223/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3904 - accuracy: 0.8218\n",
            "Epoch 224/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3665 - accuracy: 0.8494\n",
            "Epoch 225/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3390 - accuracy: 0.8536\n",
            "Epoch 226/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3406 - accuracy: 0.8564\n",
            "Epoch 227/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3321 - accuracy: 0.8605\n",
            "Epoch 228/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3307 - accuracy: 0.8729\n",
            "Epoch 229/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3422 - accuracy: 0.8591\n",
            "Epoch 230/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3427 - accuracy: 0.8619\n",
            "Epoch 231/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3544 - accuracy: 0.8536\n",
            "Epoch 232/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.3401 - accuracy: 0.8522\n",
            "Epoch 233/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.3409 - accuracy: 0.8660\n",
            "Epoch 234/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.3689 - accuracy: 0.8494\n",
            "Epoch 235/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.3320 - accuracy: 0.8729\n",
            "Epoch 236/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.3505 - accuracy: 0.8536\n",
            "Epoch 237/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.3253 - accuracy: 0.8729\n",
            "Epoch 238/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.3308 - accuracy: 0.8660\n",
            "Epoch 239/500\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 0.3238 - accuracy: 0.8633\n",
            "Epoch 240/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3638 - accuracy: 0.8481\n",
            "Epoch 241/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3264 - accuracy: 0.8757\n",
            "Epoch 242/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3438 - accuracy: 0.8564\n",
            "Epoch 243/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3483 - accuracy: 0.8674\n",
            "Epoch 244/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3431 - accuracy: 0.8591\n",
            "Epoch 245/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3462 - accuracy: 0.8453\n",
            "Epoch 246/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3262 - accuracy: 0.8605\n",
            "Epoch 247/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3300 - accuracy: 0.8757\n",
            "Epoch 248/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3374 - accuracy: 0.8688\n",
            "Epoch 249/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3273 - accuracy: 0.8743\n",
            "Epoch 250/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3325 - accuracy: 0.8619\n",
            "Epoch 251/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3112 - accuracy: 0.8688\n",
            "Epoch 252/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3194 - accuracy: 0.8757\n",
            "Epoch 253/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3219 - accuracy: 0.8688\n",
            "Epoch 254/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3455 - accuracy: 0.8550\n",
            "Epoch 255/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3121 - accuracy: 0.8854\n",
            "Epoch 256/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3220 - accuracy: 0.8646\n",
            "Epoch 257/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3176 - accuracy: 0.8605\n",
            "Epoch 258/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3274 - accuracy: 0.8591\n",
            "Epoch 259/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3039 - accuracy: 0.8798\n",
            "Epoch 260/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3204 - accuracy: 0.8688\n",
            "Epoch 261/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3230 - accuracy: 0.8729\n",
            "Epoch 262/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.3142 - accuracy: 0.8619\n",
            "Epoch 263/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3012 - accuracy: 0.8812\n",
            "Epoch 264/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3139 - accuracy: 0.8743\n",
            "Epoch 265/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3026 - accuracy: 0.8785\n",
            "Epoch 266/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2866 - accuracy: 0.8978\n",
            "Epoch 267/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2955 - accuracy: 0.8757\n",
            "Epoch 268/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3104 - accuracy: 0.8715\n",
            "Epoch 269/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2990 - accuracy: 0.8840\n",
            "Epoch 270/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3064 - accuracy: 0.8702\n",
            "Epoch 271/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3184 - accuracy: 0.8660\n",
            "Epoch 272/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3190 - accuracy: 0.8729\n",
            "Epoch 273/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3200 - accuracy: 0.8660\n",
            "Epoch 274/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2975 - accuracy: 0.8909\n",
            "Epoch 275/500\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 0.2906 - accuracy: 0.8826\n",
            "Epoch 276/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.2973 - accuracy: 0.8743\n",
            "Epoch 277/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.2712 - accuracy: 0.9088\n",
            "Epoch 278/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.3093 - accuracy: 0.8660\n",
            "Epoch 279/500\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 0.2741 - accuracy: 0.8950\n",
            "Epoch 280/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.3002 - accuracy: 0.8826\n",
            "Epoch 281/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.2633 - accuracy: 0.8936\n",
            "Epoch 282/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.3078 - accuracy: 0.8702\n",
            "Epoch 283/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2916 - accuracy: 0.8812\n",
            "Epoch 284/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2854 - accuracy: 0.8936\n",
            "Epoch 285/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3005 - accuracy: 0.8674\n",
            "Epoch 286/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3048 - accuracy: 0.8826\n",
            "Epoch 287/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3061 - accuracy: 0.8867\n",
            "Epoch 288/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3182 - accuracy: 0.8619\n",
            "Epoch 289/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2746 - accuracy: 0.8964\n",
            "Epoch 290/500\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2737 - accuracy: 0.8923\n",
            "Epoch 291/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2600 - accuracy: 0.8964\n",
            "Epoch 292/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2830 - accuracy: 0.8923\n",
            "Epoch 293/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2758 - accuracy: 0.8964\n",
            "Epoch 294/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2713 - accuracy: 0.9019\n",
            "Epoch 295/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2722 - accuracy: 0.8992\n",
            "Epoch 296/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2698 - accuracy: 0.9075\n",
            "Epoch 297/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2696 - accuracy: 0.8964\n",
            "Epoch 298/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2840 - accuracy: 0.8826\n",
            "Epoch 299/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2881 - accuracy: 0.8881\n",
            "Epoch 300/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2687 - accuracy: 0.9006\n",
            "Epoch 301/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2508 - accuracy: 0.8950\n",
            "Epoch 302/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3073 - accuracy: 0.8812\n",
            "Epoch 303/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2480 - accuracy: 0.9047\n",
            "Epoch 304/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2434 - accuracy: 0.9033\n",
            "Epoch 305/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2486 - accuracy: 0.9006\n",
            "Epoch 306/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2598 - accuracy: 0.8978\n",
            "Epoch 307/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2871 - accuracy: 0.8840\n",
            "Epoch 308/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2524 - accuracy: 0.9047\n",
            "Epoch 309/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.2753 - accuracy: 0.8895\n",
            "Epoch 310/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2635 - accuracy: 0.8978\n",
            "Epoch 311/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2364 - accuracy: 0.9130\n",
            "Epoch 312/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2356 - accuracy: 0.9199\n",
            "Epoch 313/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2617 - accuracy: 0.8992\n",
            "Epoch 314/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2800 - accuracy: 0.8812\n",
            "Epoch 315/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2484 - accuracy: 0.9061\n",
            "Epoch 316/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2708 - accuracy: 0.8881\n",
            "Epoch 317/500\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 0.2504 - accuracy: 0.9102\n",
            "Epoch 318/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.2495 - accuracy: 0.8950\n",
            "Epoch 319/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.2643 - accuracy: 0.8909\n",
            "Epoch 320/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.2516 - accuracy: 0.9075\n",
            "Epoch 321/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.2569 - accuracy: 0.8936\n",
            "Epoch 322/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.2458 - accuracy: 0.9061\n",
            "Epoch 323/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.2380 - accuracy: 0.9006\n",
            "Epoch 324/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.2510 - accuracy: 0.9033\n",
            "Epoch 325/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2636 - accuracy: 0.8895\n",
            "Epoch 326/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2516 - accuracy: 0.9047\n",
            "Epoch 327/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2595 - accuracy: 0.8950\n",
            "Epoch 328/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2475 - accuracy: 0.9047\n",
            "Epoch 329/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2445 - accuracy: 0.9006\n",
            "Epoch 330/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2341 - accuracy: 0.9075\n",
            "Epoch 331/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2198 - accuracy: 0.9157\n",
            "Epoch 332/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2307 - accuracy: 0.9075\n",
            "Epoch 333/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2427 - accuracy: 0.9102\n",
            "Epoch 334/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2247 - accuracy: 0.9130\n",
            "Epoch 335/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2338 - accuracy: 0.9102\n",
            "Epoch 336/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2593 - accuracy: 0.9019\n",
            "Epoch 337/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2354 - accuracy: 0.9144\n",
            "Epoch 338/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.2302 - accuracy: 0.9061\n",
            "Epoch 339/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1996 - accuracy: 0.9268\n",
            "Epoch 340/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2126 - accuracy: 0.9282\n",
            "Epoch 341/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2730 - accuracy: 0.8798\n",
            "Epoch 342/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2320 - accuracy: 0.9185\n",
            "Epoch 343/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2220 - accuracy: 0.9227\n",
            "Epoch 344/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2110 - accuracy: 0.9296\n",
            "Epoch 345/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2456 - accuracy: 0.9047\n",
            "Epoch 346/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.2269 - accuracy: 0.9171\n",
            "Epoch 347/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2210 - accuracy: 0.9144\n",
            "Epoch 348/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.2325 - accuracy: 0.9088\n",
            "Epoch 349/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2454 - accuracy: 0.9033\n",
            "Epoch 350/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2333 - accuracy: 0.9088\n",
            "Epoch 351/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1882 - accuracy: 0.9378\n",
            "Epoch 352/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.2183 - accuracy: 0.9171\n",
            "Epoch 353/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2101 - accuracy: 0.9116\n",
            "Epoch 354/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2221 - accuracy: 0.9171\n",
            "Epoch 355/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2263 - accuracy: 0.9130\n",
            "Epoch 356/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2061 - accuracy: 0.9296\n",
            "Epoch 357/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2179 - accuracy: 0.9213\n",
            "Epoch 358/500\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 0.2288 - accuracy: 0.9088\n",
            "Epoch 359/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.2135 - accuracy: 0.9171\n",
            "Epoch 360/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.2009 - accuracy: 0.9254\n",
            "Epoch 361/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.2316 - accuracy: 0.9061\n",
            "Epoch 362/500\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 0.2344 - accuracy: 0.9075\n",
            "Epoch 363/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.2144 - accuracy: 0.9130\n",
            "Epoch 364/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.2058 - accuracy: 0.9185\n",
            "Epoch 365/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1947 - accuracy: 0.9406\n",
            "Epoch 366/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.2107 - accuracy: 0.9254\n",
            "Epoch 367/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1920 - accuracy: 0.9282\n",
            "Epoch 368/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2046 - accuracy: 0.9227\n",
            "Epoch 369/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1862 - accuracy: 0.9268\n",
            "Epoch 370/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2070 - accuracy: 0.9171\n",
            "Epoch 371/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2108 - accuracy: 0.9199\n",
            "Epoch 372/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1992 - accuracy: 0.9227\n",
            "Epoch 373/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1949 - accuracy: 0.9296\n",
            "Epoch 374/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1867 - accuracy: 0.9351\n",
            "Epoch 375/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1897 - accuracy: 0.9351\n",
            "Epoch 376/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1902 - accuracy: 0.9323\n",
            "Epoch 377/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1952 - accuracy: 0.9282\n",
            "Epoch 378/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2182 - accuracy: 0.9185\n",
            "Epoch 379/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2074 - accuracy: 0.9282\n",
            "Epoch 380/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1859 - accuracy: 0.9240\n",
            "Epoch 381/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2146 - accuracy: 0.9185\n",
            "Epoch 382/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1817 - accuracy: 0.9309\n",
            "Epoch 383/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1941 - accuracy: 0.9268\n",
            "Epoch 384/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2114 - accuracy: 0.9144\n",
            "Epoch 385/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1851 - accuracy: 0.9337\n",
            "Epoch 386/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1784 - accuracy: 0.9392\n",
            "Epoch 387/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1823 - accuracy: 0.9337\n",
            "Epoch 388/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2223 - accuracy: 0.9088\n",
            "Epoch 389/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2015 - accuracy: 0.9323\n",
            "Epoch 390/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1938 - accuracy: 0.9337\n",
            "Epoch 391/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1680 - accuracy: 0.9517\n",
            "Epoch 392/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1897 - accuracy: 0.9296\n",
            "Epoch 393/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2028 - accuracy: 0.9185\n",
            "Epoch 394/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1728 - accuracy: 0.9309\n",
            "Epoch 395/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1879 - accuracy: 0.9268\n",
            "Epoch 396/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1785 - accuracy: 0.9392\n",
            "Epoch 397/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1951 - accuracy: 0.9268\n",
            "Epoch 398/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1691 - accuracy: 0.9461\n",
            "Epoch 399/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1722 - accuracy: 0.9323\n",
            "Epoch 400/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1599 - accuracy: 0.9517\n",
            "Epoch 401/500\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 0.1816 - accuracy: 0.9282\n",
            "Epoch 402/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1789 - accuracy: 0.9240\n",
            "Epoch 403/500\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.2643 - accuracy: 0.8992\n",
            "Epoch 404/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1867 - accuracy: 0.9365\n",
            "Epoch 405/500\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 0.1989 - accuracy: 0.9240\n",
            "Epoch 406/500\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 0.1587 - accuracy: 0.9503\n",
            "Epoch 407/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.2088 - accuracy: 0.9102\n",
            "Epoch 408/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1863 - accuracy: 0.9240\n",
            "Epoch 409/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1687 - accuracy: 0.9448\n",
            "Epoch 410/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1737 - accuracy: 0.9406\n",
            "Epoch 411/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1999 - accuracy: 0.9102\n",
            "Epoch 412/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1668 - accuracy: 0.9378\n",
            "Epoch 413/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2015 - accuracy: 0.9130\n",
            "Epoch 414/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1718 - accuracy: 0.9337\n",
            "Epoch 415/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1591 - accuracy: 0.9448\n",
            "Epoch 416/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1611 - accuracy: 0.9503\n",
            "Epoch 417/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1867 - accuracy: 0.9323\n",
            "Epoch 418/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1606 - accuracy: 0.9475\n",
            "Epoch 419/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1526 - accuracy: 0.9406\n",
            "Epoch 420/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.2065 - accuracy: 0.9185\n",
            "Epoch 421/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1986 - accuracy: 0.9213\n",
            "Epoch 422/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1851 - accuracy: 0.9365\n",
            "Epoch 423/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1677 - accuracy: 0.9517\n",
            "Epoch 424/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1607 - accuracy: 0.9420\n",
            "Epoch 425/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1619 - accuracy: 0.9434\n",
            "Epoch 426/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1632 - accuracy: 0.9420\n",
            "Epoch 427/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1491 - accuracy: 0.9517\n",
            "Epoch 428/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1669 - accuracy: 0.9434\n",
            "Epoch 429/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1624 - accuracy: 0.9392\n",
            "Epoch 430/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2184 - accuracy: 0.9061\n",
            "Epoch 431/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1527 - accuracy: 0.9406\n",
            "Epoch 432/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1758 - accuracy: 0.9420\n",
            "Epoch 433/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1676 - accuracy: 0.9461\n",
            "Epoch 434/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1795 - accuracy: 0.9351\n",
            "Epoch 435/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1550 - accuracy: 0.9489\n",
            "Epoch 436/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1483 - accuracy: 0.9530\n",
            "Epoch 437/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1590 - accuracy: 0.9406\n",
            "Epoch 438/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1623 - accuracy: 0.9309\n",
            "Epoch 439/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1816 - accuracy: 0.9296\n",
            "Epoch 440/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1538 - accuracy: 0.9448\n",
            "Epoch 441/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1830 - accuracy: 0.9309\n",
            "Epoch 442/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1696 - accuracy: 0.9434\n",
            "Epoch 443/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1728 - accuracy: 0.9406\n",
            "Epoch 444/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1469 - accuracy: 0.9613\n",
            "Epoch 445/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1771 - accuracy: 0.9337\n",
            "Epoch 446/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1578 - accuracy: 0.9503\n",
            "Epoch 447/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1443 - accuracy: 0.9448\n",
            "Epoch 448/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1668 - accuracy: 0.9268\n",
            "Epoch 449/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1466 - accuracy: 0.9489\n",
            "Epoch 450/500\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 0.1695 - accuracy: 0.9365\n",
            "Epoch 451/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1609 - accuracy: 0.9461\n",
            "Epoch 452/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1499 - accuracy: 0.9434\n",
            "Epoch 453/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1730 - accuracy: 0.9365\n",
            "Epoch 454/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1929 - accuracy: 0.9254\n",
            "Epoch 455/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1582 - accuracy: 0.9475\n",
            "Epoch 456/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1366 - accuracy: 0.9544\n",
            "Epoch 457/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1315 - accuracy: 0.9530\n",
            "Epoch 458/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1461 - accuracy: 0.9475\n",
            "Epoch 459/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1374 - accuracy: 0.9530\n",
            "Epoch 460/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1589 - accuracy: 0.9392\n",
            "Epoch 461/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1323 - accuracy: 0.9586\n",
            "Epoch 462/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1475 - accuracy: 0.9544\n",
            "Epoch 463/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1346 - accuracy: 0.9613\n",
            "Epoch 464/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1468 - accuracy: 0.9503\n",
            "Epoch 465/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1336 - accuracy: 0.9572\n",
            "Epoch 466/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1299 - accuracy: 0.9655\n",
            "Epoch 467/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1413 - accuracy: 0.9489\n",
            "Epoch 468/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1619 - accuracy: 0.9392\n",
            "Epoch 469/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1563 - accuracy: 0.9503\n",
            "Epoch 470/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1336 - accuracy: 0.9558\n",
            "Epoch 471/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1359 - accuracy: 0.9530\n",
            "Epoch 472/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1616 - accuracy: 0.9365\n",
            "Epoch 473/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1445 - accuracy: 0.9544\n",
            "Epoch 474/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1471 - accuracy: 0.9503\n",
            "Epoch 475/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1397 - accuracy: 0.9461\n",
            "Epoch 476/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1115 - accuracy: 0.9696\n",
            "Epoch 477/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1246 - accuracy: 0.9572\n",
            "Epoch 478/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1246 - accuracy: 0.9655\n",
            "Epoch 479/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1249 - accuracy: 0.9599\n",
            "Epoch 480/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1385 - accuracy: 0.9613\n",
            "Epoch 481/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1450 - accuracy: 0.9489\n",
            "Epoch 482/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1419 - accuracy: 0.9503\n",
            "Epoch 483/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1450 - accuracy: 0.9475\n",
            "Epoch 484/500\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.1283 - accuracy: 0.9558\n",
            "Epoch 485/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1268 - accuracy: 0.9558\n",
            "Epoch 486/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1292 - accuracy: 0.9530\n",
            "Epoch 487/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1346 - accuracy: 0.9503\n",
            "Epoch 488/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1203 - accuracy: 0.9655\n",
            "Epoch 489/500\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 0.1162 - accuracy: 0.9655\n",
            "Epoch 490/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1423 - accuracy: 0.9544\n",
            "Epoch 491/500\n",
            "46/46 [==============================] - 0s 9ms/step - loss: 0.1556 - accuracy: 0.9475\n",
            "Epoch 492/500\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 0.1491 - accuracy: 0.9434\n",
            "Epoch 493/500\n",
            "46/46 [==============================] - 0s 8ms/step - loss: 0.1397 - accuracy: 0.9572\n",
            "Epoch 494/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1363 - accuracy: 0.9503\n",
            "Epoch 495/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1279 - accuracy: 0.9558\n",
            "Epoch 496/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1277 - accuracy: 0.9530\n",
            "Epoch 497/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1146 - accuracy: 0.9613\n",
            "Epoch 498/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1484 - accuracy: 0.9406\n",
            "Epoch 499/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1296 - accuracy: 0.9558\n",
            "Epoch 500/500\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.1098 - accuracy: 0.9669\n",
            "CNN training loss: 0.0578516386449337\n",
            "CNN training accuracy: 0.9958563446998596\n",
            "23/23 [==============================] - 0s 4ms/step\n",
            "Training confusion matrix \n",
            " [[324   3]\n",
            " [  0 397]]\n",
            "CNN test loss: 1.7890411615371704\n",
            "CNN test accuracy: 0.47999998927116394\n",
            "8/8 [==============================] - 0s 4ms/step\n",
            "Testing confusion matrix \n",
            " [[53 80]\n",
            " [50 67]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9-mFUUV1kA85"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pMHtDX0okBAI"
      },
      "execution_count": 68,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}